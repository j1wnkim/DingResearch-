{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 21:59:37.818628: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-06 21:59:37.821271: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-06 21:59:37.864720: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-06 21:59:37.865269: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-06 21:59:38.476995: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "from tensorflow import keras \n",
    "import tensorflow \n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0+cu117'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Data Setup "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining methods to set up data to return sequences of varying lengths (n_steps) for x and y:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also plan to try to clean up the data more exhaustively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Demand</th>\n",
       "      <th>Annual Usage (kWh)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>WeekDay or Weekend</th>\n",
       "      <th>HVN_lon</th>\n",
       "      <th>HVN_lat</th>\n",
       "      <th>HVN_tmpf</th>\n",
       "      <th>...</th>\n",
       "      <th>DXR_drct</th>\n",
       "      <th>DXR_sknt</th>\n",
       "      <th>DXR_vsby</th>\n",
       "      <th>MMK_lon</th>\n",
       "      <th>MMK_lat</th>\n",
       "      <th>MMK_tmpf</th>\n",
       "      <th>MMK_drct</th>\n",
       "      <th>MMK_sknt</th>\n",
       "      <th>MMK_vsby</th>\n",
       "      <th>HotTemperatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3053.00</td>\n",
       "      <td>13244.454545</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>33.980000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>28.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2892.00</td>\n",
       "      <td>13244.454545</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>37.940000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>28.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2774.00</td>\n",
       "      <td>13244.454545</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>37.040000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>33.08</td>\n",
       "      <td>150.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2710.00</td>\n",
       "      <td>13244.454545</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>33.980000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>33.08</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2698.00</td>\n",
       "      <td>13244.454545</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>30.920000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>28.94</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96422</th>\n",
       "      <td>3310.60</td>\n",
       "      <td>14064.500000</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>46.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96423</th>\n",
       "      <td>3148.00</td>\n",
       "      <td>14064.500000</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>46.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96424</th>\n",
       "      <td>2988.93</td>\n",
       "      <td>14064.500000</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>46.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96425</th>\n",
       "      <td>2793.70</td>\n",
       "      <td>14064.500000</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>46.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96426</th>\n",
       "      <td>2629.35</td>\n",
       "      <td>14064.500000</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>46.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96427 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Demand  Annual Usage (kWh)  Year  Month  Day  Hour  \\\n",
       "0      3053.00        13244.454545  2011      1    1     0   \n",
       "1      2892.00        13244.454545  2011      1    1     1   \n",
       "2      2774.00        13244.454545  2011      1    1     2   \n",
       "3      2710.00        13244.454545  2011      1    1     3   \n",
       "4      2698.00        13244.454545  2011      1    1     4   \n",
       "...        ...                 ...   ...    ...  ...   ...   \n",
       "96422  3310.60        14064.500000  2021     12   31    19   \n",
       "96423  3148.00        14064.500000  2021     12   31    20   \n",
       "96424  2988.93        14064.500000  2021     12   31    21   \n",
       "96425  2793.70        14064.500000  2021     12   31    22   \n",
       "96426  2629.35        14064.500000  2021     12   31    23   \n",
       "\n",
       "       WeekDay or Weekend  HVN_lon  HVN_lat   HVN_tmpf  ...   DXR_drct  \\\n",
       "0                       0 -72.8868  41.2638  33.980000  ...   0.000000   \n",
       "1                       0 -72.8868  41.2638  37.940000  ...   0.000000   \n",
       "2                       0 -72.8868  41.2638  37.040000  ...   0.000000   \n",
       "3                       0 -72.8868  41.2638  33.980000  ...   0.000000   \n",
       "4                       0 -72.8868  41.2638  30.920000  ...   0.000000   \n",
       "...                   ...      ...      ...        ...  ...        ...   \n",
       "96422                   1 -72.8868  41.2638  46.133333  ...  46.666667   \n",
       "96423                   1 -72.8868  41.2638  46.133333  ...  46.666667   \n",
       "96424                   1 -72.8868  41.2638  46.133333  ...  46.666667   \n",
       "96425                   1 -72.8868  41.2638  46.133333  ...  46.666667   \n",
       "96426                   1 -72.8868  41.2638  46.133333  ...  46.666667   \n",
       "\n",
       "       DXR_sknt  DXR_vsby  MMK_lon  MMK_lat  MMK_tmpf  MMK_drct  MMK_sknt  \\\n",
       "0      0.000000  5.000000   -72.83    41.51     28.94       0.0       0.0   \n",
       "1      0.000000  5.000000   -72.83    41.51     28.94       0.0       0.0   \n",
       "2      0.000000  4.000000   -72.83    41.51     33.08     150.0       5.0   \n",
       "3      0.000000  4.000000   -72.83    41.51     33.08     150.0       4.0   \n",
       "4      0.000000  4.000000   -72.83    41.51     28.94     100.0       3.0   \n",
       "...         ...       ...      ...      ...       ...       ...       ...   \n",
       "96422  1.333333  6.666667   -72.83    41.51     43.00       0.0       0.0   \n",
       "96423  1.333333  6.666667   -72.83    41.51     43.00       0.0       0.0   \n",
       "96424  1.333333  6.666667   -72.83    41.51     43.00       0.0       0.0   \n",
       "96425  1.333333  6.666667   -72.83    41.51     43.00       0.0       0.0   \n",
       "96426  1.333333  6.666667   -72.83    41.51     43.00       0.0       0.0   \n",
       "\n",
       "       MMK_vsby  HotTemperatures  \n",
       "0           4.0                0  \n",
       "1           4.0                0  \n",
       "2           5.0                0  \n",
       "3           6.0                0  \n",
       "4           5.0                0  \n",
       "...         ...              ...  \n",
       "96422       4.0                0  \n",
       "96423       4.0                0  \n",
       "96424       4.0                0  \n",
       "96425       4.0                0  \n",
       "96426       4.0                0  \n",
       "\n",
       "[96427 rows x 56 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TransformerData = pd.read_csv(\"/home/jik19004/FilesToRun/DINGRESEARCH/DingResearchDec28th/DingLSTMFolder/FINALIZED_DATA.csv\")\n",
    "display(TransformerData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annual Usage (kWh)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>WeekDay or Weekend</th>\n",
       "      <th>HVN_lon</th>\n",
       "      <th>HVN_lat</th>\n",
       "      <th>HVN_tmpf</th>\n",
       "      <th>HVN_drct</th>\n",
       "      <th>...</th>\n",
       "      <th>DXR_drct</th>\n",
       "      <th>DXR_sknt</th>\n",
       "      <th>DXR_vsby</th>\n",
       "      <th>MMK_lon</th>\n",
       "      <th>MMK_lat</th>\n",
       "      <th>MMK_tmpf</th>\n",
       "      <th>MMK_drct</th>\n",
       "      <th>MMK_sknt</th>\n",
       "      <th>MMK_vsby</th>\n",
       "      <th>HotTemperatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13244.454545</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>33.980000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>28.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13244.454545</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>37.940000</td>\n",
       "      <td>63.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>28.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13244.454545</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>37.040000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>33.08</td>\n",
       "      <td>150.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13244.454545</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>33.980000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>33.08</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13244.454545</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>30.920000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>28.94</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96422</th>\n",
       "      <td>14064.500000</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>46.133333</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96423</th>\n",
       "      <td>14064.500000</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>46.133333</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96424</th>\n",
       "      <td>14064.500000</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>46.133333</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96425</th>\n",
       "      <td>14064.500000</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>46.133333</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96426</th>\n",
       "      <td>14064.500000</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>-72.8868</td>\n",
       "      <td>41.2638</td>\n",
       "      <td>46.133333</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>-72.83</td>\n",
       "      <td>41.51</td>\n",
       "      <td>43.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96427 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Annual Usage (kWh)  Year  Month  Day  Hour  WeekDay or Weekend  \\\n",
       "0            13244.454545  2011      1    1     0                   0   \n",
       "1            13244.454545  2011      1    1     1                   0   \n",
       "2            13244.454545  2011      1    1     2                   0   \n",
       "3            13244.454545  2011      1    1     3                   0   \n",
       "4            13244.454545  2011      1    1     4                   0   \n",
       "...                   ...   ...    ...  ...   ...                 ...   \n",
       "96422        14064.500000  2021     12   31    19                   1   \n",
       "96423        14064.500000  2021     12   31    20                   1   \n",
       "96424        14064.500000  2021     12   31    21                   1   \n",
       "96425        14064.500000  2021     12   31    22                   1   \n",
       "96426        14064.500000  2021     12   31    23                   1   \n",
       "\n",
       "       HVN_lon  HVN_lat   HVN_tmpf    HVN_drct  ...   DXR_drct  DXR_sknt  \\\n",
       "0     -72.8868  41.2638  33.980000  190.000000  ...   0.000000  0.000000   \n",
       "1     -72.8868  41.2638  37.940000   63.333333  ...   0.000000  0.000000   \n",
       "2     -72.8868  41.2638  37.040000  200.000000  ...   0.000000  0.000000   \n",
       "3     -72.8868  41.2638  33.980000  130.000000  ...   0.000000  0.000000   \n",
       "4     -72.8868  41.2638  30.920000  130.000000  ...   0.000000  0.000000   \n",
       "...        ...      ...        ...         ...  ...        ...       ...   \n",
       "96422 -72.8868  41.2638  46.133333   86.666667  ...  46.666667  1.333333   \n",
       "96423 -72.8868  41.2638  46.133333   86.666667  ...  46.666667  1.333333   \n",
       "96424 -72.8868  41.2638  46.133333   86.666667  ...  46.666667  1.333333   \n",
       "96425 -72.8868  41.2638  46.133333   86.666667  ...  46.666667  1.333333   \n",
       "96426 -72.8868  41.2638  46.133333   86.666667  ...  46.666667  1.333333   \n",
       "\n",
       "       DXR_vsby  MMK_lon  MMK_lat  MMK_tmpf  MMK_drct  MMK_sknt  MMK_vsby  \\\n",
       "0      5.000000   -72.83    41.51     28.94       0.0       0.0       4.0   \n",
       "1      5.000000   -72.83    41.51     28.94       0.0       0.0       4.0   \n",
       "2      4.000000   -72.83    41.51     33.08     150.0       5.0       5.0   \n",
       "3      4.000000   -72.83    41.51     33.08     150.0       4.0       6.0   \n",
       "4      4.000000   -72.83    41.51     28.94     100.0       3.0       5.0   \n",
       "...         ...      ...      ...       ...       ...       ...       ...   \n",
       "96422  6.666667   -72.83    41.51     43.00       0.0       0.0       4.0   \n",
       "96423  6.666667   -72.83    41.51     43.00       0.0       0.0       4.0   \n",
       "96424  6.666667   -72.83    41.51     43.00       0.0       0.0       4.0   \n",
       "96425  6.666667   -72.83    41.51     43.00       0.0       0.0       4.0   \n",
       "96426  6.666667   -72.83    41.51     43.00       0.0       0.0       4.0   \n",
       "\n",
       "       HotTemperatures  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "96422                0  \n",
       "96423                0  \n",
       "96424                0  \n",
       "96425                0  \n",
       "96426                0  \n",
       "\n",
       "[96427 rows x 55 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DemandData = TransformerData.loc[:, \"Demand\"].copy()\n",
    "TransformerData.drop(\"Demand\", axis = 1,inplace = True)\n",
    "display(TransformerData)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Our Data so that one particular feature wouldn't dominate the loss in particular! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data into Training, Validation, and Testing! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameter \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras as keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_sequences(data, outputData, input_n_steps, output_n_steps):\n",
    "    X = []\n",
    "    Y = []\n",
    "    length = len(data)\n",
    "    for i in range(0,length, output_n_steps):\n",
    "        input_indx = i + input_n_steps\n",
    "        output_indx = input_indx + output_n_steps \n",
    "        if (output_indx > len(data)): # we need to have equally split sequences. \n",
    "            break               # The remaining data that cannot fit into a fixed\n",
    "                                # sequence will immediately be cut!\n",
    "        else:\n",
    "            Xsample = data.iloc[i:input_indx, :] # get the previous data\n",
    "            Ysample = outputData[input_indx:output_indx]\n",
    "            X.append(Xsample)\n",
    "            Y.append(Ysample) \n",
    "    X = np.asarray(X).astype('float64')\n",
    "    Y = np.asarray(Y).astype('float64')\n",
    "    return (X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "def scaleTheData(data):\n",
    "    scaler = StandardScaler()\n",
    "    # split the data first. \n",
    "    data2 = scaler.fit_transform(data)\n",
    "    data = pd.DataFrame(data2, columns = data.columns)\n",
    "    return data\n",
    "\n",
    "def splitDataAndScale(data, output):\n",
    "    \n",
    "    TrainingData = scaleTheData(data.iloc[:61363, :].copy()) # The index for Janruary 1st 2018 basically, don't necessarily hard code it. \n",
    "    TrainingOutput = output[:61363].copy()\n",
    "\n",
    "    RemainingData = data.iloc[61363:, :].copy()\n",
    "    RemainingOutput = output[61363:].copy()\n",
    "\n",
    "    ValidationData = scaleTheData(RemainingData.iloc[:int(0.5*len(RemainingData)), :].copy())\n",
    "    ValidationOutput = RemainingOutput[:int(0.5*len(RemainingOutput))].copy()\n",
    "\n",
    "    TestingData = scaleTheData(RemainingData.iloc[int(0.5 * len(RemainingData)):, :].copy())\n",
    "    TestingOutput = RemainingOutput[int(0.5 * len(RemainingData)):].copy()\n",
    "\n",
    "    TrainingSequences = return_sequences(TrainingData, TrainingOutput, 18, 6)\n",
    "\n",
    "    TransformedTrainingData = TrainingSequences[0]\n",
    "    TransformedTrainingOutput = TrainingSequences[1]\n",
    "\n",
    "    ValidationSequences = return_sequences(ValidationData, ValidationOutput, 18,6)\n",
    "\n",
    "    TransformedValidationData = ValidationSequences[0]\n",
    "    TransformedValidationOutput = ValidationSequences[1]\n",
    "\n",
    "    TestingSequences = return_sequences(TestingData, TestingOutput, 18, 6)\n",
    "\n",
    "    TransformedTestingData = TestingSequences[0]\n",
    "    TransformedTestingOutput = TestingSequences[1]\n",
    "\n",
    "\n",
    "\n",
    "    return (TransformedTrainingData, TransformedTrainingOutput, TransformedValidationData, TransformedValidationOutput, \n",
    "    TransformedTestingData, TransformedTestingOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = splitDataAndScale(TransformerData, DemandData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10224, 18, 55)\n"
     ]
    }
   ],
   "source": [
    "print(data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2919, 18, 55)\n"
     ]
    }
   ],
   "source": [
    "print(data[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2919, 18, 55)\n"
     ]
    }
   ],
   "source": [
    "print(data[4].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = data[0]\n",
    "trainingOutput = data[1]\n",
    "validationData = data[2]\n",
    "validationOutput = data[3]\n",
    "testingData = data[4]\n",
    "testingnOutput = data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2919\n"
     ]
    }
   ],
   "source": [
    "print(len(data[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = [];  \n",
    "for i in range(len(data[0])): \n",
    "    TrainingData.append((data[0][i], data[1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2919, 18, 55)\n",
      "(2919, 6)\n"
     ]
    }
   ],
   "source": [
    "print(validationData.shape)\n",
    "print(validationOutput.shape)\n",
    "\n",
    "ValidationData = []; \n",
    "for i in range(len(data[2])):\n",
    "    ValidationData.append((data[2][i], data[3][i]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model Construction1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31266/1688313836.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(P)\n"
     ]
    }
   ],
   "source": [
    "def getPositionalEncoding1(batch_size, seq_len, d, n = 10000):\n",
    "        P = np.zeros((batch_size,seq_len, d))\n",
    "        for z in range(batch_size):\n",
    "            for k in range(seq_len):\n",
    "                for i in np.arange(int(d/2)):\n",
    "                    denominator = np.power(n, 2*i/d)\n",
    "                    P[z, k, 2*i] = np.sin(k/denominator)\n",
    "                    P[z,k, 2*i+1] = np.cos(k/denominator)\n",
    "        P = torch.tensor(P).to()\n",
    "        return torch.tensor(P)\n",
    "\n",
    "print(type(getPositionalEncoding1(10, 10, 10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesTransformer(nn.Module): \n",
    "    def __init__(self, num_layers, dropout = 0.3, outfeatures1 = 16, outfeatures2 = 16, dim_feedforward = 2048, output_num = 6):\n",
    "        super().__init__()\n",
    "\n",
    "        self.Linear0 = nn.Linear(in_features = 55, out_features = 80)\n",
    "        self.encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model = 80, nhead = 10, dim_feedforward = dim_feedforward,  dropout = dropout, batch_first = True), num_layers = num_layers)\n",
    "        self.batchnorm = nn.BatchNorm1d(num_features = 18)      \n",
    "        self.Flatten = nn.Flatten() # take into account that we're doing this in batches!! \n",
    "        \n",
    "        self.Linear1 = nn.Linear(in_features = 80, out_features = outfeatures1);\n",
    "        self.activation1 = nn.LeakyReLU(negative_slope = 0.25, inplace = True)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(num_features = 18)\n",
    "        self.dropoutLayer1 = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "        # We then slice the last half! \n",
    "        self.Linear2 = nn.Linear(in_features = outfeatures1, out_features = outfeatures2); \n",
    "        self.activation2 = nn.LeakyReLU(negative_slope= 0.25, inplace = True); \n",
    "        self.batchnorm2 = nn.BatchNorm1d(num_features = 18)\n",
    "        self.dropoutLayer2 = nn.Dropout(dropout);\n",
    "\n",
    "\n",
    "        self.Linear3 = nn.Linear(in_features= outfeatures2, out_features = 96)\n",
    "        self.activation3 = nn.LeakyReLU(negative_slope= 0.25, inplace = True); \n",
    "        self.batchnorm3 = nn.BatchNorm1d(num_features = 18)\n",
    "        self.dropoutLayer3 = nn.Dropout(dropout);\n",
    "\n",
    "\n",
    "        self.Linear4 = nn.Linear(in_features = 96 , out_features = 64) # we will then compute using 2 more fully connected layers. \n",
    "        self.activation4 = nn.ELU()\n",
    "        self.batchnorm4 = nn.BatchNorm1d(num_features = 18)\n",
    "        self.dropoutLayer4 = nn.Dropout(dropout);\n",
    "\n",
    "        self.Linear5 = nn.Linear(in_features= 64 * 18, out_features = 32 * 18)\n",
    "        self.activation5 = nn.ELU(); \n",
    "        self.dropoutLayer5 = nn.Dropout(dropout)\n",
    "\n",
    "        \n",
    "        #self.Linear4 = nn.Linear(in_features = outfeatures3, out_features = 64)\n",
    "        #self.activation4 = nn.LeakyReLU(negative_slope = 0.25, inplace = False)\n",
    "        #self.dropoutLayer4 = nn.Dropout(dropout);\n",
    "\n",
    "\n",
    "        self.Linear6 = nn.Linear(in_features = 32 * 18, out_features = output_num)\n",
    "\n",
    "    def getPositionalEncoding(self, batch_size = 128, seq_len = 18, d = 110, n = 10000, device = torch.device(\"cuda\")):\n",
    "        P = np.zeros((batch_size,seq_len, d))\n",
    "        for z in range(batch_size):\n",
    "            for k in range(seq_len):\n",
    "                for i in np.arange(int(d/2)):\n",
    "                    denominator = np.power(n, 2*i/d)\n",
    "                    P[z, k, 2*i] = np.sin(k/denominator)\n",
    "                    P[z,k, 2*i+1] = np.cos(k/denominator)\n",
    "        P = torch.tensor(P)\n",
    "        P = P.type(\"torch.FloatTensor\")\n",
    "        return P.to(device)\n",
    "\n",
    "    def forward(self, src):\n",
    "        \n",
    "        val = self.Linear0(src)\n",
    "        val = val + self.getPositionalEncoding(batch_size = val.size(0), seq_len = val.size(1), d = val.size(2))\n",
    "        val = self.encoder(val) # this would be (72, 50)\n",
    "        val = self.batchnorm(val)    \n",
    "\n",
    "\n",
    "        val = self.Linear1(val) # this would then become (72, 6) \n",
    "        val = self.activation1(val) \n",
    "        val = self.batchnorm1(val) \n",
    "        val = self.dropoutLayer1(val) \n",
    "\n",
    "\n",
    "        val = self.Linear2(val) \n",
    "        val = self.activation2(val)\n",
    "        val = self.batchnorm2(val)\n",
    "        val = self.dropoutLayer2(val)\n",
    "\n",
    "        val = self.Linear3(val)\n",
    "        val = self.activation3(val)\n",
    "        val = self.batchnorm3(val)\n",
    "        val = self.dropoutLayer3(val)\n",
    "        \n",
    "                                    # Somehow, we need to conver the tensor of a size [28, 1, 55] into a 2 dimensional vector \n",
    "                                    # where it preserves dimension of the zeroeth index. But have it up to 2nd dimension. \n",
    "                                    # [28, etc] use tensor = torch.randn(x,y,1).squeeze(-1) where x = 10, y = 20, z = 30\n",
    "        val = self.Linear4(val) \n",
    "        val = self.activation4(val)\n",
    "        val = self.batchnorm4(val)\n",
    "        val = self.dropoutLayer4(val)\n",
    "        val = val.view(-1, val.size(1) * val.size(2)) # convert to 2 dimensional tensor \n",
    "\n",
    "        val = self.Linear5(val)\n",
    "        val = self.activation5(val)\n",
    "        val = self.dropoutLayer5(val)\n",
    "\n",
    "\n",
    "        val = self.Linear6(val) # This returns an output of a varying number. \n",
    "        val = val.squeeze()\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna \n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, output):\n",
    "        data = torch.tensor(data).float(); \n",
    "        output = torch.tensor(output).float() \n",
    "\n",
    "        self.data = data \n",
    "        self.output = output; \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx];\n",
    "        y = self.output[idx];\n",
    "        return x, y;\n",
    "\n",
    "# use the past 72 hours in advance and then predict the 1st hour, 6th hour, 12 hours! \n",
    "\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            running_loss += loss.item() * target.size(0)\n",
    "    return running_loss / len(val_loader.dataset)\n",
    "\n",
    "def Train_and_Evaluate(train_loader, val_loader, device, params, numEpochs, early_stop_epochs):\n",
    "    #num_layers, dropout = 0.1, outfeatures1 = 16, outfeatures2 = 16, outfeatures3 = 16, outfeatures4 = 16, dim_feedforward = 2048, output_num = 6\n",
    "    model = TimeSeriesTransformer(num_layers = params[0], outfeatures1 = params[1], outfeatures2 = params[2],\n",
    "                                dim_feedforward = params[3], output_num = 6)\n",
    "    model = model.to(device);\n",
    "    LossFunction = torch.nn.L1Loss();\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_count = 0\n",
    "    print(\"num layers:\", params[0])\n",
    "    print(\"outfeatures1:\", params[1])\n",
    "    print(\"outfeatures2:\", params[2])\n",
    "    print(\"dim_feedforward:\", params[3])\n",
    "    \n",
    "    Optimizer = torch.optim.Adam(params = model.parameters())\n",
    "    for epoch in range(0,numEpochs): \n",
    "        Training_Loss = 0; \n",
    "        total_samples = 0; \n",
    "        for input, output in train_loader:\n",
    "            input = input.to(device); \n",
    "            output = torch.squeeze(output, 1); \n",
    "            output = output.to(device); \n",
    "            predictedVal = model(input)\n",
    "            #predictedVal = torch.squeeze(predictedVal, 1)\n",
    "            Optimizer.zero_grad();\n",
    "            batchLoss = LossFunction(predictedVal, output);\n",
    "            batchLoss.backward(); \n",
    "            Optimizer.step();\n",
    "            Training_Loss += batchLoss * output.size(0) #* output.size(0);\n",
    "            total_samples += output.size(0)\n",
    "        Training_Loss = Training_Loss/total_samples\n",
    "\n",
    "\n",
    "        Validation_Loss = 0; \n",
    "        print(\"passed \", epoch, \"epoch\", \"Training Loss: \", Training_Loss,\" \", end = \"\")\n",
    "        with torch.no_grad():\n",
    "            total_val_samples = 0; \n",
    "            Validation_Loss = 0; \n",
    "            for val_input, val_output in val_loader:\n",
    "                val_input = val_input.to(device); \n",
    "                val_output = torch.squeeze(val_output,1);\n",
    "                val_output = val_output.to(device);\n",
    "\n",
    "                predictedVal = model(val_input)\n",
    "                Validation_Loss += LossFunction(val_output, predictedVal) * val_output.size(0)\n",
    "                total_val_samples += val_output.size(0)\n",
    "            Validation_Loss = Validation_Loss/total_val_samples\n",
    "            print(\"Validation Loss: \", Validation_Loss)\n",
    "\n",
    "            if Validation_Loss < best_val_loss:\n",
    "                best_val_loss = Validation_Loss\n",
    "                torch.save(model, \"//home//jik19004//FilesToRun//DINGRESEARCH//DingResearchDec28th//DingTransformerFolderTransformer6\")\n",
    "                early_stop_count = 0;\n",
    "            else:\n",
    "                early_stop_count +=1 \n",
    "            if early_stop_count >= early_stop_epochs:\n",
    "                return best_val_loss; \n",
    "            \n",
    "            \n",
    "\n",
    "    return best_val_loss; \n",
    "\n",
    "def predict(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    act_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for data, _ in data_loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            predictions.append(output.cpu().numpy())\n",
    "            act_outputs.append(_.numpy())\n",
    "\n",
    "    return (np.concatenate(predictions), np.concatenate(act_outputs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation_Loss = 0; \n",
    "        print(\"passed \", epoch, \"epoch\", \"Training Loss: \", Training_Loss,\" \", end = \"\")\n",
    "        with torch.no_grad():\n",
    "            count1 = 0;\n",
    "            for val_input, val_output in val_loader:\n",
    "                val_input = val_input.to(device); \n",
    "                val_output = torch.squeeze(val_output,1);\n",
    "                val_output = val_output.to(device);\n",
    "\n",
    "                predictedVal = model(val_input);\n",
    "                predictedVal = torch.squeeze(predictedVal, 1)\n",
    "                batchLoss = LossFunction(val_output, predictedVal);\n",
    "                Validation_Loss += batchLoss # * val_output.size(0);\n",
    "                count1 += \n",
    "            Validation_Loss = Validation_Loss/count1\n",
    "            print(\"Validation Loss: \", Validation_Loss)\n",
    "\n",
    "            if Validation_Loss < best_val_loss:\n",
    "                best_val_loss = Validation_Loss\n",
    "                early_stop_count = 0;\n",
    "            else:\n",
    "                early_stop_count +=1 \n",
    "            if early_stop_count >= early_stop_epochs:\n",
    "                return best_val_loss; "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GO DEAL WITH NAN VALUES IN OUR DATA!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = TimeSeriesDataset(data[0],data[1])\n",
    "ValidationData = TimeSeriesDataset(data[2],data[3])\n",
    "TestingData = TimeSeriesDataset(data[4],data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingLoader = DataLoader(TrainingData, batch_size = 256);\n",
    "ValidationLoader = DataLoader(ValidationData, batch_size = 256);\n",
    "TestingLoader = DataLoader(TestingData, batch_size = 256);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fb09467c670>\n"
     ]
    }
   ],
   "source": [
    "print(TrainingLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    #num_layers = params[0], outfeatures = params[1], dim_feedforward = params[2]\n",
    "    params = [trial.suggest_int(\"num_layers\", low = 2, high = 4, step = 1), \n",
    "              trial.suggest_int(\"out_features1\", low = 140, high = 180, step = 20),\n",
    "              trial.suggest_int(\"out_features2\", low = 96, high = 120, step = 12),\n",
    "              trial.suggest_int(\"dim_feedforward\", low = 256, high = 512, step = 64)];\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\");\n",
    "    return Train_and_Evaluate(TrainingLoader, ValidationLoader ,device, params, 260,20); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-06 21:59:42,925]\u001b[0m Using an existing study with name 'Transformer6' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num layers: 3\n",
      "outfeatures1: 160\n",
      "outfeatures2: 120\n",
      "dim_feedforward: 448\n",
      "passed  0 epoch Training Loss:  tensor(3241.2156, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(2497.6699, device='cuda:0')\n",
      "passed  1 epoch Training Loss:  tensor(1478.4838, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(659.9746, device='cuda:0')\n",
      "passed  2 epoch Training Loss:  tensor(600.4034, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(566.6569, device='cuda:0')\n",
      "passed  3 epoch Training Loss:  tensor(585.0054, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(479.4328, device='cuda:0')\n",
      "passed  4 epoch Training Loss:  tensor(489.5555, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(456.5722, device='cuda:0')\n",
      "passed  5 epoch Training Loss:  tensor(439.6370, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(395.1451, device='cuda:0')\n",
      "passed  6 epoch Training Loss:  tensor(418.5207, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(374.0264, device='cuda:0')\n",
      "passed  7 epoch Training Loss:  tensor(407.5405, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(355.9302, device='cuda:0')\n",
      "passed  8 epoch Training Loss:  tensor(389.8794, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(365.9484, device='cuda:0')\n",
      "passed  9 epoch Training Loss:  tensor(360.0298, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(326.6020, device='cuda:0')\n",
      "passed  10 epoch Training Loss:  tensor(367.1623, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(410.1705, device='cuda:0')\n",
      "passed  11 epoch Training Loss:  tensor(330.4462, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(334.8441, device='cuda:0')\n",
      "passed  12 epoch Training Loss:  tensor(368.0528, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(360.4895, device='cuda:0')\n",
      "passed  13 epoch Training Loss:  tensor(323.7607, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(336.7541, device='cuda:0')\n",
      "passed  14 epoch Training Loss:  tensor(323.8040, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(371.7184, device='cuda:0')\n",
      "passed  15 epoch Training Loss:  tensor(324.5163, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(357.5880, device='cuda:0')\n",
      "passed  16 epoch Training Loss:  tensor(313.7622, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(309.6877, device='cuda:0')\n",
      "passed  17 epoch Training Loss:  tensor(315.1435, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(400.4082, device='cuda:0')\n",
      "passed  18 epoch Training Loss:  tensor(324.2703, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(389.6216, device='cuda:0')\n",
      "passed  19 epoch Training Loss:  tensor(319.1092, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(425.8562, device='cuda:0')\n",
      "passed  20 epoch Training Loss:  tensor(316.4096, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(431.8804, device='cuda:0')\n",
      "passed  21 epoch Training Loss:  tensor(321.9134, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(358.7260, device='cuda:0')\n",
      "passed  22 epoch Training Loss:  tensor(297.3137, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(393.1336, device='cuda:0')\n",
      "passed  23 epoch Training Loss:  tensor(296.5919, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(351.6873, device='cuda:0')\n",
      "passed  24 epoch Training Loss:  tensor(287.3907, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(378.1408, device='cuda:0')\n",
      "passed  25 epoch Training Loss:  tensor(288.7104, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(391.0770, device='cuda:0')\n",
      "passed  26 epoch Training Loss:  tensor(290.2170, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(416.4023, device='cuda:0')\n",
      "passed  27 epoch Training Loss:  tensor(287.8309, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(444.8969, device='cuda:0')\n",
      "passed  28 epoch Training Loss:  tensor(297.4665, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(387.9485, device='cuda:0')\n",
      "passed  29 epoch Training Loss:  tensor(279.7154, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(358.4331, device='cuda:0')\n",
      "passed  30 epoch Training Loss:  tensor(272.1678, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(350.3311, device='cuda:0')\n",
      "passed  31 epoch Training Loss:  tensor(260.2603, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(336.4215, device='cuda:0')\n",
      "passed  32 epoch Training Loss:  tensor(258.6649, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(343.4038, device='cuda:0')\n",
      "passed  33 epoch Training Loss:  tensor(250.9593, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(339.8561, device='cuda:0')\n",
      "passed  34 epoch Training Loss:  tensor(258.8657, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(343.4637, device='cuda:0')\n",
      "passed  35 epoch Training Loss:  tensor(250.5625, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(289.9858, device='cuda:0')\n",
      "passed  36 epoch Training Loss:  tensor(259.0787, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(315.3741, device='cuda:0')\n",
      "passed  37 epoch Training Loss:  tensor(248.5112, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(379.3543, device='cuda:0')\n",
      "passed  38 epoch Training Loss:  tensor(247.5312, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(365.2706, device='cuda:0')\n",
      "passed  39 epoch Training Loss:  tensor(256.3200, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(327.5603, device='cuda:0')\n",
      "passed  40 epoch Training Loss:  tensor(235.5344, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(302.9829, device='cuda:0')\n",
      "passed  41 epoch Training Loss:  tensor(231.7740, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(269.9219, device='cuda:0')\n",
      "passed  42 epoch Training Loss:  tensor(261.4626, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(289.9343, device='cuda:0')\n",
      "passed  43 epoch Training Loss:  tensor(250.7737, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(271.2023, device='cuda:0')\n",
      "passed  44 epoch Training Loss:  tensor(255.4389, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(273.4419, device='cuda:0')\n",
      "passed  45 epoch Training Loss:  tensor(262.0367, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(286.8459, device='cuda:0')\n",
      "passed  46 epoch Training Loss:  tensor(275.4453, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(261.8540, device='cuda:0')\n",
      "passed  47 epoch Training Loss:  tensor(260.5987, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(261.4889, device='cuda:0')\n",
      "passed  48 epoch Training Loss:  tensor(239.4635, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(263.3877, device='cuda:0')\n",
      "passed  49 epoch Training Loss:  tensor(230.1785, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(252.3276, device='cuda:0')\n",
      "passed  50 epoch Training Loss:  tensor(230.3872, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(259.3180, device='cuda:0')\n",
      "passed  51 epoch Training Loss:  tensor(229.2248, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(247.3768, device='cuda:0')\n",
      "passed  52 epoch Training Loss:  tensor(244.8337, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(261.9991, device='cuda:0')\n",
      "passed  53 epoch Training Loss:  tensor(249.0912, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(268.1514, device='cuda:0')\n",
      "passed  54 epoch Training Loss:  tensor(240.0795, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(255.3267, device='cuda:0')\n",
      "passed  55 epoch Training Loss:  tensor(226.7310, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(274.7716, device='cuda:0')\n",
      "passed  56 epoch Training Loss:  tensor(216.1640, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(254.6608, device='cuda:0')\n",
      "passed  57 epoch Training Loss:  tensor(218.5575, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(263.0482, device='cuda:0')\n",
      "passed  58 epoch Training Loss:  tensor(218.2613, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(266.0923, device='cuda:0')\n",
      "passed  59 epoch Training Loss:  tensor(216.5232, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(257.8140, device='cuda:0')\n",
      "passed  60 epoch Training Loss:  tensor(215.4891, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(275.5165, device='cuda:0')\n",
      "passed  61 epoch Training Loss:  tensor(223.8508, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(289.7461, device='cuda:0')\n",
      "passed  62 epoch Training Loss:  tensor(228.2482, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(250.5236, device='cuda:0')\n",
      "passed  63 epoch Training Loss:  tensor(218.1353, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(258.5341, device='cuda:0')\n",
      "passed  64 epoch Training Loss:  tensor(225.9487, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(260.0640, device='cuda:0')\n",
      "passed  65 epoch Training Loss:  tensor(218.0926, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(242.2196, device='cuda:0')\n",
      "passed  66 epoch Training Loss:  tensor(214.1370, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(250.8990, device='cuda:0')\n",
      "passed  67 epoch Training Loss:  tensor(227.0360, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(251.4425, device='cuda:0')\n",
      "passed  68 epoch Training Loss:  tensor(217.0502, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(239.6124, device='cuda:0')\n",
      "passed  69 epoch Training Loss:  tensor(218.1001, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(245.2391, device='cuda:0')\n",
      "passed  70 epoch Training Loss:  tensor(213.8888, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(241.1208, device='cuda:0')\n",
      "passed  71 epoch Training Loss:  tensor(219.5507, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(254.4949, device='cuda:0')\n",
      "passed  72 epoch Training Loss:  tensor(224.3706, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(256.4475, device='cuda:0')\n",
      "passed  73 epoch Training Loss:  tensor(216.6493, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(263.1719, device='cuda:0')\n",
      "passed  74 epoch Training Loss:  tensor(216.8870, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(270.8398, device='cuda:0')\n",
      "passed  75 epoch Training Loss:  tensor(218.0289, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(257.4612, device='cuda:0')\n",
      "passed  76 epoch Training Loss:  tensor(213.6095, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(308.3886, device='cuda:0')\n",
      "passed  77 epoch Training Loss:  tensor(225.6405, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(283.8923, device='cuda:0')\n",
      "passed  78 epoch Training Loss:  tensor(214.9023, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(284.7675, device='cuda:0')\n",
      "passed  79 epoch Training Loss:  tensor(219.6549, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(331.0069, device='cuda:0')\n",
      "passed  80 epoch Training Loss:  tensor(234.5625, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(442.8014, device='cuda:0')\n",
      "passed  81 epoch Training Loss:  tensor(251.3343, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(324.1831, device='cuda:0')\n",
      "passed  82 epoch Training Loss:  tensor(215.2946, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(264.4223, device='cuda:0')\n",
      "passed  83 epoch Training Loss:  tensor(205.8215, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(276.7051, device='cuda:0')\n",
      "passed  84 epoch Training Loss:  tensor(208.0903, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(236.8109, device='cuda:0')\n",
      "passed  85 epoch Training Loss:  tensor(205.1143, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(243.2264, device='cuda:0')\n",
      "passed  86 epoch Training Loss:  tensor(204.0016, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(244.1147, device='cuda:0')\n",
      "passed  87 epoch Training Loss:  tensor(199.6317, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(228.8759, device='cuda:0')\n",
      "passed  88 epoch Training Loss:  tensor(213.3361, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(246.1006, device='cuda:0')\n",
      "passed  89 epoch Training Loss:  tensor(205.2247, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(239.7753, device='cuda:0')\n",
      "passed  90 epoch Training Loss:  tensor(208.7720, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(227.8096, device='cuda:0')\n",
      "passed  91 epoch Training Loss:  tensor(206.3356, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(236.2039, device='cuda:0')\n",
      "passed  92 epoch Training Loss:  tensor(207.8675, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(252.4782, device='cuda:0')\n",
      "passed  93 epoch Training Loss:  tensor(203.8331, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(248.4419, device='cuda:0')\n",
      "passed  94 epoch Training Loss:  tensor(209.6066, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(266.2556, device='cuda:0')\n",
      "passed  95 epoch Training Loss:  tensor(208.1418, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(252.0003, device='cuda:0')\n",
      "passed  96 epoch Training Loss:  tensor(200.0931, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(295.4785, device='cuda:0')\n",
      "passed  97 epoch Training Loss:  tensor(224.0372, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(286.5604, device='cuda:0')\n",
      "passed  98 epoch Training Loss:  tensor(218.7747, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(351.7318, device='cuda:0')\n",
      "passed  99 epoch Training Loss:  tensor(226.8198, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(387.9062, device='cuda:0')\n",
      "passed  100 epoch Training Loss:  tensor(226.5828, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(300.6510, device='cuda:0')\n",
      "passed  101 epoch Training Loss:  tensor(207.0607, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(306.0287, device='cuda:0')\n",
      "passed  102 epoch Training Loss:  tensor(200.8232, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(241.3981, device='cuda:0')\n",
      "passed  103 epoch Training Loss:  tensor(200.8259, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(253.7078, device='cuda:0')\n",
      "passed  104 epoch Training Loss:  tensor(198.2293, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(253.6841, device='cuda:0')\n",
      "passed  105 epoch Training Loss:  tensor(194.0725, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(235.0354, device='cuda:0')\n",
      "passed  106 epoch Training Loss:  tensor(208.1811, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(238.5205, device='cuda:0')\n",
      "passed  107 epoch Training Loss:  tensor(200.2042, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(242.1303, device='cuda:0')\n",
      "passed  108 epoch Training Loss:  tensor(197.7801, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(233.5364, device='cuda:0')\n",
      "passed  109 epoch Training Loss:  tensor(197.4778, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(244.7310, device='cuda:0')\n",
      "passed  110 epoch Training Loss:  tensor(196.8236, device='cuda:0', grad_fn=<DivBackward0>)  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-06 22:54:33,424]\u001b[0m Trial 17 finished with value: 227.80963134765625 and parameters: {'num_layers': 3, 'out_features1': 160, 'out_features2': 120, 'dim_feedforward': 448}. Best is trial 0 with value: 223.60110473632812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(256.2593, device='cuda:0')\n",
      "num layers: 4\n",
      "outfeatures1: 160\n",
      "outfeatures2: 108\n",
      "dim_feedforward: 256\n",
      "passed  0 epoch Training Loss:  tensor(3246.4600, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(2515.8667, device='cuda:0')\n",
      "passed  1 epoch Training Loss:  tensor(1512.3806, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(654.8198, device='cuda:0')\n",
      "passed  2 epoch Training Loss:  tensor(561.6547, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(527.4077, device='cuda:0')\n",
      "passed  3 epoch Training Loss:  tensor(482.8646, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(410.0387, device='cuda:0')\n",
      "passed  4 epoch Training Loss:  tensor(434.8415, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(407.9243, device='cuda:0')\n",
      "passed  5 epoch Training Loss:  tensor(415.0546, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(381.5749, device='cuda:0')\n",
      "passed  6 epoch Training Loss:  tensor(400.0178, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(368.8491, device='cuda:0')\n",
      "passed  7 epoch Training Loss:  tensor(378.7314, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(327.6436, device='cuda:0')\n",
      "passed  8 epoch Training Loss:  tensor(360.4572, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(362.9714, device='cuda:0')\n",
      "passed  9 epoch Training Loss:  tensor(341.4892, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(326.4258, device='cuda:0')\n",
      "passed  10 epoch Training Loss:  tensor(340.1955, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(393.7856, device='cuda:0')\n",
      "passed  11 epoch Training Loss:  tensor(350.8006, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(326.6713, device='cuda:0')\n",
      "passed  12 epoch Training Loss:  tensor(327.6560, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(328.1733, device='cuda:0')\n",
      "passed  13 epoch Training Loss:  tensor(334.7994, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(311.3970, device='cuda:0')\n",
      "passed  14 epoch Training Loss:  tensor(311.8476, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(306.2523, device='cuda:0')\n",
      "passed  15 epoch Training Loss:  tensor(320.0010, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(313.3708, device='cuda:0')\n",
      "passed  16 epoch Training Loss:  tensor(314.3308, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(347.3894, device='cuda:0')\n",
      "passed  17 epoch Training Loss:  tensor(321.6947, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(349.3384, device='cuda:0')\n",
      "passed  18 epoch Training Loss:  tensor(305.3235, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(332.9966, device='cuda:0')\n",
      "passed  19 epoch Training Loss:  tensor(297.2684, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(318.8360, device='cuda:0')\n",
      "passed  20 epoch Training Loss:  tensor(310.3113, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(399.2575, device='cuda:0')\n",
      "passed  21 epoch Training Loss:  tensor(315.6102, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(397.4883, device='cuda:0')\n",
      "passed  22 epoch Training Loss:  tensor(309.3728, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(399.9505, device='cuda:0')\n",
      "passed  23 epoch Training Loss:  tensor(309.0453, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(389.7484, device='cuda:0')\n",
      "passed  24 epoch Training Loss:  tensor(286.9339, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(426.9757, device='cuda:0')\n",
      "passed  25 epoch Training Loss:  tensor(305.0460, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(382.7019, device='cuda:0')\n",
      "passed  26 epoch Training Loss:  tensor(284.4790, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(340.4375, device='cuda:0')\n",
      "passed  27 epoch Training Loss:  tensor(271.1659, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(329.3773, device='cuda:0')\n",
      "passed  28 epoch Training Loss:  tensor(264.9602, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(323.4671, device='cuda:0')\n",
      "passed  29 epoch Training Loss:  tensor(267.6104, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(439.6349, device='cuda:0')\n",
      "passed  30 epoch Training Loss:  tensor(288.4786, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(326.4835, device='cuda:0')\n",
      "passed  31 epoch Training Loss:  tensor(262.9269, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(328.7323, device='cuda:0')\n",
      "passed  32 epoch Training Loss:  tensor(256.7572, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(416.6973, device='cuda:0')\n",
      "passed  33 epoch Training Loss:  tensor(263.5032, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(327.8382, device='cuda:0')\n",
      "passed  34 epoch Training Loss:  tensor(260.3065, device='cuda:0', grad_fn=<DivBackward0>)  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-06 23:11:45,524]\u001b[0m Trial 18 finished with value: 306.2523498535156 and parameters: {'num_layers': 4, 'out_features1': 160, 'out_features2': 108, 'dim_feedforward': 256}. Best is trial 0 with value: 223.60110473632812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(322.5273, device='cuda:0')\n",
      "num layers: 3\n",
      "outfeatures1: 160\n",
      "outfeatures2: 120\n",
      "dim_feedforward: 448\n",
      "passed  0 epoch Training Loss:  tensor(3222.4497, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(2450.9431, device='cuda:0')\n",
      "passed  1 epoch Training Loss:  tensor(1443.6229, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(683.2685, device='cuda:0')\n",
      "passed  2 epoch Training Loss:  tensor(575.2747, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(547.6384, device='cuda:0')\n",
      "passed  3 epoch Training Loss:  tensor(511.1798, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(475.4823, device='cuda:0')\n",
      "passed  4 epoch Training Loss:  tensor(476.9335, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(413.8932, device='cuda:0')\n",
      "passed  5 epoch Training Loss:  tensor(429.2249, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(406.2000, device='cuda:0')\n",
      "passed  6 epoch Training Loss:  tensor(409.0249, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(411.6308, device='cuda:0')\n",
      "passed  7 epoch Training Loss:  tensor(397.7510, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(376.2761, device='cuda:0')\n",
      "passed  8 epoch Training Loss:  tensor(402.4373, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(452.3968, device='cuda:0')\n",
      "passed  9 epoch Training Loss:  tensor(380.0754, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(334.5601, device='cuda:0')\n",
      "passed  10 epoch Training Loss:  tensor(358.6670, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(321.7788, device='cuda:0')\n",
      "passed  11 epoch Training Loss:  tensor(358.0064, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(369.0268, device='cuda:0')\n",
      "passed  12 epoch Training Loss:  tensor(322.6135, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(339.8192, device='cuda:0')\n",
      "passed  13 epoch Training Loss:  tensor(332.5740, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(348.3849, device='cuda:0')\n",
      "passed  14 epoch Training Loss:  tensor(331.2192, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(314.7045, device='cuda:0')\n",
      "passed  15 epoch Training Loss:  tensor(316.0497, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(319.5927, device='cuda:0')\n",
      "passed  16 epoch Training Loss:  tensor(324.2460, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(424.0190, device='cuda:0')\n",
      "passed  17 epoch Training Loss:  tensor(325.5035, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(382.7390, device='cuda:0')\n",
      "passed  18 epoch Training Loss:  tensor(312.1541, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(353.9395, device='cuda:0')\n",
      "passed  19 epoch Training Loss:  tensor(295.0960, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(340.7947, device='cuda:0')\n",
      "passed  20 epoch Training Loss:  tensor(295.2612, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(370.9842, device='cuda:0')\n",
      "passed  21 epoch Training Loss:  tensor(304.8904, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(350.5597, device='cuda:0')\n",
      "passed  22 epoch Training Loss:  tensor(299.2394, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(366.9689, device='cuda:0')\n",
      "passed  23 epoch Training Loss:  tensor(292.2632, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(432.2097, device='cuda:0')\n",
      "passed  24 epoch Training Loss:  tensor(307.8584, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(366.0877, device='cuda:0')\n",
      "passed  25 epoch Training Loss:  tensor(289.4200, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(395.4800, device='cuda:0')\n",
      "passed  26 epoch Training Loss:  tensor(282.6291, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(358.7601, device='cuda:0')\n",
      "passed  27 epoch Training Loss:  tensor(284.1324, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(440.9418, device='cuda:0')\n",
      "passed  28 epoch Training Loss:  tensor(296.9399, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(396.4547, device='cuda:0')\n",
      "passed  29 epoch Training Loss:  tensor(276.9182, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(379.2465, device='cuda:0')\n",
      "passed  30 epoch Training Loss:  tensor(269.6996, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(408.9286, device='cuda:0')\n",
      "passed  31 epoch Training Loss:  tensor(268.8255, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(333.5421, device='cuda:0')\n",
      "passed  32 epoch Training Loss:  tensor(260.9457, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(316.2235, device='cuda:0')\n",
      "passed  33 epoch Training Loss:  tensor(257.1523, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(342.9353, device='cuda:0')\n",
      "passed  34 epoch Training Loss:  tensor(253.2979, device='cuda:0', grad_fn=<DivBackward0>)  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-06 23:28:56,334]\u001b[0m Trial 19 finished with value: 314.70452880859375 and parameters: {'num_layers': 3, 'out_features1': 160, 'out_features2': 120, 'dim_feedforward': 448}. Best is trial 0 with value: 223.60110473632812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(316.0623, device='cuda:0')\n",
      "num layers: 2\n",
      "outfeatures1: 160\n",
      "outfeatures2: 108\n",
      "dim_feedforward: 448\n",
      "passed  0 epoch Training Loss:  tensor(3225.8147, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(2453.6970, device='cuda:0')\n",
      "passed  1 epoch Training Loss:  tensor(1427.0858, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(578.6613, device='cuda:0')\n",
      "passed  2 epoch Training Loss:  tensor(462.9990, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(384.9135, device='cuda:0')\n",
      "passed  3 epoch Training Loss:  tensor(424.5481, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(406.6516, device='cuda:0')\n",
      "passed  4 epoch Training Loss:  tensor(426.0122, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(388.1003, device='cuda:0')\n",
      "passed  5 epoch Training Loss:  tensor(396.0174, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(358.0610, device='cuda:0')\n",
      "passed  6 epoch Training Loss:  tensor(381.4206, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(328.0825, device='cuda:0')\n",
      "passed  7 epoch Training Loss:  tensor(368.6652, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(341.8461, device='cuda:0')\n",
      "passed  8 epoch Training Loss:  tensor(350.4757, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(359.7760, device='cuda:0')\n",
      "passed  9 epoch Training Loss:  tensor(337.0067, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(405.8732, device='cuda:0')\n",
      "passed  10 epoch Training Loss:  tensor(333.5637, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(360.2817, device='cuda:0')\n",
      "passed  11 epoch Training Loss:  tensor(332.1462, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(370.5242, device='cuda:0')\n",
      "passed  12 epoch Training Loss:  tensor(329.2287, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(382.9952, device='cuda:0')\n",
      "passed  13 epoch Training Loss:  tensor(323.4144, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(416.0027, device='cuda:0')\n",
      "passed  14 epoch Training Loss:  tensor(320.3275, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(418.8952, device='cuda:0')\n",
      "passed  15 epoch Training Loss:  tensor(319.2836, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(427.7124, device='cuda:0')\n",
      "passed  16 epoch Training Loss:  tensor(320.0352, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(470.5928, device='cuda:0')\n",
      "passed  17 epoch Training Loss:  tensor(314.2871, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(470.0626, device='cuda:0')\n",
      "passed  18 epoch Training Loss:  tensor(320.1757, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(388.0656, device='cuda:0')\n",
      "passed  19 epoch Training Loss:  tensor(306.8459, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(366.7900, device='cuda:0')\n",
      "passed  20 epoch Training Loss:  tensor(294.1253, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(334.4296, device='cuda:0')\n",
      "passed  21 epoch Training Loss:  tensor(285.0879, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(354.0693, device='cuda:0')\n",
      "passed  22 epoch Training Loss:  tensor(277.3849, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(397.3039, device='cuda:0')\n",
      "passed  23 epoch Training Loss:  tensor(287.1385, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(337.2069, device='cuda:0')\n",
      "passed  24 epoch Training Loss:  tensor(263.5880, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(389.6406, device='cuda:0')\n",
      "passed  25 epoch Training Loss:  tensor(266.5573, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(391.5251, device='cuda:0')\n",
      "passed  26 epoch Training Loss:  tensor(265.5305, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(311.9114, device='cuda:0')\n",
      "passed  27 epoch Training Loss:  tensor(258.9347, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(415.8021, device='cuda:0')\n",
      "passed  28 epoch Training Loss:  tensor(269.9220, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(402.1696, device='cuda:0')\n",
      "passed  29 epoch Training Loss:  tensor(277.2008, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(369.0815, device='cuda:0')\n",
      "passed  30 epoch Training Loss:  tensor(245.2235, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(340.9992, device='cuda:0')\n",
      "passed  31 epoch Training Loss:  tensor(246.3575, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(403.6669, device='cuda:0')\n",
      "passed  32 epoch Training Loss:  tensor(249.4606, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(300.3810, device='cuda:0')\n",
      "passed  33 epoch Training Loss:  tensor(239.8027, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(335.2974, device='cuda:0')\n",
      "passed  34 epoch Training Loss:  tensor(234.3331, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(302.7840, device='cuda:0')\n",
      "passed  35 epoch Training Loss:  tensor(246.2282, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(423.3163, device='cuda:0')\n",
      "passed  36 epoch Training Loss:  tensor(243.6401, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(387.0350, device='cuda:0')\n",
      "passed  37 epoch Training Loss:  tensor(251.2511, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(401.4730, device='cuda:0')\n",
      "passed  38 epoch Training Loss:  tensor(238.8144, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(289.1527, device='cuda:0')\n",
      "passed  39 epoch Training Loss:  tensor(238.1412, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(307.4088, device='cuda:0')\n",
      "passed  40 epoch Training Loss:  tensor(231.5421, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(287.4562, device='cuda:0')\n",
      "passed  41 epoch Training Loss:  tensor(229.3871, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(309.5862, device='cuda:0')\n",
      "passed  42 epoch Training Loss:  tensor(226.3185, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(290.9160, device='cuda:0')\n",
      "passed  43 epoch Training Loss:  tensor(225.8727, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(276.8605, device='cuda:0')\n",
      "passed  44 epoch Training Loss:  tensor(225.6560, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(319.3791, device='cuda:0')\n",
      "passed  45 epoch Training Loss:  tensor(225.8793, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(257.0024, device='cuda:0')\n",
      "passed  46 epoch Training Loss:  tensor(256.3842, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(270.7583, device='cuda:0')\n",
      "passed  47 epoch Training Loss:  tensor(244.8848, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(255.6001, device='cuda:0')\n",
      "passed  48 epoch Training Loss:  tensor(253.1563, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(259.2752, device='cuda:0')\n",
      "passed  49 epoch Training Loss:  tensor(260.1331, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(258.7440, device='cuda:0')\n",
      "passed  50 epoch Training Loss:  tensor(240.9693, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(250.7853, device='cuda:0')\n",
      "passed  51 epoch Training Loss:  tensor(227.2464, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(250.1342, device='cuda:0')\n",
      "passed  52 epoch Training Loss:  tensor(219.2155, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(258.1033, device='cuda:0')\n",
      "passed  53 epoch Training Loss:  tensor(211.9860, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(264.9251, device='cuda:0')\n",
      "passed  54 epoch Training Loss:  tensor(210.9468, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(250.7377, device='cuda:0')\n",
      "passed  55 epoch Training Loss:  tensor(217.2521, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(248.0175, device='cuda:0')\n",
      "passed  56 epoch Training Loss:  tensor(214.1392, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(257.3205, device='cuda:0')\n",
      "passed  57 epoch Training Loss:  tensor(210.5317, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(252.4187, device='cuda:0')\n",
      "passed  58 epoch Training Loss:  tensor(211.7633, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(274.1578, device='cuda:0')\n",
      "passed  59 epoch Training Loss:  tensor(217.2369, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(265.9025, device='cuda:0')\n",
      "passed  60 epoch Training Loss:  tensor(205.7492, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(236.7110, device='cuda:0')\n",
      "passed  61 epoch Training Loss:  tensor(222.0966, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(245.3012, device='cuda:0')\n",
      "passed  62 epoch Training Loss:  tensor(211.0091, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(251.7263, device='cuda:0')\n",
      "passed  63 epoch Training Loss:  tensor(213.6488, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(241.1059, device='cuda:0')\n",
      "passed  64 epoch Training Loss:  tensor(215.4532, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(247.4172, device='cuda:0')\n",
      "passed  65 epoch Training Loss:  tensor(208.6212, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(249.6927, device='cuda:0')\n",
      "passed  66 epoch Training Loss:  tensor(208.7506, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(258.9441, device='cuda:0')\n",
      "passed  67 epoch Training Loss:  tensor(210.0500, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(246.8419, device='cuda:0')\n",
      "passed  68 epoch Training Loss:  tensor(201.0831, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(251.8207, device='cuda:0')\n",
      "passed  69 epoch Training Loss:  tensor(206.1282, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(248.4295, device='cuda:0')\n",
      "passed  70 epoch Training Loss:  tensor(216.9508, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(268.3182, device='cuda:0')\n",
      "passed  71 epoch Training Loss:  tensor(228.9255, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(249.2684, device='cuda:0')\n",
      "passed  72 epoch Training Loss:  tensor(210.1918, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(286.1451, device='cuda:0')\n",
      "passed  73 epoch Training Loss:  tensor(209.2678, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(276.3341, device='cuda:0')\n",
      "passed  74 epoch Training Loss:  tensor(204.7159, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(293.2442, device='cuda:0')\n",
      "passed  75 epoch Training Loss:  tensor(211.0079, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(278.4394, device='cuda:0')\n",
      "passed  76 epoch Training Loss:  tensor(202.9595, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(367.8639, device='cuda:0')\n",
      "passed  77 epoch Training Loss:  tensor(232.8769, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(291.1246, device='cuda:0')\n",
      "passed  78 epoch Training Loss:  tensor(202.4844, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(282.1728, device='cuda:0')\n",
      "passed  79 epoch Training Loss:  tensor(200.1893, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(297.2036, device='cuda:0')\n",
      "passed  80 epoch Training Loss:  tensor(200.2837, device='cuda:0', grad_fn=<DivBackward0>)  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-07 00:08:48,942]\u001b[0m Trial 20 finished with value: 236.7110137939453 and parameters: {'num_layers': 2, 'out_features1': 160, 'out_features2': 108, 'dim_feedforward': 448}. Best is trial 0 with value: 223.60110473632812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(322.1401, device='cuda:0')\n",
      "num layers: 3\n",
      "outfeatures1: 160\n",
      "outfeatures2: 120\n",
      "dim_feedforward: 384\n",
      "passed  0 epoch Training Loss:  tensor(3233.7288, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(2479.8870, device='cuda:0')\n",
      "passed  1 epoch Training Loss:  tensor(1467.0626, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(651.9709, device='cuda:0')\n",
      "passed  2 epoch Training Loss:  tensor(534.4026, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(473.9236, device='cuda:0')\n",
      "passed  3 epoch Training Loss:  tensor(462.5826, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(398.5106, device='cuda:0')\n",
      "passed  4 epoch Training Loss:  tensor(417.9892, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(389.2248, device='cuda:0')\n",
      "passed  5 epoch Training Loss:  tensor(398.4745, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(357.4321, device='cuda:0')\n",
      "passed  6 epoch Training Loss:  tensor(380.1193, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(349.9110, device='cuda:0')\n",
      "passed  7 epoch Training Loss:  tensor(367.3370, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(321.9527, device='cuda:0')\n",
      "passed  8 epoch Training Loss:  tensor(357.9772, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(329.3321, device='cuda:0')\n",
      "passed  9 epoch Training Loss:  tensor(360.7825, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(400.3539, device='cuda:0')\n",
      "passed  10 epoch Training Loss:  tensor(332.6294, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(346.4129, device='cuda:0')\n",
      "passed  11 epoch Training Loss:  tensor(345.4983, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(353.5198, device='cuda:0')\n",
      "passed  12 epoch Training Loss:  tensor(326.3821, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(378.8607, device='cuda:0')\n",
      "passed  13 epoch Training Loss:  tensor(319.9737, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(375.5431, device='cuda:0')\n",
      "passed  14 epoch Training Loss:  tensor(311.8882, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(403.9806, device='cuda:0')\n",
      "passed  15 epoch Training Loss:  tensor(317.5393, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(388.7391, device='cuda:0')\n",
      "passed  16 epoch Training Loss:  tensor(308.1103, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(401.2765, device='cuda:0')\n",
      "passed  17 epoch Training Loss:  tensor(307.6977, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(387.6387, device='cuda:0')\n",
      "passed  18 epoch Training Loss:  tensor(297.2570, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(347.5700, device='cuda:0')\n",
      "passed  19 epoch Training Loss:  tensor(288.9203, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(360.4705, device='cuda:0')\n",
      "passed  20 epoch Training Loss:  tensor(286.3120, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(369.9841, device='cuda:0')\n",
      "passed  21 epoch Training Loss:  tensor(301.2051, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(318.8548, device='cuda:0')\n",
      "passed  22 epoch Training Loss:  tensor(287.2194, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(374.8823, device='cuda:0')\n",
      "passed  23 epoch Training Loss:  tensor(277.4131, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(444.0329, device='cuda:0')\n",
      "passed  24 epoch Training Loss:  tensor(285.6989, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(344.6654, device='cuda:0')\n",
      "passed  25 epoch Training Loss:  tensor(267.5806, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(328.7697, device='cuda:0')\n",
      "passed  26 epoch Training Loss:  tensor(265.0121, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(401.4202, device='cuda:0')\n",
      "passed  27 epoch Training Loss:  tensor(270.1845, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(335.0314, device='cuda:0')\n",
      "passed  28 epoch Training Loss:  tensor(272.3712, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(314.1174, device='cuda:0')\n",
      "passed  29 epoch Training Loss:  tensor(250.3741, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(355.8228, device='cuda:0')\n",
      "passed  30 epoch Training Loss:  tensor(248.1967, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(317.4401, device='cuda:0')\n",
      "passed  31 epoch Training Loss:  tensor(256.2431, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(360.5167, device='cuda:0')\n",
      "passed  32 epoch Training Loss:  tensor(253.4268, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(273.0581, device='cuda:0')\n",
      "passed  33 epoch Training Loss:  tensor(246.4060, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(354.1304, device='cuda:0')\n",
      "passed  34 epoch Training Loss:  tensor(257.8632, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(340.9686, device='cuda:0')\n",
      "passed  35 epoch Training Loss:  tensor(234.9247, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(299.3028, device='cuda:0')\n",
      "passed  36 epoch Training Loss:  tensor(242.6348, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(262.6039, device='cuda:0')\n",
      "passed  37 epoch Training Loss:  tensor(243.3637, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(302.3705, device='cuda:0')\n",
      "passed  38 epoch Training Loss:  tensor(237.2119, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(345.8042, device='cuda:0')\n",
      "passed  39 epoch Training Loss:  tensor(236.5108, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(330.7128, device='cuda:0')\n",
      "passed  40 epoch Training Loss:  tensor(231.6065, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(266.3010, device='cuda:0')\n",
      "passed  41 epoch Training Loss:  tensor(242.7576, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(261.2097, device='cuda:0')\n",
      "passed  42 epoch Training Loss:  tensor(258.2567, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(274.3558, device='cuda:0')\n",
      "passed  43 epoch Training Loss:  tensor(250.0643, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(281.1133, device='cuda:0')\n",
      "passed  44 epoch Training Loss:  tensor(262.2399, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(265.6801, device='cuda:0')\n",
      "passed  45 epoch Training Loss:  tensor(255.5592, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(256.9058, device='cuda:0')\n",
      "passed  46 epoch Training Loss:  tensor(240.4284, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(250.2139, device='cuda:0')\n",
      "passed  47 epoch Training Loss:  tensor(229.4753, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(270.8633, device='cuda:0')\n",
      "passed  48 epoch Training Loss:  tensor(220.8786, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(256.6879, device='cuda:0')\n",
      "passed  49 epoch Training Loss:  tensor(222.6779, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(269.4444, device='cuda:0')\n",
      "passed  50 epoch Training Loss:  tensor(213.8929, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(244.6711, device='cuda:0')\n",
      "passed  51 epoch Training Loss:  tensor(221.3530, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(248.6724, device='cuda:0')\n",
      "passed  52 epoch Training Loss:  tensor(220.5794, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(242.5813, device='cuda:0')\n",
      "passed  53 epoch Training Loss:  tensor(218.9969, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(244.9523, device='cuda:0')\n",
      "passed  54 epoch Training Loss:  tensor(216.8977, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(239.1346, device='cuda:0')\n",
      "passed  55 epoch Training Loss:  tensor(220.1789, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(248.6219, device='cuda:0')\n",
      "passed  56 epoch Training Loss:  tensor(219.7817, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(243.4535, device='cuda:0')\n",
      "passed  57 epoch Training Loss:  tensor(228.1134, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(261.4897, device='cuda:0')\n",
      "passed  58 epoch Training Loss:  tensor(244.7772, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(267.5007, device='cuda:0')\n",
      "passed  59 epoch Training Loss:  tensor(235.2130, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(250.7898, device='cuda:0')\n",
      "passed  60 epoch Training Loss:  tensor(219.4900, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(254.5108, device='cuda:0')\n",
      "passed  61 epoch Training Loss:  tensor(213.2072, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(272.8009, device='cuda:0')\n",
      "passed  62 epoch Training Loss:  tensor(213.7434, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(269.9398, device='cuda:0')\n",
      "passed  63 epoch Training Loss:  tensor(204.0702, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(277.7656, device='cuda:0')\n",
      "passed  64 epoch Training Loss:  tensor(213.1175, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(249.4731, device='cuda:0')\n",
      "passed  65 epoch Training Loss:  tensor(205.2853, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(338.3206, device='cuda:0')\n",
      "passed  66 epoch Training Loss:  tensor(221.1139, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(253.8484, device='cuda:0')\n",
      "passed  67 epoch Training Loss:  tensor(216.3479, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(259.4792, device='cuda:0')\n",
      "passed  68 epoch Training Loss:  tensor(205.4355, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(247.4943, device='cuda:0')\n",
      "passed  69 epoch Training Loss:  tensor(203.5335, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(253.9560, device='cuda:0')\n",
      "passed  70 epoch Training Loss:  tensor(208.6475, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(273.6344, device='cuda:0')\n",
      "passed  71 epoch Training Loss:  tensor(208.9000, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(255.5148, device='cuda:0')\n",
      "passed  72 epoch Training Loss:  tensor(202.9451, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(270.0889, device='cuda:0')\n",
      "passed  73 epoch Training Loss:  tensor(204.8184, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(281.3436, device='cuda:0')\n",
      "passed  74 epoch Training Loss:  tensor(202.2073, device='cuda:0', grad_fn=<DivBackward0>)  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-07 00:45:57,304]\u001b[0m Trial 21 finished with value: 239.13455200195312 and parameters: {'num_layers': 3, 'out_features1': 160, 'out_features2': 120, 'dim_feedforward': 384}. Best is trial 0 with value: 223.60110473632812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(249.8589, device='cuda:0')\n",
      "num layers: 4\n",
      "outfeatures1: 160\n",
      "outfeatures2: 120\n",
      "dim_feedforward: 512\n",
      "passed  0 epoch Training Loss:  tensor(3226.7600, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(2463.9412, device='cuda:0')\n",
      "passed  1 epoch Training Loss:  tensor(1450.0054, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(647.7532, device='cuda:0')\n",
      "passed  2 epoch Training Loss:  tensor(611.0958, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(567.6970, device='cuda:0')\n",
      "passed  3 epoch Training Loss:  tensor(615.7273, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(565.3384, device='cuda:0')\n",
      "passed  4 epoch Training Loss:  tensor(606.1182, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(521.9608, device='cuda:0')\n",
      "passed  5 epoch Training Loss:  tensor(514.3823, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(424.8448, device='cuda:0')\n",
      "passed  6 epoch Training Loss:  tensor(431.2580, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(385.0140, device='cuda:0')\n",
      "passed  7 epoch Training Loss:  tensor(413.1984, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(377.0724, device='cuda:0')\n",
      "passed  8 epoch Training Loss:  tensor(415.4391, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(383.2215, device='cuda:0')\n",
      "passed  9 epoch Training Loss:  tensor(407.7976, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(347.2428, device='cuda:0')\n",
      "passed  10 epoch Training Loss:  tensor(385.1845, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(352.8118, device='cuda:0')\n",
      "passed  11 epoch Training Loss:  tensor(363.0051, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(374.9222, device='cuda:0')\n",
      "passed  12 epoch Training Loss:  tensor(367.6196, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(445.7160, device='cuda:0')\n",
      "passed  13 epoch Training Loss:  tensor(350.6426, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(427.3694, device='cuda:0')\n",
      "passed  14 epoch Training Loss:  tensor(379.1808, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(393.6270, device='cuda:0')\n",
      "passed  15 epoch Training Loss:  tensor(355.9218, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(368.5056, device='cuda:0')\n",
      "passed  16 epoch Training Loss:  tensor(339.6019, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(341.0152, device='cuda:0')\n",
      "passed  17 epoch Training Loss:  tensor(323.2139, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(366.2097, device='cuda:0')\n",
      "passed  18 epoch Training Loss:  tensor(326.4814, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(343.8595, device='cuda:0')\n",
      "passed  19 epoch Training Loss:  tensor(319.4336, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(367.5473, device='cuda:0')\n",
      "passed  20 epoch Training Loss:  tensor(318.3034, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(354.6858, device='cuda:0')\n",
      "passed  21 epoch Training Loss:  tensor(306.8737, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(384.2185, device='cuda:0')\n",
      "passed  22 epoch Training Loss:  tensor(326.6643, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(413.2772, device='cuda:0')\n",
      "passed  23 epoch Training Loss:  tensor(316.0153, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(423.0947, device='cuda:0')\n",
      "passed  24 epoch Training Loss:  tensor(320.6764, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(384.1118, device='cuda:0')\n",
      "passed  25 epoch Training Loss:  tensor(313.9906, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(418.6215, device='cuda:0')\n",
      "passed  26 epoch Training Loss:  tensor(301.4191, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(376.4151, device='cuda:0')\n",
      "passed  27 epoch Training Loss:  tensor(291.7117, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(380.4724, device='cuda:0')\n",
      "passed  28 epoch Training Loss:  tensor(283.6422, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(383.8729, device='cuda:0')\n",
      "passed  29 epoch Training Loss:  tensor(280.1745, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(368.7466, device='cuda:0')\n",
      "passed  30 epoch Training Loss:  tensor(276.4096, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(367.8636, device='cuda:0')\n",
      "passed  31 epoch Training Loss:  tensor(271.3413, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(380.6349, device='cuda:0')\n",
      "passed  32 epoch Training Loss:  tensor(269.5958, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(386.0421, device='cuda:0')\n",
      "passed  33 epoch Training Loss:  tensor(274.6277, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(377.0299, device='cuda:0')\n",
      "passed  34 epoch Training Loss:  tensor(263.8809, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(322.0589, device='cuda:0')\n",
      "passed  35 epoch Training Loss:  tensor(257.9951, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(398.7781, device='cuda:0')\n",
      "passed  36 epoch Training Loss:  tensor(261.8494, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(354.3420, device='cuda:0')\n",
      "passed  37 epoch Training Loss:  tensor(259.0880, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(307.7204, device='cuda:0')\n",
      "passed  38 epoch Training Loss:  tensor(257.5851, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(324.5835, device='cuda:0')\n",
      "passed  39 epoch Training Loss:  tensor(256.6127, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(364.5972, device='cuda:0')\n",
      "passed  40 epoch Training Loss:  tensor(255.7205, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(313.1971, device='cuda:0')\n",
      "passed  41 epoch Training Loss:  tensor(246.9722, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(284.9794, device='cuda:0')\n",
      "passed  42 epoch Training Loss:  tensor(261.3759, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(275.7143, device='cuda:0')\n",
      "passed  43 epoch Training Loss:  tensor(260.2358, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(264.9770, device='cuda:0')\n",
      "passed  44 epoch Training Loss:  tensor(282.2206, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(288.3433, device='cuda:0')\n",
      "passed  45 epoch Training Loss:  tensor(276.4531, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(277.5581, device='cuda:0')\n",
      "passed  46 epoch Training Loss:  tensor(255.3421, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(280.7363, device='cuda:0')\n",
      "passed  47 epoch Training Loss:  tensor(249.7775, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(267.0787, device='cuda:0')\n",
      "passed  48 epoch Training Loss:  tensor(242.9270, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(272.3322, device='cuda:0')\n",
      "passed  49 epoch Training Loss:  tensor(246.6598, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(264.9782, device='cuda:0')\n",
      "passed  50 epoch Training Loss:  tensor(241.6717, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(264.6426, device='cuda:0')\n",
      "passed  51 epoch Training Loss:  tensor(243.5001, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(262.2580, device='cuda:0')\n",
      "passed  52 epoch Training Loss:  tensor(234.4259, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(272.8288, device='cuda:0')\n",
      "passed  53 epoch Training Loss:  tensor(243.4894, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(263.7954, device='cuda:0')\n",
      "passed  54 epoch Training Loss:  tensor(232.3947, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(263.1698, device='cuda:0')\n",
      "passed  55 epoch Training Loss:  tensor(229.7149, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(260.0193, device='cuda:0')\n",
      "passed  56 epoch Training Loss:  tensor(226.8759, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(266.6297, device='cuda:0')\n",
      "passed  57 epoch Training Loss:  tensor(224.3951, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(260.6292, device='cuda:0')\n",
      "passed  58 epoch Training Loss:  tensor(233.3542, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(269.3600, device='cuda:0')\n",
      "passed  59 epoch Training Loss:  tensor(236.6777, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(324.6707, device='cuda:0')\n",
      "passed  60 epoch Training Loss:  tensor(237.1388, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(249.4438, device='cuda:0')\n",
      "passed  61 epoch Training Loss:  tensor(221.3770, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(266.4501, device='cuda:0')\n",
      "passed  62 epoch Training Loss:  tensor(238.1670, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(269.1008, device='cuda:0')\n",
      "passed  63 epoch Training Loss:  tensor(225.9678, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(260.8315, device='cuda:0')\n",
      "passed  64 epoch Training Loss:  tensor(226.0018, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(277.1818, device='cuda:0')\n",
      "passed  65 epoch Training Loss:  tensor(235.0574, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(271.0486, device='cuda:0')\n",
      "passed  66 epoch Training Loss:  tensor(225.5116, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(249.1224, device='cuda:0')\n",
      "passed  67 epoch Training Loss:  tensor(222.3814, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(259.2458, device='cuda:0')\n",
      "passed  68 epoch Training Loss:  tensor(225.1988, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(268.7537, device='cuda:0')\n",
      "passed  69 epoch Training Loss:  tensor(213.8859, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(256.2364, device='cuda:0')\n",
      "passed  70 epoch Training Loss:  tensor(217.4353, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(257.3329, device='cuda:0')\n",
      "passed  71 epoch Training Loss:  tensor(217.0619, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(252.3647, device='cuda:0')\n",
      "passed  72 epoch Training Loss:  tensor(227.7321, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(244.5993, device='cuda:0')\n",
      "passed  73 epoch Training Loss:  tensor(214.1088, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(251.0753, device='cuda:0')\n",
      "passed  74 epoch Training Loss:  tensor(218.8041, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(261.6623, device='cuda:0')\n",
      "passed  75 epoch Training Loss:  tensor(218.1379, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(241.3251, device='cuda:0')\n",
      "passed  76 epoch Training Loss:  tensor(223.4348, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(239.7142, device='cuda:0')\n",
      "passed  77 epoch Training Loss:  tensor(218.6029, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(237.9504, device='cuda:0')\n",
      "passed  78 epoch Training Loss:  tensor(223.0497, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(237.4836, device='cuda:0')\n",
      "passed  79 epoch Training Loss:  tensor(224.7963, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(263.2958, device='cuda:0')\n",
      "passed  80 epoch Training Loss:  tensor(233.9411, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(250.3219, device='cuda:0')\n",
      "passed  81 epoch Training Loss:  tensor(225.9910, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(245.2248, device='cuda:0')\n",
      "passed  82 epoch Training Loss:  tensor(217.3147, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(254.3340, device='cuda:0')\n",
      "passed  83 epoch Training Loss:  tensor(220.6380, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(237.1601, device='cuda:0')\n",
      "passed  84 epoch Training Loss:  tensor(213.7175, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(241.7260, device='cuda:0')\n",
      "passed  85 epoch Training Loss:  tensor(231.0873, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(243.9941, device='cuda:0')\n",
      "passed  86 epoch Training Loss:  tensor(226.5278, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(256.2505, device='cuda:0')\n",
      "passed  87 epoch Training Loss:  tensor(217.3298, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(272.6643, device='cuda:0')\n",
      "passed  88 epoch Training Loss:  tensor(224.4769, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(277.5774, device='cuda:0')\n",
      "passed  89 epoch Training Loss:  tensor(214.6153, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(323.8173, device='cuda:0')\n",
      "passed  90 epoch Training Loss:  tensor(239.3007, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(369.7055, device='cuda:0')\n",
      "passed  91 epoch Training Loss:  tensor(229.9678, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(319.0391, device='cuda:0')\n",
      "passed  92 epoch Training Loss:  tensor(216.6109, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(307.8425, device='cuda:0')\n",
      "passed  93 epoch Training Loss:  tensor(209.6240, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(282.0255, device='cuda:0')\n",
      "passed  94 epoch Training Loss:  tensor(207.8797, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(316.9057, device='cuda:0')\n",
      "passed  95 epoch Training Loss:  tensor(210.9193, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(275.8766, device='cuda:0')\n",
      "passed  96 epoch Training Loss:  tensor(201.6322, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(281.2253, device='cuda:0')\n",
      "passed  97 epoch Training Loss:  tensor(216.0567, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(290.9482, device='cuda:0')\n",
      "passed  98 epoch Training Loss:  tensor(209.6847, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(255.9177, device='cuda:0')\n",
      "passed  99 epoch Training Loss:  tensor(202.6136, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(303.4462, device='cuda:0')\n",
      "passed  100 epoch Training Loss:  tensor(211.3161, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(287.3282, device='cuda:0')\n",
      "passed  101 epoch Training Loss:  tensor(207.5214, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(279.2719, device='cuda:0')\n",
      "passed  102 epoch Training Loss:  tensor(197.6326, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(280.7074, device='cuda:0')\n",
      "passed  103 epoch Training Loss:  tensor(208.7099, device='cuda:0', grad_fn=<DivBackward0>)  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-07 01:37:30,043]\u001b[0m Trial 22 finished with value: 237.1601104736328 and parameters: {'num_layers': 4, 'out_features1': 160, 'out_features2': 120, 'dim_feedforward': 512}. Best is trial 0 with value: 223.60110473632812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(310.3752, device='cuda:0')\n",
      "num layers: 3\n",
      "outfeatures1: 140\n",
      "outfeatures2: 108\n",
      "dim_feedforward: 448\n",
      "passed  0 epoch Training Loss:  tensor(3230.8433, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(2472.3445, device='cuda:0')\n",
      "passed  1 epoch Training Loss:  tensor(1447.7313, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(626.6046, device='cuda:0')\n",
      "passed  2 epoch Training Loss:  tensor(478.2978, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(398.7943, device='cuda:0')\n",
      "passed  3 epoch Training Loss:  tensor(418.0992, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(360.7270, device='cuda:0')\n",
      "passed  4 epoch Training Loss:  tensor(414.9508, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(364.7068, device='cuda:0')\n",
      "passed  5 epoch Training Loss:  tensor(396.7456, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(351.2882, device='cuda:0')\n",
      "passed  6 epoch Training Loss:  tensor(379.6991, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(357.4174, device='cuda:0')\n",
      "passed  7 epoch Training Loss:  tensor(356.8916, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(379.9736, device='cuda:0')\n",
      "passed  8 epoch Training Loss:  tensor(334.1819, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(395.0377, device='cuda:0')\n",
      "passed  9 epoch Training Loss:  tensor(351.2383, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(327.7258, device='cuda:0')\n",
      "passed  10 epoch Training Loss:  tensor(314.9281, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(356.9111, device='cuda:0')\n",
      "passed  11 epoch Training Loss:  tensor(325.9964, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(329.1635, device='cuda:0')\n",
      "passed  12 epoch Training Loss:  tensor(330.3777, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(362.8673, device='cuda:0')\n",
      "passed  13 epoch Training Loss:  tensor(307.3106, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(321.3361, device='cuda:0')\n",
      "passed  14 epoch Training Loss:  tensor(315.1791, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(359.6316, device='cuda:0')\n",
      "passed  15 epoch Training Loss:  tensor(313.2785, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(344.8108, device='cuda:0')\n",
      "passed  16 epoch Training Loss:  tensor(303.3469, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(342.7893, device='cuda:0')\n",
      "passed  17 epoch Training Loss:  tensor(304.7522, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(415.3312, device='cuda:0')\n",
      "passed  18 epoch Training Loss:  tensor(315.4908, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(378.8077, device='cuda:0')\n",
      "passed  19 epoch Training Loss:  tensor(286.3656, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(362.4221, device='cuda:0')\n",
      "passed  20 epoch Training Loss:  tensor(285.4661, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(342.1207, device='cuda:0')\n",
      "passed  21 epoch Training Loss:  tensor(275.0211, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(352.7338, device='cuda:0')\n",
      "passed  22 epoch Training Loss:  tensor(270.3998, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(352.7167, device='cuda:0')\n",
      "passed  23 epoch Training Loss:  tensor(274.1949, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(471.9248, device='cuda:0')\n",
      "passed  24 epoch Training Loss:  tensor(287.5409, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(342.9263, device='cuda:0')\n",
      "passed  25 epoch Training Loss:  tensor(264.0544, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(408.3729, device='cuda:0')\n",
      "passed  26 epoch Training Loss:  tensor(269.1522, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(380.4378, device='cuda:0')\n",
      "passed  27 epoch Training Loss:  tensor(264.8229, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(312.3010, device='cuda:0')\n",
      "passed  28 epoch Training Loss:  tensor(262.1374, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(363.3153, device='cuda:0')\n",
      "passed  29 epoch Training Loss:  tensor(266.3448, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(377.2164, device='cuda:0')\n",
      "passed  30 epoch Training Loss:  tensor(258.9632, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(325.3352, device='cuda:0')\n",
      "passed  31 epoch Training Loss:  tensor(259.4500, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(313.2049, device='cuda:0')\n",
      "passed  32 epoch Training Loss:  tensor(254.0039, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(274.7283, device='cuda:0')\n",
      "passed  33 epoch Training Loss:  tensor(267.5609, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(279.5269, device='cuda:0')\n",
      "passed  34 epoch Training Loss:  tensor(276.8979, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(279.0707, device='cuda:0')\n",
      "passed  35 epoch Training Loss:  tensor(267.2395, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(268.9052, device='cuda:0')\n",
      "passed  36 epoch Training Loss:  tensor(251.1270, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(270.6767, device='cuda:0')\n",
      "passed  37 epoch Training Loss:  tensor(238.2456, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(260.4364, device='cuda:0')\n",
      "passed  38 epoch Training Loss:  tensor(242.3921, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(262.4356, device='cuda:0')\n",
      "passed  39 epoch Training Loss:  tensor(238.7557, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(254.6434, device='cuda:0')\n",
      "passed  40 epoch Training Loss:  tensor(237.5703, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(245.1196, device='cuda:0')\n",
      "passed  41 epoch Training Loss:  tensor(238.0298, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(261.3080, device='cuda:0')\n",
      "passed  42 epoch Training Loss:  tensor(250.9213, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(259.7106, device='cuda:0')\n",
      "passed  43 epoch Training Loss:  tensor(247.8198, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(275.2061, device='cuda:0')\n",
      "passed  44 epoch Training Loss:  tensor(253.0897, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(264.6972, device='cuda:0')\n",
      "passed  45 epoch Training Loss:  tensor(255.6560, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(278.8088, device='cuda:0')\n",
      "passed  46 epoch Training Loss:  tensor(231.2381, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(272.4563, device='cuda:0')\n",
      "passed  47 epoch Training Loss:  tensor(228.8190, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(264.3913, device='cuda:0')\n",
      "passed  48 epoch Training Loss:  tensor(219.0184, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(258.7451, device='cuda:0')\n",
      "passed  49 epoch Training Loss:  tensor(224.9526, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(268.2505, device='cuda:0')\n",
      "passed  50 epoch Training Loss:  tensor(229.5193, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(292.0140, device='cuda:0')\n",
      "passed  51 epoch Training Loss:  tensor(230.1886, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(270.2146, device='cuda:0')\n",
      "passed  52 epoch Training Loss:  tensor(215.7693, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(311.3257, device='cuda:0')\n",
      "passed  53 epoch Training Loss:  tensor(219.3447, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(261.1589, device='cuda:0')\n",
      "passed  54 epoch Training Loss:  tensor(222.2433, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(290.8088, device='cuda:0')\n",
      "passed  55 epoch Training Loss:  tensor(223.1461, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(276.7540, device='cuda:0')\n",
      "passed  56 epoch Training Loss:  tensor(212.9774, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(262.1836, device='cuda:0')\n",
      "passed  57 epoch Training Loss:  tensor(217.9783, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(266.8005, device='cuda:0')\n",
      "passed  58 epoch Training Loss:  tensor(227.8683, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(308.8723, device='cuda:0')\n",
      "passed  59 epoch Training Loss:  tensor(214.7393, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(279.5056, device='cuda:0')\n",
      "passed  60 epoch Training Loss:  tensor(220.2714, device='cuda:0', grad_fn=<DivBackward0>)  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-07 02:07:33,461]\u001b[0m Trial 23 finished with value: 245.11962890625 and parameters: {'num_layers': 3, 'out_features1': 140, 'out_features2': 108, 'dim_feedforward': 448}. Best is trial 0 with value: 223.60110473632812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(279.3694, device='cuda:0')\n",
      "num layers: 4\n",
      "outfeatures1: 180\n",
      "outfeatures2: 120\n",
      "dim_feedforward: 512\n",
      "passed  0 epoch Training Loss:  tensor(3252.8872, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(2542.8381, device='cuda:0')\n",
      "passed  1 epoch Training Loss:  tensor(1549.4182, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(629.3925, device='cuda:0')\n",
      "passed  2 epoch Training Loss:  tensor(575.6042, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(531.8929, device='cuda:0')\n",
      "passed  3 epoch Training Loss:  tensor(498.0599, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(428.4506, device='cuda:0')\n",
      "passed  4 epoch Training Loss:  tensor(438.5252, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(422.3976, device='cuda:0')\n",
      "passed  5 epoch Training Loss:  tensor(436.5203, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(395.7222, device='cuda:0')\n",
      "passed  6 epoch Training Loss:  tensor(411.4883, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(429.7627, device='cuda:0')\n",
      "passed  7 epoch Training Loss:  tensor(403.5155, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(410.7404, device='cuda:0')\n",
      "passed  8 epoch Training Loss:  tensor(390.4998, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(381.5857, device='cuda:0')\n",
      "passed  9 epoch Training Loss:  tensor(376.4819, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(374.2029, device='cuda:0')\n",
      "passed  10 epoch Training Loss:  tensor(398.2482, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(431.7951, device='cuda:0')\n",
      "passed  11 epoch Training Loss:  tensor(384.0378, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(353.4292, device='cuda:0')\n",
      "passed  12 epoch Training Loss:  tensor(367.3855, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(461.6978, device='cuda:0')\n",
      "passed  13 epoch Training Loss:  tensor(356.9592, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(375.9460, device='cuda:0')\n",
      "passed  14 epoch Training Loss:  tensor(335.3528, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(308.1624, device='cuda:0')\n",
      "passed  15 epoch Training Loss:  tensor(339.7704, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(336.3580, device='cuda:0')\n",
      "passed  16 epoch Training Loss:  tensor(331.9284, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(383.2111, device='cuda:0')\n",
      "passed  17 epoch Training Loss:  tensor(324.7226, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(351.7924, device='cuda:0')\n",
      "passed  18 epoch Training Loss:  tensor(314.4085, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(324.3705, device='cuda:0')\n",
      "passed  19 epoch Training Loss:  tensor(323.5390, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(360.6507, device='cuda:0')\n",
      "passed  20 epoch Training Loss:  tensor(320.5953, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(388.8156, device='cuda:0')\n",
      "passed  21 epoch Training Loss:  tensor(346.8410, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(327.1364, device='cuda:0')\n",
      "passed  22 epoch Training Loss:  tensor(320.1795, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(337.1671, device='cuda:0')\n",
      "passed  23 epoch Training Loss:  tensor(312.1377, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(315.0621, device='cuda:0')\n",
      "passed  24 epoch Training Loss:  tensor(302.6507, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(366.1138, device='cuda:0')\n",
      "passed  25 epoch Training Loss:  tensor(312.3821, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(355.2268, device='cuda:0')\n",
      "passed  26 epoch Training Loss:  tensor(311.7486, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(412.7920, device='cuda:0')\n",
      "passed  27 epoch Training Loss:  tensor(310.6895, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(377.7829, device='cuda:0')\n",
      "passed  28 epoch Training Loss:  tensor(302.3904, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(368.4551, device='cuda:0')\n",
      "passed  29 epoch Training Loss:  tensor(302.7173, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(372.2594, device='cuda:0')\n",
      "passed  30 epoch Training Loss:  tensor(305.9375, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(359.0054, device='cuda:0')\n",
      "passed  31 epoch Training Loss:  tensor(300.8834, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(373.7946, device='cuda:0')\n",
      "passed  32 epoch Training Loss:  tensor(303.0176, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(377.0206, device='cuda:0')\n",
      "passed  33 epoch Training Loss:  tensor(298.2727, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(351.9376, device='cuda:0')\n",
      "passed  34 epoch Training Loss:  tensor(298.2676, device='cuda:0', grad_fn=<DivBackward0>)  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-07 02:24:53,312]\u001b[0m Trial 24 finished with value: 308.16241455078125 and parameters: {'num_layers': 4, 'out_features1': 180, 'out_features2': 120, 'dim_feedforward': 512}. Best is trial 0 with value: 223.60110473632812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(385.4570, device='cuda:0')\n",
      "num layers: 2\n",
      "outfeatures1: 160\n",
      "outfeatures2: 108\n",
      "dim_feedforward: 384\n",
      "passed  0 epoch Training Loss:  tensor(3243.2974, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(2517.2566, device='cuda:0')\n",
      "passed  1 epoch Training Loss:  tensor(1530.2380, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(623.9365, device='cuda:0')\n",
      "passed  2 epoch Training Loss:  tensor(603.6794, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(555.3513, device='cuda:0')\n",
      "passed  3 epoch Training Loss:  tensor(530.0985, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(431.1257, device='cuda:0')\n",
      "passed  4 epoch Training Loss:  tensor(444.0412, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(381.2767, device='cuda:0')\n",
      "passed  5 epoch Training Loss:  tensor(411.4672, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(372.5260, device='cuda:0')\n",
      "passed  6 epoch Training Loss:  tensor(396.9634, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(353.9790, device='cuda:0')\n",
      "passed  7 epoch Training Loss:  tensor(387.7193, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(359.9155, device='cuda:0')\n",
      "passed  8 epoch Training Loss:  tensor(381.1721, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(326.4986, device='cuda:0')\n",
      "passed  9 epoch Training Loss:  tensor(372.1320, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(345.4601, device='cuda:0')\n",
      "passed  10 epoch Training Loss:  tensor(353.6340, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(320.0173, device='cuda:0')\n",
      "passed  11 epoch Training Loss:  tensor(338.8089, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(318.2020, device='cuda:0')\n",
      "passed  12 epoch Training Loss:  tensor(331.4442, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(354.4856, device='cuda:0')\n",
      "passed  13 epoch Training Loss:  tensor(339.1097, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(383.3254, device='cuda:0')\n",
      "passed  14 epoch Training Loss:  tensor(342.0592, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(361.1861, device='cuda:0')\n",
      "passed  15 epoch Training Loss:  tensor(319.7902, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(366.6218, device='cuda:0')\n",
      "passed  16 epoch Training Loss:  tensor(333.0481, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(401.0256, device='cuda:0')\n",
      "passed  17 epoch Training Loss:  tensor(318.9220, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(405.1313, device='cuda:0')\n",
      "passed  18 epoch Training Loss:  tensor(320.6252, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(414.6200, device='cuda:0')\n",
      "passed  19 epoch Training Loss:  tensor(313.7408, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(418.9864, device='cuda:0')\n",
      "passed  20 epoch Training Loss:  tensor(312.3143, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(421.6887, device='cuda:0')\n",
      "passed  21 epoch Training Loss:  tensor(311.6237, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(377.5098, device='cuda:0')\n",
      "passed  22 epoch Training Loss:  tensor(292.5112, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(375.0792, device='cuda:0')\n",
      "passed  23 epoch Training Loss:  tensor(297.3742, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(368.7580, device='cuda:0')\n",
      "passed  24 epoch Training Loss:  tensor(288.7119, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(396.4173, device='cuda:0')\n",
      "passed  25 epoch Training Loss:  tensor(295.7893, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(369.5678, device='cuda:0')\n",
      "passed  26 epoch Training Loss:  tensor(281.2633, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(412.9507, device='cuda:0')\n",
      "passed  27 epoch Training Loss:  tensor(303.5739, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(428.3496, device='cuda:0')\n",
      "passed  28 epoch Training Loss:  tensor(275.9464, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(374.1631, device='cuda:0')\n",
      "passed  29 epoch Training Loss:  tensor(272.4321, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(405.2861, device='cuda:0')\n",
      "passed  30 epoch Training Loss:  tensor(280.2577, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(387.5949, device='cuda:0')\n",
      "passed  31 epoch Training Loss:  tensor(265.9419, device='cuda:0', grad_fn=<DivBackward0>)  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-07 02:40:27,694]\u001b[0m Trial 25 finished with value: 318.2019958496094 and parameters: {'num_layers': 2, 'out_features1': 160, 'out_features2': 108, 'dim_feedforward': 384}. Best is trial 0 with value: 223.60110473632812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(409.5978, device='cuda:0')\n",
      "num layers: 3\n",
      "outfeatures1: 140\n",
      "outfeatures2: 120\n",
      "dim_feedforward: 448\n",
      "passed  0 epoch Training Loss:  tensor(3256.1323, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(2555.1145, device='cuda:0')\n",
      "passed  1 epoch Training Loss:  tensor(1577.5507, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(572.5587, device='cuda:0')\n",
      "passed  2 epoch Training Loss:  tensor(589.8831, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(568.1462, device='cuda:0')\n",
      "passed  3 epoch Training Loss:  tensor(547.4922, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(488.6949, device='cuda:0')\n",
      "passed  4 epoch Training Loss:  tensor(502.9531, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(397.9344, device='cuda:0')\n",
      "passed  5 epoch Training Loss:  tensor(425.4026, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(369.8966, device='cuda:0')\n",
      "passed  6 epoch Training Loss:  tensor(401.8748, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(349.3223, device='cuda:0')\n",
      "passed  7 epoch Training Loss:  tensor(390.5818, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(359.3271, device='cuda:0')\n",
      "passed  8 epoch Training Loss:  tensor(374.7307, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(347.2665, device='cuda:0')\n",
      "passed  9 epoch Training Loss:  tensor(358.4049, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(370.4721, device='cuda:0')\n",
      "passed  10 epoch Training Loss:  tensor(334.5060, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(308.3765, device='cuda:0')\n",
      "passed  11 epoch Training Loss:  tensor(354.3957, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(345.4428, device='cuda:0')\n",
      "passed  12 epoch Training Loss:  tensor(332.0911, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(349.7464, device='cuda:0')\n",
      "passed  13 epoch Training Loss:  tensor(342.9143, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(356.5575, device='cuda:0')\n",
      "passed  14 epoch Training Loss:  tensor(340.2352, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(381.3780, device='cuda:0')\n",
      "passed  15 epoch Training Loss:  tensor(334.0581, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(411.2204, device='cuda:0')\n",
      "passed  16 epoch Training Loss:  tensor(332.2905, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(387.8081, device='cuda:0')\n",
      "passed  17 epoch Training Loss:  tensor(315.3052, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(349.6867, device='cuda:0')\n",
      "passed  18 epoch Training Loss:  tensor(306.6614, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(404.3977, device='cuda:0')\n",
      "passed  19 epoch Training Loss:  tensor(319.3084, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(375.0105, device='cuda:0')\n",
      "passed  20 epoch Training Loss:  tensor(309.9987, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(376.5144, device='cuda:0')\n",
      "passed  21 epoch Training Loss:  tensor(307.8833, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(414.7670, device='cuda:0')\n",
      "passed  22 epoch Training Loss:  tensor(309.2293, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(373.1813, device='cuda:0')\n",
      "passed  23 epoch Training Loss:  tensor(295.7225, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(363.2674, device='cuda:0')\n",
      "passed  24 epoch Training Loss:  tensor(288.7695, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(337.5108, device='cuda:0')\n",
      "passed  25 epoch Training Loss:  tensor(278.3716, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(326.5285, device='cuda:0')\n",
      "passed  26 epoch Training Loss:  tensor(269.3122, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(351.4969, device='cuda:0')\n",
      "passed  27 epoch Training Loss:  tensor(277.1855, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(399.8941, device='cuda:0')\n",
      "passed  28 epoch Training Loss:  tensor(279.9414, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(339.9608, device='cuda:0')\n",
      "passed  29 epoch Training Loss:  tensor(261.3011, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(321.9958, device='cuda:0')\n",
      "passed  30 epoch Training Loss:  tensor(264.8743, device='cuda:0', grad_fn=<DivBackward0>)  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-07 02:55:48,346]\u001b[0m Trial 26 finished with value: 308.3764953613281 and parameters: {'num_layers': 3, 'out_features1': 140, 'out_features2': 120, 'dim_feedforward': 448}. Best is trial 0 with value: 223.60110473632812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(387.2162, device='cuda:0')\n",
      "num layers: 3\n",
      "outfeatures1: 160\n",
      "outfeatures2: 120\n",
      "dim_feedforward: 320\n",
      "passed  0 epoch Training Loss:  tensor(3239.6125, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(2501.7117, device='cuda:0')\n",
      "passed  1 epoch Training Loss:  tensor(1496.9569, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(658.6265, device='cuda:0')\n",
      "passed  2 epoch Training Loss:  tensor(555.6808, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(453.3983, device='cuda:0')\n",
      "passed  3 epoch Training Loss:  tensor(464.2506, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(411.2012, device='cuda:0')\n",
      "passed  4 epoch Training Loss:  tensor(427.0706, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(417.9125, device='cuda:0')\n",
      "passed  5 epoch Training Loss:  tensor(403.7034, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(349.6913, device='cuda:0')\n",
      "passed  6 epoch Training Loss:  tensor(378.0982, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(337.6743, device='cuda:0')\n",
      "passed  7 epoch Training Loss:  tensor(369.7791, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(314.6218, device='cuda:0')\n",
      "passed  8 epoch Training Loss:  tensor(363.9702, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(421.3152, device='cuda:0')\n",
      "passed  9 epoch Training Loss:  tensor(333.9265, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(330.8943, device='cuda:0')\n",
      "passed  10 epoch Training Loss:  tensor(332.8229, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(429.0220, device='cuda:0')\n",
      "passed  11 epoch Training Loss:  tensor(325.9043, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(359.4531, device='cuda:0')\n",
      "passed  12 epoch Training Loss:  tensor(340.5202, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(359.4345, device='cuda:0')\n",
      "passed  13 epoch Training Loss:  tensor(330.9709, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(352.6864, device='cuda:0')\n",
      "passed  14 epoch Training Loss:  tensor(325.9364, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(364.8558, device='cuda:0')\n",
      "passed  15 epoch Training Loss:  tensor(318.6441, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(375.5083, device='cuda:0')\n",
      "passed  16 epoch Training Loss:  tensor(313.8367, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(423.0957, device='cuda:0')\n",
      "passed  17 epoch Training Loss:  tensor(321.8772, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(431.8857, device='cuda:0')\n",
      "passed  18 epoch Training Loss:  tensor(310.0310, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(430.6257, device='cuda:0')\n",
      "passed  19 epoch Training Loss:  tensor(304.0358, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(392.3006, device='cuda:0')\n",
      "passed  20 epoch Training Loss:  tensor(296.6560, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(369.0302, device='cuda:0')\n",
      "passed  21 epoch Training Loss:  tensor(296.9803, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(372.1957, device='cuda:0')\n",
      "passed  22 epoch Training Loss:  tensor(283.3065, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(344.4470, device='cuda:0')\n",
      "passed  23 epoch Training Loss:  tensor(280.6012, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(384.0485, device='cuda:0')\n",
      "passed  24 epoch Training Loss:  tensor(281.9149, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(354.1697, device='cuda:0')\n",
      "passed  25 epoch Training Loss:  tensor(296.3709, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(372.0522, device='cuda:0')\n",
      "passed  26 epoch Training Loss:  tensor(273.8415, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(357.6989, device='cuda:0')\n",
      "passed  27 epoch Training Loss:  tensor(260.6790, device='cuda:0', grad_fn=<DivBackward0>)  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-07 03:09:44,098]\u001b[0m Trial 27 finished with value: 314.621826171875 and parameters: {'num_layers': 3, 'out_features1': 160, 'out_features2': 120, 'dim_feedforward': 320}. Best is trial 0 with value: 223.60110473632812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(320.6567, device='cuda:0')\n",
      "num layers: 4\n",
      "outfeatures1: 180\n",
      "outfeatures2: 108\n",
      "dim_feedforward: 512\n",
      "passed  0 epoch Training Loss:  tensor(3238.6135, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(2488.1875, device='cuda:0')\n",
      "passed  1 epoch Training Loss:  tensor(1493.1355, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(672.0733, device='cuda:0')\n",
      "passed  2 epoch Training Loss:  tensor(605.4265, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(568.2502, device='cuda:0')\n",
      "passed  3 epoch Training Loss:  tensor(612.9809, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(558.4629, device='cuda:0')\n",
      "passed  4 epoch Training Loss:  tensor(605.0013, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(569.4220, device='cuda:0')\n",
      "passed  5 epoch Training Loss:  tensor(620.2934, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(566.7493, device='cuda:0')\n",
      "passed  6 epoch Training Loss:  tensor(596.7032, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(476.5254, device='cuda:0')\n",
      "passed  7 epoch Training Loss:  tensor(495.7490, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(427.9643, device='cuda:0')\n",
      "passed  8 epoch Training Loss:  tensor(454.6959, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(400.8719, device='cuda:0')\n",
      "passed  9 epoch Training Loss:  tensor(422.2378, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(374.5277, device='cuda:0')\n",
      "passed  10 epoch Training Loss:  tensor(398.7911, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(371.0688, device='cuda:0')\n",
      "passed  11 epoch Training Loss:  tensor(412.2506, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(344.0078, device='cuda:0')\n",
      "passed  12 epoch Training Loss:  tensor(374.2500, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(331.6541, device='cuda:0')\n",
      "passed  13 epoch Training Loss:  tensor(342.6111, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(350.8251, device='cuda:0')\n",
      "passed  14 epoch Training Loss:  tensor(379.4337, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(362.2786, device='cuda:0')\n",
      "passed  15 epoch Training Loss:  tensor(351.8848, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(311.1385, device='cuda:0')\n",
      "passed  16 epoch Training Loss:  tensor(345.2856, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(496.8969, device='cuda:0')\n",
      "passed  17 epoch Training Loss:  tensor(341.9934, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(403.5201, device='cuda:0')\n",
      "passed  18 epoch Training Loss:  tensor(337.9278, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(365.3565, device='cuda:0')\n",
      "passed  19 epoch Training Loss:  tensor(315.7440, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(354.2133, device='cuda:0')\n",
      "passed  20 epoch Training Loss:  tensor(319.6223, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(325.0681, device='cuda:0')\n",
      "passed  21 epoch Training Loss:  tensor(304.8380, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(403.5922, device='cuda:0')\n",
      "passed  22 epoch Training Loss:  tensor(332.8690, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(381.8139, device='cuda:0')\n",
      "passed  23 epoch Training Loss:  tensor(309.0720, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(334.2638, device='cuda:0')\n",
      "passed  24 epoch Training Loss:  tensor(300.2254, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(378.9684, device='cuda:0')\n",
      "passed  25 epoch Training Loss:  tensor(307.4525, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(315.8268, device='cuda:0')\n",
      "passed  26 epoch Training Loss:  tensor(287.8923, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(424.2206, device='cuda:0')\n",
      "passed  27 epoch Training Loss:  tensor(323.5574, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(430.5204, device='cuda:0')\n",
      "passed  28 epoch Training Loss:  tensor(306.2735, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(354.3204, device='cuda:0')\n",
      "passed  29 epoch Training Loss:  tensor(285.3943, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(349.4973, device='cuda:0')\n",
      "passed  30 epoch Training Loss:  tensor(270.7065, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(330.0730, device='cuda:0')\n",
      "passed  31 epoch Training Loss:  tensor(277.5323, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(389.5653, device='cuda:0')\n",
      "passed  32 epoch Training Loss:  tensor(276.9691, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(372.7286, device='cuda:0')\n",
      "passed  33 epoch Training Loss:  tensor(265.6303, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(345.7091, device='cuda:0')\n",
      "passed  34 epoch Training Loss:  tensor(260.1096, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(307.8307, device='cuda:0')\n",
      "passed  35 epoch Training Loss:  tensor(265.3568, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(521.7025, device='cuda:0')\n",
      "passed  36 epoch Training Loss:  tensor(291.2411, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(299.7181, device='cuda:0')\n",
      "passed  37 epoch Training Loss:  tensor(269.2518, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(433.0957, device='cuda:0')\n",
      "passed  38 epoch Training Loss:  tensor(261.2465, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(293.0900, device='cuda:0')\n",
      "passed  39 epoch Training Loss:  tensor(267.4056, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(296.2107, device='cuda:0')\n",
      "passed  40 epoch Training Loss:  tensor(267.2565, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(278.6280, device='cuda:0')\n",
      "passed  41 epoch Training Loss:  tensor(269.9607, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(274.1459, device='cuda:0')\n",
      "passed  42 epoch Training Loss:  tensor(288.1494, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(296.7698, device='cuda:0')\n",
      "passed  43 epoch Training Loss:  tensor(291.1948, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(273.9033, device='cuda:0')\n",
      "passed  44 epoch Training Loss:  tensor(255.9188, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(293.5516, device='cuda:0')\n",
      "passed  45 epoch Training Loss:  tensor(260.9750, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(284.5381, device='cuda:0')\n",
      "passed  46 epoch Training Loss:  tensor(254.1371, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(326.0421, device='cuda:0')\n",
      "passed  47 epoch Training Loss:  tensor(251.2752, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(270.0185, device='cuda:0')\n",
      "passed  48 epoch Training Loss:  tensor(250.3324, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(293.4690, device='cuda:0')\n",
      "passed  49 epoch Training Loss:  tensor(240.3046, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(258.2482, device='cuda:0')\n",
      "passed  50 epoch Training Loss:  tensor(247.2812, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(271.1262, device='cuda:0')\n",
      "passed  51 epoch Training Loss:  tensor(252.1458, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(264.5471, device='cuda:0')\n",
      "passed  52 epoch Training Loss:  tensor(254.0170, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(261.8170, device='cuda:0')\n",
      "passed  53 epoch Training Loss:  tensor(266.1983, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(302.8609, device='cuda:0')\n",
      "passed  54 epoch Training Loss:  tensor(287.9055, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(263.4393, device='cuda:0')\n",
      "passed  55 epoch Training Loss:  tensor(252.8101, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(261.8696, device='cuda:0')\n",
      "passed  56 epoch Training Loss:  tensor(245.9265, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(278.0913, device='cuda:0')\n",
      "passed  57 epoch Training Loss:  tensor(235.1105, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(281.4005, device='cuda:0')\n",
      "passed  58 epoch Training Loss:  tensor(231.5190, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(254.7900, device='cuda:0')\n",
      "passed  59 epoch Training Loss:  tensor(241.9977, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(262.1126, device='cuda:0')\n",
      "passed  60 epoch Training Loss:  tensor(246.1818, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(254.6371, device='cuda:0')\n",
      "passed  61 epoch Training Loss:  tensor(250.0050, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(250.2987, device='cuda:0')\n",
      "passed  62 epoch Training Loss:  tensor(240.5235, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(246.6107, device='cuda:0')\n",
      "passed  63 epoch Training Loss:  tensor(239.9366, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(253.8931, device='cuda:0')\n",
      "passed  64 epoch Training Loss:  tensor(239.3945, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(246.6437, device='cuda:0')\n",
      "passed  65 epoch Training Loss:  tensor(232.6303, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(252.0565, device='cuda:0')\n",
      "passed  66 epoch Training Loss:  tensor(234.7180, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(262.7807, device='cuda:0')\n",
      "passed  67 epoch Training Loss:  tensor(228.3507, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(248.3902, device='cuda:0')\n",
      "passed  68 epoch Training Loss:  tensor(237.1705, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(260.1899, device='cuda:0')\n",
      "passed  69 epoch Training Loss:  tensor(246.3350, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(256.6535, device='cuda:0')\n",
      "passed  70 epoch Training Loss:  tensor(233.1815, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(246.9091, device='cuda:0')\n",
      "passed  71 epoch Training Loss:  tensor(230.2047, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(251.9595, device='cuda:0')\n",
      "passed  72 epoch Training Loss:  tensor(221.7633, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(265.1208, device='cuda:0')\n",
      "passed  73 epoch Training Loss:  tensor(230.3067, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(270.9833, device='cuda:0')\n",
      "passed  74 epoch Training Loss:  tensor(217.9904, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(239.1014, device='cuda:0')\n",
      "passed  75 epoch Training Loss:  tensor(227.5704, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(243.2142, device='cuda:0')\n",
      "passed  76 epoch Training Loss:  tensor(230.0744, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(293.7483, device='cuda:0')\n",
      "passed  77 epoch Training Loss:  tensor(222.2135, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(256.8742, device='cuda:0')\n",
      "passed  78 epoch Training Loss:  tensor(216.6087, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(282.2914, device='cuda:0')\n",
      "passed  79 epoch Training Loss:  tensor(225.9963, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(259.9405, device='cuda:0')\n",
      "passed  80 epoch Training Loss:  tensor(237.8367, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(244.0541, device='cuda:0')\n",
      "passed  81 epoch Training Loss:  tensor(222.7246, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(265.4413, device='cuda:0')\n",
      "passed  82 epoch Training Loss:  tensor(218.2749, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(230.4287, device='cuda:0')\n",
      "passed  83 epoch Training Loss:  tensor(221.8297, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(255.5253, device='cuda:0')\n",
      "passed  84 epoch Training Loss:  tensor(215.8055, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(264.5073, device='cuda:0')\n",
      "passed  85 epoch Training Loss:  tensor(212.6405, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(231.2719, device='cuda:0')\n",
      "passed  86 epoch Training Loss:  tensor(228.3969, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(243.6885, device='cuda:0')\n",
      "passed  87 epoch Training Loss:  tensor(220.9285, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(304.3430, device='cuda:0')\n",
      "passed  88 epoch Training Loss:  tensor(234.8765, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(254.5782, device='cuda:0')\n",
      "passed  89 epoch Training Loss:  tensor(210.2364, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(262.9008, device='cuda:0')\n",
      "passed  90 epoch Training Loss:  tensor(220.1081, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(283.1578, device='cuda:0')\n",
      "passed  91 epoch Training Loss:  tensor(219.3099, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(242.2357, device='cuda:0')\n",
      "passed  92 epoch Training Loss:  tensor(220.3953, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(238.8352, device='cuda:0')\n",
      "passed  93 epoch Training Loss:  tensor(215.0718, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(326.9070, device='cuda:0')\n",
      "passed  94 epoch Training Loss:  tensor(244.1553, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(250.1918, device='cuda:0')\n",
      "passed  95 epoch Training Loss:  tensor(215.8712, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(309.8689, device='cuda:0')\n",
      "passed  96 epoch Training Loss:  tensor(218.4524, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(273.6797, device='cuda:0')\n",
      "passed  97 epoch Training Loss:  tensor(210.9681, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(252.5755, device='cuda:0')\n",
      "passed  98 epoch Training Loss:  tensor(213.2975, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(281.6551, device='cuda:0')\n",
      "passed  99 epoch Training Loss:  tensor(210.3649, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(284.7648, device='cuda:0')\n",
      "passed  100 epoch Training Loss:  tensor(215.3684, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(245.4225, device='cuda:0')\n",
      "passed  101 epoch Training Loss:  tensor(203.5141, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(277.5385, device='cuda:0')\n",
      "passed  102 epoch Training Loss:  tensor(213.3528, device='cuda:0', grad_fn=<DivBackward0>)  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-07 04:00:49,342]\u001b[0m Trial 28 finished with value: 230.42872619628906 and parameters: {'num_layers': 4, 'out_features1': 180, 'out_features2': 108, 'dim_feedforward': 512}. Best is trial 0 with value: 223.60110473632812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(273.9070, device='cuda:0')\n",
      "num layers: 4\n",
      "outfeatures1: 180\n",
      "outfeatures2: 108\n",
      "dim_feedforward: 512\n",
      "passed  0 epoch Training Loss:  tensor(3247.6313, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(2514.5818, device='cuda:0')\n",
      "passed  1 epoch Training Loss:  tensor(1506.9323, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(637.8672, device='cuda:0')\n",
      "passed  2 epoch Training Loss:  tensor(496.5901, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(409.0864, device='cuda:0')\n",
      "passed  3 epoch Training Loss:  tensor(433.0958, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(380.6974, device='cuda:0')\n",
      "passed  4 epoch Training Loss:  tensor(429.3778, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(418.8511, device='cuda:0')\n",
      "passed  5 epoch Training Loss:  tensor(424.2072, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(353.4429, device='cuda:0')\n",
      "passed  6 epoch Training Loss:  tensor(383.7203, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(329.1650, device='cuda:0')\n",
      "passed  7 epoch Training Loss:  tensor(375.1624, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(334.2809, device='cuda:0')\n",
      "passed  8 epoch Training Loss:  tensor(381.0992, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(339.6457, device='cuda:0')\n",
      "passed  9 epoch Training Loss:  tensor(347.4122, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(321.6049, device='cuda:0')\n",
      "passed  10 epoch Training Loss:  tensor(350.8250, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(323.0972, device='cuda:0')\n",
      "passed  11 epoch Training Loss:  tensor(333.5363, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(354.1494, device='cuda:0')\n",
      "passed  12 epoch Training Loss:  tensor(333.0826, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(363.8998, device='cuda:0')\n",
      "passed  13 epoch Training Loss:  tensor(327.5722, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(321.7817, device='cuda:0')\n",
      "passed  14 epoch Training Loss:  tensor(313.9770, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(334.0084, device='cuda:0')\n",
      "passed  15 epoch Training Loss:  tensor(314.2422, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(317.0751, device='cuda:0')\n",
      "passed  16 epoch Training Loss:  tensor(308.6069, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(347.0153, device='cuda:0')\n",
      "passed  17 epoch Training Loss:  tensor(317.0373, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(352.4920, device='cuda:0')\n",
      "passed  18 epoch Training Loss:  tensor(307.8656, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(369.5496, device='cuda:0')\n",
      "passed  19 epoch Training Loss:  tensor(304.0512, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(346.3112, device='cuda:0')\n",
      "passed  20 epoch Training Loss:  tensor(296.8474, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(327.0211, device='cuda:0')\n",
      "passed  21 epoch Training Loss:  tensor(285.7678, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(314.2053, device='cuda:0')\n",
      "passed  22 epoch Training Loss:  tensor(282.0142, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(313.6571, device='cuda:0')\n",
      "passed  23 epoch Training Loss:  tensor(282.2206, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(312.2946, device='cuda:0')\n",
      "passed  24 epoch Training Loss:  tensor(271.0265, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(297.3647, device='cuda:0')\n",
      "passed  25 epoch Training Loss:  tensor(262.2938, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(303.5432, device='cuda:0')\n",
      "passed  26 epoch Training Loss:  tensor(270.6097, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(276.0933, device='cuda:0')\n",
      "passed  27 epoch Training Loss:  tensor(282.2080, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(287.5843, device='cuda:0')\n",
      "passed  28 epoch Training Loss:  tensor(263.7790, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(296.6794, device='cuda:0')\n",
      "passed  29 epoch Training Loss:  tensor(283.0015, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(294.7322, device='cuda:0')\n",
      "passed  30 epoch Training Loss:  tensor(277.7787, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(289.1993, device='cuda:0')\n",
      "passed  31 epoch Training Loss:  tensor(274.5089, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(288.3160, device='cuda:0')\n",
      "passed  32 epoch Training Loss:  tensor(275.2686, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(301.8389, device='cuda:0')\n",
      "passed  33 epoch Training Loss:  tensor(263.3685, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(267.7356, device='cuda:0')\n",
      "passed  34 epoch Training Loss:  tensor(252.1843, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(268.0488, device='cuda:0')\n",
      "passed  35 epoch Training Loss:  tensor(243.8649, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(275.6670, device='cuda:0')\n",
      "passed  36 epoch Training Loss:  tensor(244.9128, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(267.5543, device='cuda:0')\n",
      "passed  37 epoch Training Loss:  tensor(241.3402, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(293.1135, device='cuda:0')\n",
      "passed  38 epoch Training Loss:  tensor(245.0022, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(275.7392, device='cuda:0')\n",
      "passed  39 epoch Training Loss:  tensor(243.2698, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(260.2370, device='cuda:0')\n",
      "passed  40 epoch Training Loss:  tensor(238.2505, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(255.8241, device='cuda:0')\n",
      "passed  41 epoch Training Loss:  tensor(244.9755, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(262.5278, device='cuda:0')\n",
      "passed  42 epoch Training Loss:  tensor(235.2424, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(254.8073, device='cuda:0')\n",
      "passed  43 epoch Training Loss:  tensor(249.0731, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(264.8379, device='cuda:0')\n",
      "passed  44 epoch Training Loss:  tensor(251.8349, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(295.6841, device='cuda:0')\n",
      "passed  45 epoch Training Loss:  tensor(249.8595, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(265.4879, device='cuda:0')\n",
      "passed  46 epoch Training Loss:  tensor(239.0652, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(275.5003, device='cuda:0')\n",
      "passed  47 epoch Training Loss:  tensor(230.0679, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(260.8275, device='cuda:0')\n",
      "passed  48 epoch Training Loss:  tensor(230.9458, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(260.2418, device='cuda:0')\n",
      "passed  49 epoch Training Loss:  tensor(227.1491, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(252.6232, device='cuda:0')\n",
      "passed  50 epoch Training Loss:  tensor(223.7553, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(246.8853, device='cuda:0')\n",
      "passed  51 epoch Training Loss:  tensor(218.2125, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(252.7138, device='cuda:0')\n",
      "passed  52 epoch Training Loss:  tensor(234.5957, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(250.2993, device='cuda:0')\n",
      "passed  53 epoch Training Loss:  tensor(229.1520, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(251.6784, device='cuda:0')\n",
      "passed  54 epoch Training Loss:  tensor(227.8486, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(261.0701, device='cuda:0')\n",
      "passed  55 epoch Training Loss:  tensor(225.6989, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(274.3282, device='cuda:0')\n",
      "passed  56 epoch Training Loss:  tensor(222.6496, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(252.2561, device='cuda:0')\n",
      "passed  57 epoch Training Loss:  tensor(216.6328, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(267.6362, device='cuda:0')\n",
      "passed  58 epoch Training Loss:  tensor(228.2354, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(289.8390, device='cuda:0')\n",
      "passed  59 epoch Training Loss:  tensor(232.5565, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(255.4236, device='cuda:0')\n",
      "passed  60 epoch Training Loss:  tensor(217.9042, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(294.7831, device='cuda:0')\n",
      "passed  61 epoch Training Loss:  tensor(230.3441, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(252.5717, device='cuda:0')\n",
      "passed  62 epoch Training Loss:  tensor(215.1728, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(400.0302, device='cuda:0')\n",
      "passed  63 epoch Training Loss:  tensor(261.0804, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(293.5233, device='cuda:0')\n",
      "passed  64 epoch Training Loss:  tensor(219.6236, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(294.4731, device='cuda:0')\n",
      "passed  65 epoch Training Loss:  tensor(219.2325, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(294.7669, device='cuda:0')\n",
      "passed  66 epoch Training Loss:  tensor(214.0215, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(293.7361, device='cuda:0')\n",
      "passed  67 epoch Training Loss:  tensor(217.2717, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(378.1358, device='cuda:0')\n",
      "passed  68 epoch Training Loss:  tensor(230.4773, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(271.2520, device='cuda:0')\n",
      "passed  69 epoch Training Loss:  tensor(207.9534, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(291.9270, device='cuda:0')\n",
      "passed  70 epoch Training Loss:  tensor(211.4525, device='cuda:0', grad_fn=<DivBackward0>)  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-07 04:35:50,293]\u001b[0m Trial 29 finished with value: 246.8852996826172 and parameters: {'num_layers': 4, 'out_features1': 180, 'out_features2': 108, 'dim_feedforward': 512}. Best is trial 0 with value: 223.60110473632812.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  tensor(364.6827, device='cuda:0')\n",
      "num layers: 4\n",
      "outfeatures1: 180\n",
      "outfeatures2: 108\n",
      "dim_feedforward: 512\n",
      "passed  0 epoch Training Loss:  tensor(3235.3369, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(2470.7988, device='cuda:0')\n",
      "passed  1 epoch Training Loss:  tensor(1450.5956, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(661.5764, device='cuda:0')\n",
      "passed  2 epoch Training Loss:  tensor(603.0489, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(569.2935, device='cuda:0')\n",
      "passed  3 epoch Training Loss:  tensor(613.9188, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(566.0052, device='cuda:0')\n",
      "passed  4 epoch Training Loss:  tensor(616.5770, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(571.0635, device='cuda:0')\n",
      "passed  5 epoch Training Loss:  tensor(617.0167, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(564.6511, device='cuda:0')\n",
      "passed  6 epoch Training Loss:  tensor(618.6676, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(568.3210, device='cuda:0')\n",
      "passed  7 epoch Training Loss:  tensor(617.5722, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(567.3989, device='cuda:0')\n",
      "passed  8 epoch Training Loss:  tensor(609.1211, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(564.1744, device='cuda:0')\n",
      "passed  9 epoch Training Loss:  tensor(534.8985, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(452.9820, device='cuda:0')\n",
      "passed  10 epoch Training Loss:  tensor(461.9582, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(407.5939, device='cuda:0')\n",
      "passed  11 epoch Training Loss:  tensor(426.3683, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(442.3911, device='cuda:0')\n",
      "passed  12 epoch Training Loss:  tensor(391.3961, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(356.5733, device='cuda:0')\n",
      "passed  13 epoch Training Loss:  tensor(398.2741, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(410.1516, device='cuda:0')\n",
      "passed  14 epoch Training Loss:  tensor(377.3664, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(412.7314, device='cuda:0')\n",
      "passed  15 epoch Training Loss:  tensor(384.5873, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(392.9995, device='cuda:0')\n",
      "passed  16 epoch Training Loss:  tensor(366.9068, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(359.7383, device='cuda:0')\n",
      "passed  17 epoch Training Loss:  tensor(334.7950, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(379.7295, device='cuda:0')\n",
      "passed  18 epoch Training Loss:  tensor(357.5973, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(353.2009, device='cuda:0')\n",
      "passed  19 epoch Training Loss:  tensor(324.3448, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(351.0901, device='cuda:0')\n",
      "passed  20 epoch Training Loss:  tensor(333.3471, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(331.6290, device='cuda:0')\n",
      "passed  21 epoch Training Loss:  tensor(313.9553, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(339.6169, device='cuda:0')\n",
      "passed  22 epoch Training Loss:  tensor(326.6989, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(354.3655, device='cuda:0')\n",
      "passed  23 epoch Training Loss:  tensor(323.6181, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(348.2605, device='cuda:0')\n",
      "passed  24 epoch Training Loss:  tensor(301.7444, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(349.2404, device='cuda:0')\n",
      "passed  25 epoch Training Loss:  tensor(294.2388, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(342.8102, device='cuda:0')\n",
      "passed  26 epoch Training Loss:  tensor(300.4895, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(311.0672, device='cuda:0')\n",
      "passed  27 epoch Training Loss:  tensor(289.1487, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(324.3467, device='cuda:0')\n",
      "passed  28 epoch Training Loss:  tensor(302.2331, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(292.7042, device='cuda:0')\n",
      "passed  29 epoch Training Loss:  tensor(282.4962, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(379.2342, device='cuda:0')\n",
      "passed  30 epoch Training Loss:  tensor(291.8575, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(328.0158, device='cuda:0')\n",
      "passed  31 epoch Training Loss:  tensor(275.7139, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(345.7177, device='cuda:0')\n",
      "passed  32 epoch Training Loss:  tensor(281.0316, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(334.4080, device='cuda:0')\n",
      "passed  33 epoch Training Loss:  tensor(274.7199, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(334.4221, device='cuda:0')\n",
      "passed  34 epoch Training Loss:  tensor(265.3630, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(366.9759, device='cuda:0')\n",
      "passed  35 epoch Training Loss:  tensor(277.9326, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(369.7773, device='cuda:0')\n",
      "passed  36 epoch Training Loss:  tensor(272.9545, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(360.0770, device='cuda:0')\n",
      "passed  37 epoch Training Loss:  tensor(260.2934, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(387.9835, device='cuda:0')\n",
      "passed  38 epoch Training Loss:  tensor(274.0410, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(351.4741, device='cuda:0')\n",
      "passed  39 epoch Training Loss:  tensor(257.3801, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(446.0361, device='cuda:0')\n",
      "passed  40 epoch Training Loss:  tensor(276.8518, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(356.5369, device='cuda:0')\n",
      "passed  41 epoch Training Loss:  tensor(266.2619, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(308.3575, device='cuda:0')\n",
      "passed  42 epoch Training Loss:  tensor(268.7043, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(280.3981, device='cuda:0')\n",
      "passed  43 epoch Training Loss:  tensor(262.6819, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(268.4672, device='cuda:0')\n",
      "passed  44 epoch Training Loss:  tensor(269.1879, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(270.3521, device='cuda:0')\n",
      "passed  45 epoch Training Loss:  tensor(254.4075, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(271.6823, device='cuda:0')\n",
      "passed  46 epoch Training Loss:  tensor(246.4504, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(271.4589, device='cuda:0')\n",
      "passed  47 epoch Training Loss:  tensor(241.0419, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(265.5663, device='cuda:0')\n",
      "passed  48 epoch Training Loss:  tensor(242.2841, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(268.3988, device='cuda:0')\n",
      "passed  49 epoch Training Loss:  tensor(246.3044, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(268.6935, device='cuda:0')\n",
      "passed  50 epoch Training Loss:  tensor(246.6486, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(265.9181, device='cuda:0')\n",
      "passed  51 epoch Training Loss:  tensor(277.6159, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(288.1476, device='cuda:0')\n",
      "passed  52 epoch Training Loss:  tensor(272.3880, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(261.3498, device='cuda:0')\n",
      "passed  53 epoch Training Loss:  tensor(251.8646, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(263.0230, device='cuda:0')\n",
      "passed  54 epoch Training Loss:  tensor(238.2291, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(270.5791, device='cuda:0')\n",
      "passed  55 epoch Training Loss:  tensor(236.7508, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(258.5014, device='cuda:0')\n",
      "passed  56 epoch Training Loss:  tensor(245.1252, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(254.9431, device='cuda:0')\n",
      "passed  57 epoch Training Loss:  tensor(235.4404, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(252.1248, device='cuda:0')\n",
      "passed  58 epoch Training Loss:  tensor(231.3195, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(250.7363, device='cuda:0')\n",
      "passed  59 epoch Training Loss:  tensor(231.6644, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(247.1740, device='cuda:0')\n",
      "passed  60 epoch Training Loss:  tensor(226.4360, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(250.5575, device='cuda:0')\n",
      "passed  61 epoch Training Loss:  tensor(227.4834, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(260.5506, device='cuda:0')\n",
      "passed  62 epoch Training Loss:  tensor(230.3760, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(253.7750, device='cuda:0')\n",
      "passed  63 epoch Training Loss:  tensor(231.5837, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(254.3957, device='cuda:0')\n",
      "passed  64 epoch Training Loss:  tensor(227.4497, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(247.3563, device='cuda:0')\n",
      "passed  65 epoch Training Loss:  tensor(222.8521, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(263.4692, device='cuda:0')\n",
      "passed  66 epoch Training Loss:  tensor(227.6152, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(245.3512, device='cuda:0')\n",
      "passed  67 epoch Training Loss:  tensor(219.7959, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(247.6788, device='cuda:0')\n",
      "passed  68 epoch Training Loss:  tensor(227.8750, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(253.6820, device='cuda:0')\n",
      "passed  69 epoch Training Loss:  tensor(226.1113, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(248.9282, device='cuda:0')\n",
      "passed  70 epoch Training Loss:  tensor(222.7324, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(247.6802, device='cuda:0')\n",
      "passed  71 epoch Training Loss:  tensor(219.5052, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(275.1559, device='cuda:0')\n",
      "passed  72 epoch Training Loss:  tensor(229.1069, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(242.2938, device='cuda:0')\n",
      "passed  73 epoch Training Loss:  tensor(214.6034, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(238.6935, device='cuda:0')\n",
      "passed  74 epoch Training Loss:  tensor(214.1870, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(240.8712, device='cuda:0')\n",
      "passed  75 epoch Training Loss:  tensor(227.5692, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(252.0335, device='cuda:0')\n",
      "passed  76 epoch Training Loss:  tensor(213.7858, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(236.7225, device='cuda:0')\n",
      "passed  77 epoch Training Loss:  tensor(217.9128, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(275.0590, device='cuda:0')\n",
      "passed  78 epoch Training Loss:  tensor(223.5855, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(241.9370, device='cuda:0')\n",
      "passed  79 epoch Training Loss:  tensor(209.4948, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(235.1378, device='cuda:0')\n",
      "passed  80 epoch Training Loss:  tensor(209.9683, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(251.2417, device='cuda:0')\n",
      "passed  81 epoch Training Loss:  tensor(220.3191, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(274.7863, device='cuda:0')\n",
      "passed  82 epoch Training Loss:  tensor(214.8877, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(239.7573, device='cuda:0')\n",
      "passed  83 epoch Training Loss:  tensor(212.7469, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(257.1418, device='cuda:0')\n",
      "passed  84 epoch Training Loss:  tensor(221.4439, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(245.4907, device='cuda:0')\n",
      "passed  85 epoch Training Loss:  tensor(207.6686, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(242.8205, device='cuda:0')\n",
      "passed  86 epoch Training Loss:  tensor(209.9230, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(262.0646, device='cuda:0')\n",
      "passed  87 epoch Training Loss:  tensor(228.2069, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(245.5075, device='cuda:0')\n",
      "passed  88 epoch Training Loss:  tensor(210.2912, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(248.9736, device='cuda:0')\n",
      "passed  89 epoch Training Loss:  tensor(212.2665, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(248.4184, device='cuda:0')\n",
      "passed  90 epoch Training Loss:  tensor(208.6062, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(244.6887, device='cuda:0')\n",
      "passed  91 epoch Training Loss:  tensor(216.0551, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(288.8680, device='cuda:0')\n",
      "passed  92 epoch Training Loss:  tensor(213.2082, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(250.1795, device='cuda:0')\n",
      "passed  93 epoch Training Loss:  tensor(207.6847, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(252.4882, device='cuda:0')\n",
      "passed  94 epoch Training Loss:  tensor(219.6386, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(257.3372, device='cuda:0')\n",
      "passed  95 epoch Training Loss:  tensor(204.8737, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(236.5191, device='cuda:0')\n",
      "passed  96 epoch Training Loss:  tensor(203.9118, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(227.8728, device='cuda:0')\n",
      "passed  97 epoch Training Loss:  tensor(217.4411, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(233.6943, device='cuda:0')\n",
      "passed  98 epoch Training Loss:  tensor(217.1618, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(264.5499, device='cuda:0')\n",
      "passed  99 epoch Training Loss:  tensor(206.6674, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(245.8635, device='cuda:0')\n",
      "passed  100 epoch Training Loss:  tensor(198.9531, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(245.8067, device='cuda:0')\n",
      "passed  101 epoch Training Loss:  tensor(225.6675, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(246.6553, device='cuda:0')\n",
      "passed  102 epoch Training Loss:  tensor(202.4294, device='cuda:0', grad_fn=<DivBackward0>)  Validation Loss:  tensor(242.1470, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-12-07 05:26:54,031]\u001b[0m Trial 30 failed with parameters: {'num_layers': 4, 'out_features1': 180, 'out_features2': 108, 'dim_feedforward': 512} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jik19004/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_31266/2542569413.py\", line 8, in objective\n",
      "    return Train_and_Evaluate(TrainingLoader, ValidationLoader ,device, params, 260,20);\n",
      "  File \"/tmp/ipykernel_31266/1224213325.py\", line 53, in Train_and_Evaluate\n",
      "    predictedVal = model(input)\n",
      "  File \"/home/jik19004/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_31266/3737814934.py\", line 61, in forward\n",
      "    val = val + self.getPositionalEncoding(batch_size = val.size(0), seq_len = val.size(1), d = val.size(2))\n",
      "  File \"/tmp/ipykernel_31266/3737814934.py\", line 50, in getPositionalEncoding\n",
      "    for i in np.arange(int(d/2)):\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-12-07 05:26:54,032]\u001b[0m Trial 30 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31266/3526714421.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy_name\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"Transformer6\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_if_exists\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sqlite:///example6.db'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"study6.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \"\"\"\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31266/2542569413.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      6\u001b[0m               trial.suggest_int(\"dim_feedforward\", low = 256, high = 512, step = 64)];\n\u001b[1;32m      7\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTrain_and_Evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainingLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValidationLoader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m260\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_31266/1224213325.py\u001b[0m in \u001b[0;36mTrain_and_Evaluate\u001b[0;34m(train_loader, val_loader, device, params, numEpochs, early_stop_epochs)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mpredictedVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;31m#predictedVal = torch.squeeze(predictedVal, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31266/3737814934.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPositionalEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this would be (72, 50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31266/3737814934.py\u001b[0m in \u001b[0;36mgetPositionalEncoding\u001b[0;34m(self, batch_size, seq_len, d, n, device)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                     \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                     \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdenominator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import joblib \n",
    "study_name = 'sqlite:///example6.db'\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(), study_name= \"Transformer6\", load_if_exists= True, storage='sqlite:///example6.db')\n",
    "joblib.dump(study, \"study6.pkl\") \n",
    "study.optimize(objective, n_trials = 60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'dim_feedforward': 512, 'num_layers': 4, 'out_features1': 140, 'out_features2': 120}\n",
      "MAE for validation set: 223.60110473632812\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameters:\", study.best_params)\n",
    "print(\"MAE for validation set:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_and_Evaluate2(train_loader, val_loader, device, numEpochs, early_stop_epochs):\n",
    "    #num_layers, dropout = 0.1, outfeatures1 = 16, outfeatures2 = 16, outfeatures3 = 16, outfeatures4 = 16, dim_feedforward = 2048, output_num = 6\n",
    "    model = TimeSeriesTransformer(num_layers = 4, dropout = 0.2, outfeatures1 = 140, outfeatures2 = 120,\n",
    "                                dim_feedforward = 384, output_num = 6) # construct the model. \n",
    "    model = model.to(device);\n",
    "    LossFunction = torch.nn.L1Loss();\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_count = 0\n",
    "    \n",
    "    Optimizer = torch.optim.Adam(params = model.parameters(), betas = (0.9, 0.98), weight_decay= 0.00001)\n",
    "    for epoch in range(0,numEpochs): \n",
    "        Training_Loss = 0; \n",
    "        total_samples = 0; \n",
    "        for input, output in train_loader:\n",
    "            input = input.to(device); \n",
    "            output = torch.squeeze(output, 1); \n",
    "            output = output.to(device); \n",
    "            predictedVal = model(input)\n",
    "            #predictedVal = torch.squeeze(predictedVal, 1)\n",
    "            Optimizer.zero_grad();\n",
    "            batchLoss = LossFunction(predictedVal, output);\n",
    "            batchLoss.backward(); \n",
    "            Optimizer.step();\n",
    "            Training_Loss += batchLoss * output.size(0) #* output.size(0);\n",
    "            total_samples += output.size(0)\n",
    "        Training_Loss = Training_Loss/total_samples\n",
    "\n",
    "\n",
    "        Validation_Loss = 0; \n",
    "        print(\"passed \", epoch, \"epoch\", \"Training Loss: \", Training_Loss,\" \", end = \"\")\n",
    "        with torch.no_grad():\n",
    "            total_val_samples = 0; \n",
    "            Validation_Loss = 0; \n",
    "            for val_input, val_output in val_loader:\n",
    "                val_input = val_input.to(device); \n",
    "                val_output = torch.squeeze(val_output,1);\n",
    "                val_output = val_output.to(device);\n",
    "\n",
    "                predictedVal = model(val_input)\n",
    "                Validation_Loss += LossFunction(val_output, predictedVal) * val_output.size(0)\n",
    "                total_val_samples += val_output.size(0)\n",
    "            Validation_Loss = Validation_Loss/total_val_samples\n",
    "            print(\"Validation Loss: \", Validation_Loss)\n",
    "\n",
    "            if Validation_Loss < best_val_loss:\n",
    "                best_val_loss = Validation_Loss\n",
    "                early_stop_count = 0;\n",
    "                torch.save(model, \"//home//jik19004//FilesToRun//DINGRESEARCH//DingResearchDec28th//DingTransformerFolderTransformer6\"); #We go save with the transformer!!!\n",
    "            else:\n",
    "                early_stop_count +=1 \n",
    "            if early_stop_count >= early_stop_epochs:\n",
    "                return model; \n",
    "            \n",
    "            \n",
    "\n",
    "    return model; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19171/3192445927.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m Model6 = Train_and_Evaluate2(TrainingLoader, ValidationLoader, device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), \n\u001b[0m\u001b[1;32m      2\u001b[0m                              numEpochs = 260, early_stop_epochs = 26)\n",
      "\u001b[0;32m/tmp/ipykernel_19171/1870346220.py\u001b[0m in \u001b[0;36mTrain_and_Evaluate2\u001b[0;34m(train_loader, val_loader, device, numEpochs, early_stop_epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mpredictedVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;31m#predictedVal = torch.squeeze(predictedVal, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_19171/3373875214.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPositionalEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this would be (72, 50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_19171/3373875214.py\u001b[0m in \u001b[0;36mgetPositionalEncoding\u001b[0;34m(self, batch_size, seq_len, d, n, device)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                     \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdenominator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                     \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdenominator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Model6 = Train_and_Evaluate2(TrainingLoader, ValidationLoader, device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), \n",
    "                             numEpochs = 260, early_stop_epochs = 26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/jik19004/FilesToRun/DINGRESEARCH/DingResearchDec28th/DingTransformerFolderTransformer6\"\n",
    "Model6 = torch.load(PATH)\n",
    "Tuples = predict(Model6, TestingLoader, device = torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Testing:  217158.33\n",
      "MAE for Testing:  373.25333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "MAE_result = mean_absolute_error(Tuples[0], Tuples[1])\n",
    "MSE_result = mean_squared_error(Tuples[0], Tuples[1])\n",
    "print(\"MSE for Testing: \", MSE_result)\n",
    "print(\"MAE for Testing: \", MAE_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f26ca08bf10>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApQAAAIDCAYAAAC6rI7HAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOydd3xN5xvAv3fkZonESkLErE1CYm9qVVGl9ogWHXZLVXTQxa/aqlLaolardKBFS7WovYmE2itiE0JEkjvO74+Te5OTe04GkQjv9/PJ5+Y873vOee9N7jnPeaZOkiQJgUAgEAgEAoHgPtHn9QIEAoFAIBAIBPkboVAKBAKBQCAQCB4IoVAKBAKBQCAQCB4IoVAKBAKBQCAQCB4IoVAKBAKBQCAQCB4IoVAKBAKBQCAQCB4IoVAKBAKBQCAQCB4IoVAKBAKBQCAQCB4IoVAKBAKBQCAQCB4IoVAKBAIHCxYsQKfTOX6MRiMlS5bkxRdf5MKFC7myhjJlyjBgwADH9r///otOp+Pff//N1nG2b9/OxIkTuXXrltNY8+bNad68+QOt82GzdetW2rdvT6FChXB3d6dChQp8+OGHme43YMAAChQokAsrzD3Onj2LTqfjs88+y+ulOLCvacGCBXm9FIHgkcCY1wsQCASPHvPnz6dy5crcu3ePzZs3M3nyZDZt2kRUVBSenp65upaQkBB27NhB1apVs7Xf9u3bef/99xkwYAA+Pj6KsVmzZuXgCnOeH3/8kX79+tG9e3cWLVpEgQIFOHXqFBcvXszrpQkEAoEqQqEUCAROVK9endq1awPQokULrFYrH374Ib/99ht9+vRR3SchIQEPD48cX0vBggWpX79+jh4zu8ppbnLhwgVefvllXnnlFYXi26JFizxc1f3zsP4vBALBo4VweQsEgkyxK3Tnzp0DUt2qUVFRtGnTBi8vL55++mkAkpOT+eijj6hcuTKurq4UK1aMF198kWvXrimOaTabGTt2LP7+/nh4eNC4cWN2797tdG4tl/euXbvo2LEjRYoUwc3NjfLlyzNq1CgAJk6cyJtvvglA2bJlHS58+zHUXN6xsbEMGTKEgIAATCYT5cqV4+233yYpKUkxT6fTMWzYML7//nuqVKmCh4cHwcHBrF69WjHv2rVrvPzyywQGBjo+h0aNGvHPP/9k+FnPnTuXu3fv8tZbb2U4LzNOnjxJ+/btKVCgAIGBgYwePdrpvWTlPWfk2tXpdEycONGxPXHiRHQ6Hfv37+eFF16gUKFClC9fXnON165dY8iQIVStWpUCBQrg6+tLy5Yt2bJli+Y+U6dOpWzZshQoUIAGDRqwc+dOpzl79+6lU6dOFC5cGDc3N2rVqsXPP/983+e+ePEi3bt3x8vLC29vb3r06MHly5c11ygQPIkIC6VAIMiUkydPAlCsWDGHLDk5mU6dOvHKK68wbtw4LBYLNpuN5557ji1btjB27FgaNmzIuXPnmDBhAs2bN2fv3r24u7sDMHjwYBYtWsSYMWNo3bo1hw4dokuXLty5cyfT9fz111907NiRKlWqMHXqVEqVKsXZs2dZt24dAIMGDSI2NpYZM2awfPlyihcvDmhbJhMTE2nRogWnTp3i/fffJygoiC1btjB58mQiIiL4448/FPP/+OMP9uzZwwcffECBAgWYMmUKzz//PMeOHaNcuXIA9OvXj/379/Pxxx9TsWJFbt26xf79+7lx40aG723z5s0ULlyYo0eP8txzz3Ho0CEKFy5Mly5dmDJlCgULFsz08zGbzXTq1ImBAwcyevRoNm/ezIcffoi3tzfvvffefb3n7NClSxd69uzJq6++yt27dzXnxcbGAjBhwgT8/f2Jj49nxYoVNG/enPXr1zsp/TNnzqRy5cpMmzYNgHfffZf27dtz5swZvL29Adi4cSPt2rWjXr16fPPNN3h7e7N06VJ69OhBQkKCIz43q+e+d+8erVq14uLFi0yePJmKFSvyxx9/0KNHj/v+fASCxxJJIBAIUpg/f74ESDt37pTMZrN0584dafXq1VKxYsUkLy8v6fLly5IkSVJYWJgESPPmzVPsv2TJEgmQli1bppDv2bNHAqRZs2ZJkiRJR44ckQDp9ddfV8xbvHixBEhhYWEO2caNGyVA2rhxo0NWvnx5qXz58tK9e/c038unn34qAdKZM2ecxpo1ayY1a9bMsf3NN99IgPTzzz8r5n3yyScSIK1bt84hAyQ/Pz/p9u3bDtnly5clvV4vTZ482SErUKCANGrUKM31aVGpUiXJzc1N8vLykiZNmiRt3LhRmjJliuTu7i41atRIstlsGe5v/9ukfy/t27eXKlWqlO33fObMGQmQ5s+f73QuQJowYYJje8KECRIgvffee9l81zIWi0Uym83S008/LT3//PMOuX0NNWrUkCwWi0O+e/duCZCWLFnikFWuXFmqVauWZDabFcfu0KGDVLx4cclqtWbr3F9//bUESL///rti/uDBgzU/F4HgSUS4vAUCgRP169fHxcUFLy8vOnTogL+/P2vWrMHPz08xr2vXrort1atX4+PjQ8eOHbFYLI6fmjVr4u/v73A5b9y4EcApHrN79+4YjRk7To4fP86pU6cYOHAgbm5uD/hOZTZs2ICnpycvvPCCQm63Zq1fv14hb9GiBV5eXo5tPz8/fH19HSEBAHXr1mXBggV89NFH7Ny5E7PZnKW12Gw2EhMTGT9+POHh4TRv3pw333yTyZMns23bNqe1qKHT6ejYsaNCFhQUpFhfdt9zdkj/f5ER33zzDSEhIbi5uWE0GnFxcWH9+vUcOXLEae6zzz6LwWBwbAcFBQGpoRgnT57k6NGjjv+rtP+D7du359KlSxw7dixb5964cSNeXl506tRJsZbevXtn+T0KBE8CQqEUCAROLFq0iD179nDgwAEuXrxIZGQkjRo1Uszx8PBwcr9euXKFW7duYTKZcHFxUfxcvnyZ69evAzjcvv7+/or9jUYjRYoUyXBt9ljMkiVLPtB7TMuNGzfw9/dHp9Mp5L6+vhiNRic3tdoaXV1duXfvnmP7p59+IiwsjLlz59KgQQMKFy5M//79M429sx+7bdu2CvkzzzwDwP79+zN9Px4eHk7KtqurK4mJiY7t7L7n7GAPMciMqVOn8tprr1GvXj2WLVvGzp072bNnD+3atVN8lnbSf+6urq4AjrlXrlwBYMyYMU7/f0OGDAFw/A9m9dw3btxwepAC5/9dgeBJR8RQCgQCJ6pUqeLI8tYivSICULRoUYoUKcLatWtV97Fb9eyKweXLlwkICHCMWyyWTBUZexxnTExMhvOyQ5EiRdi1axeSJCne19WrV7FYLBQtWjTbxyxatCjTpk1j2rRpREdHs3LlSsaNG8fVq1c1Px+QrW5qiSaSJAGg1+eMHSCr79mumKZP6Mno76T2v6HGDz/8QPPmzfn6668V8qzE0aphX3N4eDhdunRRnVOpUqVsnbtIkSKqyWIiKUcgUCIslAKBIMfo0KEDN27cwGq1Urt2bacf+83cnvCwePFixf4///wzFoslw3NUrFiR8uXLM2/ePCclJy3prVcZ8fTTTxMfH89vv/2mkC9atMgx/iCUKlWKYcOG0bp160wtjHZ38Zo1axTyP//8EyDHSihl9T37+fnh5uZGZGSkYt7vv//+wGvQ6XSOv5OdyMhIduzYcV/Hq1SpEhUqVODgwYOq/3+1a9d2PNRk9dwtWrTgzp07rFy5UiH/8ccf72uNAsHjirBQCgSCHKNnz54sXryY9u3bM3LkSOrWrYuLiwsxMTFs3LiR5557jueff54qVarQt29fpk2bhouLC61ateLQoUN89tlnWcpinjlzJh07dqR+/fq8/vrrlCpViujoaP766y+HklqjRg0AvvzyS8LCwnBxcaFSpUqK2Ec7/fv3Z+bMmYSFhXH27Flq1KjB1q1bmTRpEu3bt6dVq1bZ+hzi4uJo0aIFvXv3pnLlynh5ebFnzx7Wrl2raTmz06ZNGzp27MgHH3yAzWajfv367N27l/fff58OHTrQuHHjbK1Fi6y+Z51OR9++fZk3bx7ly5cnODiY3bt354hC1aFDBz788EMmTJhAs2bNOHbsGB988AFly5bN9MFCi2+//ZZnnnmGtm3bMmDAAAICAoiNjeXIkSPs37+fX375JVvn7t+/P1988QX9+/fn448/pkKFCvz555/89ddfD/z+BYLHijxOChIIBI8Q9izvPXv2ZDgvLCxM8vT0VB0zm83SZ599JgUHB0tubm5SgQIFpMqVK0uvvPKKdOLECce8pKQkafTo0ZKvr6/k5uYm1a9fX9qxY4dUunTpTLO8JUmSduzYIT3zzDOSt7e35OrqKpUvX94pazw8PFwqUaKEpNfrFcdIn+UtSZJ048YN6dVXX5WKFy8uGY1GqXTp0lJ4eLiUmJiomAdIQ4cOdXrfadedmJgovfrqq1JQUJBUsGBByd3dXapUqZI0YcIE6e7duxl8sjIJCQnSW2+9JQUGBkpGo1EqVaqU6lrU0Prb2DOw7+c9x8XFSYMGDZL8/PwkT09PqWPHjtLZs2c1s7yvXbuW6TolSf4fGDNmjBQQECC5ublJISEh0m+//SaFhYVJpUuXdsyzZ3l/+umnTsdIvwZJkqSDBw9K3bt3l3x9fSUXFxfJ399fatmypfTNN99k+9ySJEkxMTFS165dpQIFCkheXl5S165dpe3bt4ssb4EgDTpJSgnMEQgEAoFAIBAI7gMRQykQCAQCgUAgeCCEQikQCAQCgUAgeCCEQikQCAQCgUAgeCCEQikQCAQCgUAgeCCEQikQCAQCgUAgeCCEQikQCAQCgUAgeCBEYfMsYrPZuHjxIl5eXlluKyYQCAQCgUCQn5EkiTt37lCiRIkMW78KhTKLXLx4kcDAwLxehkAgEAgEAkGuc/78eUqWLKk5LhTKLGJv13b+/PkstYYTCAQCgUAgyO/cvn2bwMBA1ba1aREKZRaxu7kLFiwoFEqBQCAQCARPFJmF+4mkHIFAIBAIBALBAyEUSoFAIBAIBALBAyEUSoFAIBAIBALBAyFiKHMQq9WK2WzO62UI8jEuLi4YDIa8XoZAIBAIBNlCKJQ5RHx8PDExMUiSlNdLEeRjdDodJUuWpECBAnm9FIFAIBAIsoxQKHMAq9VKTEwMHh4eFCtWTBQ+F9wXkiRx7do1YmJiqFChgrBUCgQCgSDfIBTKHMBsNiNJEsWKFcPd3T2vlyPIxxQrVoyzZ89iNpuFQikQCASCfINIyslBhGVS8KCI/yGBQCAQ5EeEQikQCAQCgUAgeCCEQikQCAQCgUAgeCCEQinIFcqUKcO0adMc2zqdjt9+++2BjpkTxxAIBAKBQPDgiKQcQZ5w6dIlChUqlKW5EydO5LfffiMiIuK+jyEQCAQCgeDhIRRKQZZJTk7GZDLlyLH8/f0fiWMIBAKBQCB4cITL+wmmefPmDBs2jGHDhuHj40ORIkV45513HMXZy5Qpw0cffcSAAQPw9vZm8ODBAGzfvp2mTZvi7u5OYGAgI0aM4O7du47jXr16lY4dO+Lu7k7ZsmVZvHix07nTu6tjYmLo2bMnhQsXxtPTk9q1a7Nr1y4WLFjA+++/z8GDB9HpdOh0OhYsWKB6jKioKFq2bIm7uztFihTh5ZdfJj4+3jE+YMAAOnfuzGeffUbx4sUpUqQIQ4cOVXQ3mjVrFhUqVMDNzQ0/Pz9eeOGFnPioBQKB4MGIuwBzW8Hti3m9EoFAFaFQPmJcirtHl1nbuByXmCvnW7hwIUajkV27djF9+nS++OIL5s6d6xj/9NNPqV69Ovv27ePdd98lKiqKtm3b0qVLFyIjI/npp5/YunUrw4YNc+wzYMAAzp49y4YNG/j111+ZNWsWV69e1VxDfHw8zZo14+LFi6xcuZKDBw8yduxYbDYbPXr0YPTo0VSrVo1Lly5x6dIlevTo4XSMhIQE2rVrR6FChdizZw+//PIL//zzj2JdABs3buTUqVNs3LiRhQsXsmDBAoeCunfvXkaMGMEHH3zAsWPHWLt2LU2bNn3AT1ggEAgeAEkCSxLsWwAxe+RXS5IsFwgeIYTL+xFBkiSSrTaW7Ipmf/QtftwdzdAW5TEZ9A+1NmFgYCBffPEFOp2OSpUqERUVxRdffOGwRrZs2ZIxY8Y45vfv35/evXszatQoACpUqMD06dNp1qwZX3/9NdHR0axZs4adO3dSr149AL777juqVKmiuYYff/yRa9eusWfPHgoXLgzAU0895RgvUKAARqMxQxf34sWLuXfvHosWLcLT0xOAr776io4dO/LJJ5/g5+cHQKFChfjqq68wGAxUrlyZZ599lvXr1zN48GCio6Px9PSkQ4cOeHl5Ubp0aWrVqnUfn6pAIBDkEKtGwP5FqdubPpF/QsKg0/S8W5dAkA5hoXxECF8eRaV31jJ9w0kApq8/QaV31jJ+RdRDPW/9+vUVCmuDBg04ceIEVqsVgNq1ayvm79u3jwULFlCgQAHHT9u2bbHZbJw5c4YjR45gNBoV+1WuXBkfHx/NNURERFCrVi2HMnk/HDlyhODgYIcyCdCoUSNsNhvHjh1zyKpVq6boQFO8eHGH9bR169aULl2acuXK0a9fPxYvXkxCQsJ9r0kgEAgemNABGvKwXF2GQJAZQqF8ROhVt5SqvGcddXlukVZBA7DZbLzyyitEREQ4fg4ePMiJEycoX768I/4yO1bVnGhXKUmS5jnTyl1cXJzGbDYbAF5eXuzfv58lS5ZQvHhx3nvvPYKDg7l169YDr08gEAjui4BQaPmOUtbyXVkuEDxCCIXyESE40IcxbSoqZG+2rURwoM9DPe/OnTudtitUqKDZRzokJITDhw/z1FNPOf2YTCaqVKmCxWJh7969jn2OHTuWoVIWFBREREQEsbGxquMmk8lhMdWiatWqREREKJKDtm3bhl6vp2LFihnsqcRoNNKqVSumTJlCZGSkIxZUIBAI8gRJgqhflLKon0UMpeCRQyiUjxArI+TsvQENywDwe8SFh37O8+fP88Ybb3Ds2DGWLFnCjBkzGDlypOb8t956ix07djB06FAiIiI4ceIEK1euZPjw4QBUqlSJdu3aMXjwYHbt2sW+ffsYNGhQhlbIXr164e/vT+fOndm2bRunT59m2bJl7NixA5Czzc+cOUNERATXr18nKSnJ6Rh9+vTBzc2NsLAwDh06xMaNGxk+fDj9+vVzxE9mxurVq5k+fToRERGcO3eORYsWYbPZqFSpUpb2FwgEghxn1Qi4dkwpu3YMVmlfpwWCvEAolI8QM/uEsGVsCyZ2qsaWsS2Y2TvkoZ+zf//+3Lt3j7p16zJ06FCGDx/Oyy+/rDk/KCiITZs2ceLECZo0aUKtWrV49913KV68uGPO/PnzCQwMpFmzZnTp0oWXX34ZX19fzWOaTCbWrVuHr68v7du3p0aNGvzvf/9zWEm7du1Ku3btaNGiBcWKFWPJkiVOx/Dw8OCvv/4iNjaWOnXq8MILL/D000/z1VdfZfmz8PHxYfny5bRs2ZIqVarwzTffsGTJEqpVq5blYwgEAkGOImIoBfkEnSQJu3lWuH37Nt7e3sTFxVGwYEHFWGJiImfOnKFs2bK4ubnl0QqzT/PmzalZs6aiJaIgb8mv/0sCgeAhIUlyVve/k1NlzcdDs7HwECuACAR2MtJ/0iIslAKBQCAQPKqsGqFUJgH+nSRc3oJHDqFQCgQCgUDwqCJc3oJ8gihs/gTz77//5vUSBAKBQJAR9rJBGz5KlYmyQYJHEGGhFAgEAoHgUUWSIPJnpSxSlA0SPHoIhVIgEAgEgkeVlSPg+nGl7LooGyR49BAKpUAgEAgEjyoJ19XldzXkAkEeIRRKgUAgEAgeVRq/oSF/PffWEHcB5raC2xdz75yCfIdQKAUCgUAgeFT57VUN+WsP/9ySBJYk2LcAYvbIr5YkEb8pUEUolALB446wLggE+ZcmGhbKJrlgoVw1Aj7yhc1T5O1Nn8jbIn5ToIJQKAUPnbNnz6LT6YiIiMjrpWTKggUL8PHxyetl5AzCuiAQ5H9q9oGSdZSyknVl+cMmZICGXNTAFDgjFMonmObNmzNq1KgcPeaAAQPo3LmzQhYYGMilS5eoXr16jp5LkAnCuiAQPB5cOii/urinbEfkznn3LVCX71+YO+cX5CuEQil46BgMBvz9/TEaRR39XEV02BAI8j+SBF3nQlBPMN+D4F7ydm54GkSGuSAbCIXyCWXAgAFs2rSJL7/8Ep1Oh06n4+zZswD8999/tG/fngIFCuDn50e/fv24fj31AvLrr79So0YN3N3dKVKkCK1ateLu3btMnDiRhQsX8vvvvzuO+e+//zq5vP/99190Oh3r16+ndu3aeHh40LBhQ44dO6ZY40cffYSvry9eXl4MGjSIcePGUbNmTdX3Y7PZKFmyJN98841Cvn//fnQ6HadPnwZg6tSp1KhRA09PTwIDAxkyZAjx8fEZfk7pLa6jRo2iefPmjm1JkpgyZQrlypXD3d2d4OBgfv31V8f4zZs36dOnD8WKFcPd3Z0KFSowf/58zXPmGPYOG2kRHTYEgvzFqhHwc3+IXCpvH1wib+eGp6HpGHV5o+EidEbghFAoHzVyKYHiyy+/pEGDBgwePJhLly5x6dIlh2u6WbNm1KxZk71797J27VquXLlC9+7dAbh06RK9evXipZde4siRI/z777906dIFSZIYM2YM3bt3p127do5jNmzYUHMNb7/9Np9//jl79+7FaDTy0ksvOcYWL17Mxx9/zCeffMK+ffsoVaoUX3/9teax9Ho9PXv2ZPHixQr5jz/+SIMGDShXrpxj3vTp0zl06BALFy5kw4YNjB079kE+St555x3mz5/P119/zeHDh3n99dfp27cvmzZtAuDdd9/lv//+Y82aNRw5coSvv/6aokWLPtA5s4QkQdQvSlmU6LAhEOQr8tLTEBAKRjdn+bx2InRG4ITwQT4qSBJYk5UJFE1Gg8EEOl2On87b2xuTyYSHhwf+/v4O+ddff01ISAiTJk1yyObNm0dgYCDHjx8nPj4ei8VCly5dKF26NAA1atRwzHV3dycpKUlxTC0+/vhjmjVrBsC4ceN49tlnSUxMxM3NjRkzZjBw4EBefPFFAN577z3WrVuXoTWxT58+TJ06lXPnzlG6dGlsNhtLly5l/PjxjjlpY0bLli3Lhx9+yGuvvcasWbMyXa8ad+/eZerUqWzYsIEGDRoAUK5cObZu3cq3335Ls2bNiI6OplatWtSuXRuAMmXK3Ne5ss3K4XBNafXl2jG588ZzM3JnDQKB4MHI617eboUg/pKzXCTmCNIhLJSPCo9IAsW+ffvYuHEjBQoUcPxUrlwZgFOnThEcHMzTTz9NjRo16NatG3PmzOHmzZv3da6goCDH78WLFwfg6tWrABw7doy6desq5qffTk+tWrWoXLkyS5YsAWDTpk1cvXrVYV0F2LhxI61btyYgIAAvLy/69+/PjRs3uHv37n29h//++4/ExERat26t+MwWLVrEqVOnAHjttddYunQpNWvWZOzYsWzfvv2+zpVtEm6oy+9pyAUCwaNJVEoITQFf5XZukD7D3I5Wwo7giUUolI8Kj0gChc1mo2PHjkRERCh+Tpw4QdOmTTEYDPz999+sWbOGqlWrMmPGDCpVqsSZM2eyfS4XFxfH77oUK6zNZnOS2ZGy4Krt06cPP/74IyC7u9u2betwL587d4727dtTvXp1li1bxr59+5g5cyYAZrNZ9Xh6vd7pvGnn2tf7xx9/KD6v//77zxFH+cwzz3Du3DlGjRrFxYsXefrppxkzRiM26UFJGzKhFf/UZPTDObdAIMh5JAm6zIHg3hB/FWr2hS6zcy90RbKoy8WDqSAdQqF8VMiDBAqTyYTValXIQkJCOHz4MGXKlOGpp55S/Hh6egKyoteoUSPef/99Dhw4gMlkYsWKFZrHvB8qVarE7t27FbK9e/dmul/v3r2Jiopi3759/Prrr/Tpk1qrbe/evVgsFj7//HPq169PxYoVuXgx41jVYsWKcemS0t2Ttp5m1apVcXV1JTo62unzCgwMVBxnwIAB/PDDD0ybNo3Zs2dn+l6yhVrNSd9q4FFEOc+jKJQIydlzCwSCh8fK4fBtEzgoPygT8YO8vXJE7pw/Ow+moonCE41QKB8l7G6Muq8otx8SZcqUYdeuXZw9e5br169js9kYOnQosbGx9OrVi927d3P69GnWrVvHSy+9hNVqZdeuXUyaNIm9e/cSHR3N8uXLuXbtGlWqVHEcMzIykmPHjnH9+nVNy19mDB8+nO+++46FCxdy4sQJPvroIyIjI52slukpW7YsDRs2ZODAgVgsFp577jnHWPny5bFYLMyYMYPTp0/z/fffO2WFp6dly5bs3buXRYsWceLECSZMmMChQ4cc415eXowZM4bXX3+dhQsXcurUKQ4cOMDMmTNZuFCu1fbee+/x+++/c/LkSQ4fPszq1asdn1eOoRYy8bGfs9s74TqSCKYXCPIPWqErWvKcJiBUfhBNi0cxpbFDNFEQIBTKR4tuC2HkQWg/RX7ttuChnm7MmDEYDAaqVq1KsWLFiI6OpkSJEmzbtg2r1Urbtm2pXr06I0eOxNvbG71eT8GCBdm8eTPt27enYsWKvPPOO3z++ec888wzAAwePJhKlSpRu3ZtihUrxrZt2+5rbX369CE8PJwxY8YQEhLCmTNnGDBgAG5uKhmHKvsePHiQLl264O7u7pDXrFmTqVOn8sknn1C9enUWL17M5MmTMzxW27Zteffddxk7dix16tThzp079O/fXzHnww8/5L333mPy5MlUqVKFtm3bsmrVKsqWLQvIVtvw8HCCgoIcYQNLly69j08lA7RCJlSYFaedeS8QCAROuBaUX+3GDlcv5fgjkgMgyFt0UlYC0wTcvn0bb29v4uLiKFiwoGIsMTGRM2fOULZs2SwpPIL7o3Xr1vj7+/P999/n9VIeGg/0v7T5U0Um6N2iQXhej3Sadr18V4r2mQt68TwpEDzyXNgHc1o6ywdvyL1M76tHwcUNCpWBm2fBnAi+lVPHY/bBXJU1DtoAJUXd2/xORvpPWsQdRfBIkpCQwNSpUzl8+DBHjx5lwoQJ/PPPP4SFiVIVmqQLmbh365rqtKKnlsHMjDPmBQLBI4AkgV9151qQ7oVyt0GBb2VZmQT5Na0yCaJFowAQdSgFjyg6nY4///yTjz76iKSkJCpVqsSyZcto1apVXi/t0aXbwlQrQoMhnJ0zjKIWlfpxAE1ez9WlCQSC+2DVCNi/yFlu1ci8fljEXYAlveSayL2WQMESynHRolGAUCgFjyju7u78888/eb2M/EVaq0GhMni1HA2rtzhNu1s0GM+afZzkAoHgESN0gLpC2enL3Dm/Pdlmz1y4fFCWbZ0GrT8Ao2tq042mY+DYn877NxUlyp4khMtbIHiMuBJziqMf1ePqhTPEbZurOsf9elQur0ogENwXWuXkqnfNnfOvGiFXi9g6NVW2+1tZljbhJiAU3NOVKNMboUgFSFNbWPB4IxTKHETkNwkelPv9H5JsNpISEzj6xwwqW45ydPV0/nFVDw9Y4j3wQZYoEAhyk1wuJ6cgo+oR6d3ZSXHKbZsF/hco4rWfIITLOwcwGAwAJCcnK8rUCATZJTk5GUj9n8oqe2b0o+7N1TRL2W56aR5NgaPWACobLjjmfWduy9GS/ehqtuBqNGRa11MgEOQx6WKjMSfm3rkDQqH2S7B3nvNYend2s3DY+KHzPBGv/cQgFMocwGg04uHhwbVr13BxcUEvyrEI7gObzca1a9fw8PDAaMzeV/Nvt3bUZbWT3F0nK6jzLW150fgXjQ2H+XBfDL/si6FX3UAmdwly2kcgEDxC+FaWk2K+aZqaFJObnNvuLPMs5pxl3mwMnPoHonekysq1ABGv/cQgFMocQKfTUbx4cc6cOcO5c+fyejmCfIxer6dUqVLZthy+WsA5+QYgylaGPua3sUgGauuP8ZE59eLeo3ag6j4CgeARwZ4Us3VaalLMnrnQdKwyKeZh0m0hLH4B4s5DcC84uARM6QqbS5JsOY3eqZSf3SrHUAojyxOBUChzCJPJRIUKFRwuS4HgfjCZTPdl4S5yVcWKAATrT3PVUoihxt+ooT9LQ8MRDlgqkoyRn/aep2apQg+6ZIFA8LBYORwOpGvksOVz+SckDDpNf/hr8K0MfX5Ndbs3H+fsdl85Ag6oZKPbzHIM5fC9D3+dgjxHKJQ5iF6vF51yBHlDi3D4bYiT+IJUjONuqcXgRxqXM9K4nB8tLahWZ0EuLlAgEGSbjPp1h+Rik4d0Jcmc0KpDCSKG8glC2KEFgscAW1AvrEZlQtg93JhkUY9fiq/Wh+BAn1xYmUAguG+ajtEee5S60Gits0QIBPfO3bUI8gyhUAoEjwGtpm7GapbDLf6zlQLAICVzVCrFXmsFxdwp5u58daygeomimH0wqQRcOPDQ1ywQCDKhRAi4equPheaihTLuAsxtBbcvqo8HhDq3hwS4uF9Zr1LwWJPnCuWFCxfo27cvRYoUwcPDg5o1a7Jv3z7HuCRJTJw4kRIlSuDu7k7z5s05fPiw4hhJSUkMHz6cokWL4unpSadOnYiJiVHMuXnzJv369cPb2xtvb2/69evHrVu3cuMtCgQPnVebluVV8yi6Jb1L++T/0S3pXXbYqnLcLYzahhOKuS8bV3M70cL4FWkKnNtskHgb1r0NyXdh3Xh5WxQlFgjyjlUjnOs7AhSrnHkv78yUwKxgTwratwBi9sivliRZnh73wurHyE3FV5Cn5KlCefPmTRo1aoSLiwtr1qzhv//+4/PPP8fHx8cxZ8qUKUydOpWvvvqKPXv24O/vT+vWrblz545jzqhRo1ixYgVLly5l69atxMfH06FDB6xWq2NO7969iYiIYO3ataxdu5aIiAj69euXm29XIHhofLP5DBtsoeyRqgCwR6pCouSqOjfKWgZIl+U9s45chNhe8uPcdlGUWCDIa7QKi1syqEWZHSUwM1aNgI98YfMUeXvTJ/K2mtWx3wpoMEwpa/lu5oqv4LEhTxXKTz75hMDAQObPn0/dunUpU6YMTz/9NOXLlwdk6+S0adN4++236dKlC9WrV2fhwoUkJCTw448/AhAXF8d3333H559/TqtWrahVqxY//PADUVFRjl7QR44cYe3atcydO5cGDRrQoEED5syZw+rVqzl27FievX+B4FLcPbrM2sbluAcrVlzUy1l5nGl9TnXup9aeACzdcx6Qv2fmhqPUDywC6gWCvEOl9WJ86GvQ6yftfbKjBGaGVuJPSH9nmW9lOCnfc/Okq48gz8lThXLlypXUrl2bbt264evrS61atZgzZ45j/MyZM1y+fJk2bdo4ZK6urjRr1ozt2+UyKfv27cNsNivmlChRgurVqzvm7NixA29vb+rVq+eYU79+fby9vR1z0pOUlMTt27cVPwJBTiFJEkkWK0t2RbM/+hY/7o4myWK979aLb7ev4iTrZdioOrdnijz2bhIA4cujqPBLYbZYqyvmHS9QWxQlFgjyGClFKTvg3x2AxP/+IqlwBe1rhZZV835cz1qJP/tVSgSBXLNy5EFoP0V+7bYg++cU5FvyVKE8ffo0X3/9NRUqVOCvv/7i1VdfZcSIESxaJP+zXr58GQA/Pz/Ffn5+fo6xy5cvYzKZKFSoUIZzfH19nc7v6+vrmJOeyZMnO+Itvb29CQwURaAFOUf48igqvbOW6RtOAjB9/QkqvbNWGdeYhswsmUElUwP3/bnBMtME/rLWVp271NoSgKEt5GSdnnUCAYm6+qOKeU8lRKq6yXLKqioQCDLnC5/xNE6axmtnmxBlK8PQW70yvFaoWTXvy/UsSdoPlFrKqW/l1LJChcooyw0JHnvyVKG02WyEhIQwadIkatWqxSuvvMLgwYP5+uuvFfPSdw2RJCnTTiLp56jNz+g44eHhxMXFOX7Onz+f1bclEGSKrMQ5k757TUaWzLSKXfjyKEAikMssd51AqP4EtQynWGhprTjed5Z2RErlKezh4lBCl+45z2TjXFx1FsVcvS0ZKY2bLKetqgKBIHNaNm7CVakQg41/UEN/ltaG/Zgw0yO0pPZOdlfzg7ieV42AeW2d5T5lRFykQJU8VSiLFy9O1apVFbIqVaoQHR0NgL+/P4CTFfHq1asOq6W/vz/JycncvHkzwzlXrlxxOv+1a9ecrJ92XF1dKViwoOJHIMgp7PGL6flpr1KuZcl8a1mkQrHrUqsEU4yz2eL2BiV0sYBcxDzM+Dcg9/IGaKw/BEBsgtlh4ehVJ5BfrU1V1zPkaI1M16JpKREIBA9M8ophHHcLY6BxLQCDjGs47hZG0orh2jt1WwgvrZPL9gz8+/5cz1qu8zuXRAUIgSp5qlA2atTIKSnm+PHjlC5dGoCyZcvi7+/P33//7RhPTk5m06ZNNGzYEIDQ0FBcXFwUcy5dusShQ4cccxo0aEBcXBy7d+92zNm1axdxcXGOOQJBbtKrbilVec86pdJtq1syf94bo1DsTs0bRHfjJtW5g5Pe4H1LGI2TpjHUPMLpXMER77HM9X2n/SKtZbjhVSXN/KxZVQUCQc7hknxTVW5KjlXfQZKgcFk5QSZmj/xauGz2s7wDQqHF285ya5KoACFQJU8Vytdff52dO3cyadIkTp48yY8//sjs2bMZOnQoILupR40axaRJk1ixYgWHDh1iwIABeHh40Lu3XH3f29ubgQMHMnr0aNavX8+BAwfo27cvNWrUoFWrVoBs9WzXrh2DBw9m586d7Ny5k8GDB9OhQwcqVaqUZ+9f8OQSHOjDgIalFbIXG5Vx6l6jZclMz5KUuEgnuaU5f0shAMRIvpyUZDdZjQBvx7mkkAGq+wYZzjIsYVama0lvVRUIBDnHnz7qnWa05Dma5b3jK+0xUQFCkI48VSjr1KnDihUrWLJkCdWrV+fDDz9k2rRp9OmTGgg8duxYRo0axZAhQ6hduzYXLlxg3bp1eHl5OeZ88cUXdO7cme7du9OoUSM8PDxYtWoVBoPBMWfx4sXUqFGDNm3a0KZNG4KCgvj+++9z9f0KBHYkSWLrSWWf3q0nrjvFI2pZMtMTKZXnhlTASd7L+C//mN50kp++Hu/4PXyXC99bnlY9rn/zlzNdS3qrqkAgyCEkiQ6tW3NXMinE12wFebZdB/V9cjLL+9lp6vKAUFEBQuCEThIR9Vni9u3beHt7ExcXJ+IpBQ/MuGWRqha/XnUDmdwlyLF9Ke4eHWds5Xp8skPWIag4qyMvOe27wzSU4npn99gbya+w3VadmabpDEkeyRUKM6NXLToGlwAgIvomZb6rjI9OJWs7uC88P9OxOXHlIRZsP+fYfrFRGSZ0rJa1Ny0QCLLHyuGqJXpuS+5MDl6nuFYo2PwpbPgodbvluxn3Bc+Ide/C9ulKmcEE715znht3AX4Jg+6LoGCJ+zuf4JEjq/pPnrdeFAieRDKLR0ybUW1XJosWkK0Ux6/ccXKXV/T15CXzm1ywKdufbbZWY43UkF7GDYTqT9DbuAF/Dx0dg4o75vy46xwmNALs/1uh2NyeYlUtlrKWbSevZ+XtCgSC+0HD2hhuHpRx7HJOZHnbO+5EyE1EKFpRfvUOlJN+1OZunyHHbW6fcf/deQT5FqFQCgR5wBKNeES71TJ9RjXA9fhkyhbxYGr3YLamU+SG353BGtfxBOiVgfqN9Yc54hrGSKOsGI40LmenrZeiHFDjox/ioUtGDVv9oY7fJUnii541eSEkgGvxybwQWpIvetQUZYMEgodFiRD+KvaiQvS5uSt/2OrL1wqtft05keVtj8VMSLnWXD8OwL1iwVC5vXLuyuHy3F0pJf92zpK3V45A8OQgFEqBIA+IjU9Sl6d0r9GyYJ65kUCHGds4efWuQj4nQb3szzyLSh05YNbtRo7fPeoPVJ1jtulpdSC1CsK4ZZE8O30rv+6/AMCv+2J4dvpWwpdHqu4vEAgekFUjaHttvkI02mUZk4xz2HH8onq/7pzK8tawji73eMG5/mzCDdW53NOQCx5LhEIpEOQBw1pWUJXbu9dkNbvbjlabxQK6RL4xP6uQTTF3p3Joc0dR9H9ul+RTczenfQ06G0U8XBw3jti76lbMG3fN2VqrQCDIIhpKXRHdHTYl9VDP5M6pLG+VjjtTzN15e7fJuf5sE/X4zOS6Q5BEvconBqFQCgR5QFBJbwp7uChkabvXZDW7245W2aCexk0MMK4DIMJWHoCXvPdy8PwtR1H0rrVK8LJxtdO+eh08f/HTTAuX6xAub4HgoRAQyopCSpf3LHMHZlo6q88PDcvZLO+U2Et7Y4TnDNsdQ4oYzn1KK6od06Jn2fNV/+yfV5AvEQqlQJAHhC+PIjZBadlL270mONCH7hm1VktHpFSe3Z7NVcfcdPJ5aupPAbDzdlFFUfST8wbhrbunum8RXbzjxpGZVVUgEOQ87WxbAYiwlQOgu3ETR6VSXAoZrZxo79ddIgSaj1OONQ+X5dml20I+qfSTamMERf1ZLZc34N1oUPbPK8iXCIVSIMgDMqrpaM/w/ueo3C7UkK7dfAFXg8qeUMPloqo8PfOsz0Aaq6KWdRNgpuU5x40jONAHH3elVdXH3cWpGLtAINBAK4kmA05KcvmdmvrTABTV3eG4WxjeEbPlCekzuVeNgH//pzzIv5Pvr7C5b2XaNa4PKBsjQLr6sxolib63tGLBucKqY4LHD6FQCgR5QHCgD2PaVFTI3mxbieBAH0eGd2xKbKI1nUe5kIeLqrs8vuXHJCHLJTcfAJJRzgNY7vo+Xxi/YplpAn7EEimVZzo9nOZdsxUkUirvuHFIkkRBN6NiTkF3o8jyFggyw15WRy2JJhNMzd5QlV9pOglGHoT2U+RXeyZ3Trq8yWJXr4BQzG5FnPatqz8qGh88QQiFUiDII1ZGyFaKAQ3LAPB7hJw9nVn85Pmbienc5RLxCQn888evuGLmkmdldIm3AEjWuF8lYXLUpTRh5hlpm9OceNwpVcjDceMIXx5F9E2lazw69l6mMZYCwRPPAyTKzD9bmE/N3RWyKebuzI6tCXoX2eJpMIFvZXlQJZnG4Q6/DyRJ4ujxY44HUFDv6uXiJhe8/s8mh8jESe5srPoRwSlx4YLHH6FQCgR5xMw+IWwZ24KJnaqxZWwLZvaWY5yCSnpTvUTWuzFNNs7luFsYvZJ+AqD43aOOsQI69QzsnsZNgFyX8rhbGJ4B1RiePIQoWxk6J02kb9I4BptHgy71piFaLwoE90nIAA155lbDXnUCec6gfODrbNhKr1q+2hbPnChsDiBJvPPrPhrcWqV4AD1x9Y7Tg6RUvAYAVfVyiIy37h6vHh2gqHkreLwRCqVAkEdU8PMisLAHAIGFPajgJ/enD18exaGLtzX3a1BO6VrKKAYyqxRv+zr1TWeooT9LB8MudktViNYH8HXfUIclIiM3vUAgyID9CzTkC9XlaQiOeI+K+gsKWUX9RYIWVtK2eHZbqO4Ozy6rRvDx4acVjRGOu4UxyTjXqVPPzGT13uJpa94KHm+EQikQPGJoWQK93eX4xR2nlRmVkVJ5DtrK3vf5DtrKoJvfjj6sAWCQcQ3H3cKYqJvjVLhcy00vEAgy4EHiGrX2zeh4vpWhUBn590JlUt3h2UXj3EutLZW1ciWJJo2bsd1aVTFvirk7jZq2ub9zC/IdQqEUCB4xggN9GN3auRSPVnZ3eLtK+HBXdSwj7LXlyukuq44X1d0GJEXhci03vUAgyIDitSBUWU+S0JdkeWYEhHK97liF6HrdtzKPk7yPjHK1c6evgznF3J1IqbyjqxcAq0YQvLASDQ3/Kea+bFyd7SYNgvyLUCgFgkeQOVvOOMku3FJv13g2NoHV1aYy26LsrxtlLa06HyDaVpQg/Sk6J01knHmw6pw2hv1MMs5VFC63u+kvxd1j5NIDeLk5Z5ELBIJ0zKzjXPx73zyYWTdLuxc9tVz+pWZfefv07xD1i3JS1M+prRfvM6NcjXYpCXvpi5sr6s9qxIK+bX5JqXgKHmuEQikQPIJMer5Gluf2qB3IigsFaaaXXdNrLLUBqKC/yLDkIeyyVnLap5T+OqH6k7QwRPK3rTZJRvUkoKXWloobh71G5uzNp9kffYs5m0879/UVCARKmqiX/qHJ6xnvZ1cOyzSVt70DYOgeKFYRrh1Tzr12LGdbL6bg1nsRYXxIqP4YR20lec8cpujqBWjGgjbSHxaND54ghEIpEDyCdAguoZoAk757zouNyrB0z3lOXo1ngrkfR23FCTEcB+QOOZX1F5hica4xacceZO+qd+63O8XcnWi3yoqkm3EpNTLnbzsLwHfbzlDpnbWELxelgwQCVSQJqr8APuk8BuVaQM0+Ge9rVw73zZO3N30iWzttVvX5Od16UZJ459946lj2EKQ/S2V9DO0Me4hPuMt4e2y1JGm+jzWmtiJp7wlCKJQCwSNK+gSY5fvPc/C//xT14LacuEb30BKYSOZdl8VU1l/CT5eaIT7M+DvLXD/goDWTpJ3keCfRy8ZVFHQzKKyPsfHq7ivh1hIINLArhbfOKeVnNmW+r5Zy2Gg4tNCIoczBOpTSyhF8/F8rhhlXOmQvGtdx3G0AY5K+lgWrRsC8tk77HrWW5JxbJeG9eIIQCqVA8IiSNgGmQw1/zl+Lo735L0U9uJNX4zk9fzDH3QZQTR+teawiKUrmnkLtncYWWVqp7uOju8erd2Yo6s2Jft4CQTbRUgpbv5/5viVCoHiws3xeO9jxlfy7Wq3JnKhDKUl8HVdPc9h+TdF6f+66ZNH44AlDKJQCwSNK2jqVE3XfctwtTLUe3NaCz2Z4nM/NXTlTqCEAwUn7OW8rBoBZkrPG6+mPcr2yustqqbWlonB5cKAPVTzusNI0npWm8fgRSxFPk3BrCQRalAiB5uFKWfPx0GB45vuuGgGXDqqPPfs5vLQOLu6HgX8ra00+MwX8g6DxqPuvQ7lqBENOD9UebzpaflWxiH5rbs9As9zfWzQ+eHIQCqVAkA9493wdVflSa0veLb4nw31HuyyjSdwqAEwJlwnUX+O6VAAXnZUDtvIcDPmYojf2Oe03xdydtm3apyqLkgTmRAbxG0H6swTpz9LP+DeFTLb7ziAVCB57Vg6HfycrZf9OgpUjMt1V0uqwA3BqI5z8R87kPvkPFC4LNpucxHN2K1yOlDO8vYpDMefEvEzJoP7lbYOPwoUupVhAN7q3BqCV4QAnpZKMaVNRPGw+QQiFUiDIBzzdsi1TzV0VsqnmFzhtqkDhpi+r7nPBVpjPkruqjhXVyTGTtfSn6B4RBskJULg8AL9YmgByeRBF4fKVI+BjP7ra1jhEw4y/88+97qK9mkCgRcINdfk9DXkawne58L1GSAoRPzhncs+sm3MZ3gGhXAodoxDZS5GZPJT9ub/wDqdF0mdE3ikAwDZbNUyYmbP5VPbPK8i3GPN6AQLBE03cBfglDLovgoIlNKe9cPFTcFmmkL3h8isVDHGE73qPF20BVErXni1AH0sH466sraPFOCgRypk4K/WLlAXdVQpev8nMgk+lzrl7TXP3mXENGZa1MwkETxZNx8CxP53lTUZnumvPOoG4HzzqJI8t24HCZ1arHPN1+G2Is/x+MryB4tHyOZZbGtHFuA2TzsqX1X9lZFNl28Uw/RrecF3q2O5v/If+xn84V7ob0O6+zi3IfwgLpUCQF2Sz+LB097qqvGmAjp51AnHDrDpeWR+T+Vrs5Ut8K1O2QjU5brNQGYpXqOXoLw4gXT6kuvstmweR0lOqYwLBE0+JEHAvopS5F5XlmbB0z3mGmkcQnRL3vNoiF0JPvnhYPZO7Zp8cy/AGkLotoG+B2cy3tOWu5MoX5udZHW1CSutClyR+SvFqpGe1S+v7Oq8gfyIUSoEgL8hm8eGvLM+pyvudaMJPe8+ztc5XHLEFqs5Jy3pLTcfv/9lSguXPbcvSkn/x6qcqv4crQ1sIhVIgUGXVCGf39r3rWXJD96oTSLTkxyZbEACnKEnLpM+41X62eia3JGl30LkPwjclceC6nndMi/HUJfGiy99cvHqV8cvSJAppJO9EWMvSuJlzOSHB44tQKAWCvCCbxYcjpfJck5TdbG5IBZjgsoi+VU0sPOGGBxnXgvzW3J6BlrGMTR7E60mv0j75f3zi9zlSt5QuF2l6/16Ku0eXWdu4HJfo2L9Su1dIkJStFhMlPUP074rAe4FAC63ves1emSp6wRHvcdwtjH7G9YBc3WGD6xgqn/sBui2UM7jbT0nN5F41QruDzn0w8fyLHHYbRD29fMx6+qMcdhvEhPMvpU7SaLtYyj1JXBeeMIRCKRDkAVKJECzN31bIbjUYh5SBGyxecgdgvqUNAHokQvUnqHZpObN6VsPU9yduVHDuirPPKlsPmxvkzhY/21qyQpJbuX19rjjjDwco3O/SnKf5Y9MO9kff5Mfd0Y7WisElvXHVKTt0mLCR6OYnZ5cKBAJnAkKheE1n+bx2mSp6WlneUkgY+FaGQmVkQaEy8nZOdskBfvfqqSpfWSDNdWafetvFY9bioqj5E4ZQKAWCPCB8WSSnNyxQyK5u+563fj2oehEe1rICg82jeT5pIh0MOwEopLsrD276hKdml6f4nwMocuInp32D9acZmPQ6VvSODjtpGZM0S+F+1925yKD9z/M/42ymrz9OpXfWysWJV43AgFJx1OtgTWIfpJl17+djEAieDO7dVJdnouiF73LhU3N3hWyKuTvjd6d4CtJ4FYCUmpfjlAdpHp6leE01/jG1ZIu1ukK22Vqdf1xbpgoS1OO7i5kv8u6yfaKk2BOEUCgFgjzgzeRZVEyXlV1Rf4GaByeqdpYILulNnGtJOhh2UixNa0UF6Vu7pWDU2RjqspKq+mh6G9djwgykXuSX2lqq7tfTuIlJxrkA9KgdmGFdul/du2mOCQRPPL1+glrpYpCbj89U0etZJ5BOhu0AzLfI8YjPGbbTI7SkelLfyhHw7/+UB/l38n27vIe1rEBdvZxlbo+5rqc/quyM1XSM2q48pb/ER4eevu9zC/IfomyQQJAHLLG2ZBhLneRLrS35oLZzco20cgR7WHTf39gQvVwPbqRxBSONK/jR0oLxlsEAVAlpBl5hcMDZdbXU2gKAn/aep2YXuS5d8X2fKeZstlanYttX7m9hAsHjjiTJbRIjflDK/50Ety9Ap+mauy7Zc5595hEkYiJG8uU76zO4kcyk34bDzTRlgzZ9Iv9UUu+alVyzHy6ShE6nSxVmoWRZUElvRune4GKSK3ukKtTRHaGEaxLTSqapQxkQyk0KUgiNB937dLcL8h/CQikQ5AFNmrdVdWVFSuX5ae95p/n/nTytepxzKeVEssuv1ibYrZTFNo1VVSYBeho2yq8p7dPsdenS0tB4TATfCwRarBrhrEzayUTZio1P4qRUkhjJF4AYyZeTUkn+dteo7dhkNH/5DVaIZpk7UHHW1VTPRzZKloUvj+L3xJrskaoAsEeqwu+JNZ28KJ4Gq9O+ALHe1e67ZJEg/yEUSoEgDwgu6U1fD2XR8c6GbYCk2vvWpcVY1eMMN4+gcdI05lmyV55juesHDnf229HaF/yl1pa82KiMrDBKEnSZw06DPH9nsW6MSRrE+25vZuvcAsEThWaizIBMXd7DWlZQlb9aYKv6DvsX0jTxXwAibOUA6G7chAmz7CaHbJUs61VXvQ93+muUqfNXqvMK6++qr1PwWCIUSoEgD5BWjqC4WRnzWFF/gWUBP6la+yqGNCPBpZBCZi8bZJaMNDUeBuBwkWcAuCl5ZrqGpVY5drJXihUyPUesAURK5dl64rqcKLRqBHzbhPpWue93/Wu/8JnrXMaUOZvpuQSCJxatLO99CzKNLwwq6U1hD2WprsIeLprtVgkN46Qku69r6mWvRlHdHY67hZH8e0rv8GxkggcH+jCmTUX8ucEy0wT8iOXNtpWcrlFS9eeZalF6XOZY2iP1cg7rETy+CIVSIMgDZt5urCr/9Ho9zVIbNy1uAOwqKvfntpcN6m3cwFvScBonfUHkFblupCMDXINllsZMcFmEH7Essaon5XjokgGJE1fjZReXxo3Iu/GgDM8lEDzx3G+W9/IoYhOUXbBiE8xylne9dHHL9V6FgFBcm6u3dPRpnOIKLxEiZ36nRStBSJJYc+AcvYwbHNeaPw+cdXKPhy+P4lm9MnmoqT6S8VvVO3gJHk+EQikQ5AGNm7ZmqrmrQva5uSs7k8owfMkBVaXS0n0xF8N2UTdQtj7alcaRxuUs073FEMPvbLAGZ+n8zQwHHTeIo1IpzuicE4FK66853OLdQ0tCQCh3GqYrSfIAbd0EgieG3j9D+pqSWfjuaLqcawfC6X+VwtMbQZKoGNKM9cWVFsz1JV6hYkgzeWPVCDnzOy3/TlK3lq4awR93ujLSuAKQrzV/3O7qNLdX3VIMNY/g+aQJhOqPcdRWkvfMYarhO4LHF6FQCgR5QPJvw3nDZZlCNtplGZOMc1kdeYm3lkU6KZWlq4RSomxlvrrVUPWYxXRxzHGd5iS3SnJm5zlbUYesqO4OIN8gjruFUcrgXJ8SUt3io385SJLFStKBnwE4UFwubCylb/MmEAiUSBIULgtHUxLa7EpkFr47mi7niPc0O+JINhvlr6xRDJW//CeSvflAdoqfZ3FucElv+jWqwEzTdIL0Z6msj+HNCpcI9ncTdSifIIRCKRDkAVpZmnYF7ue9Mar1KAGCr/2uKm9tOKAqN+jkC3ppvXoBYoCfSrwJDYYpZPasc4BiXm5UemctPW+9SuOkaTx/5jkaJ01jWqHxmscUCASkJsHYC4BfkGOQKVop8321XM4aHXQIDWPPjH6UsSkrRZSxnWf3jP7yRkAotHxHuZ+WtTQrcyUJfh9G2N7nKaFLde3Xjp4HH/uJOpRPEEKhFAjygA7PdNQsG2RH4S5K0xFjS0H1WnP3yxRzdyq2DEM6+Q8Aq907AXIBZYCQUj6EP1MZwKmESYvGTXN0LQLBY4eWla9xFhQtLZfz/oWaip7Ww+pGt6dTrYUHU5JlavaVX6N+1V6DfayAr/rcjMoigahD+QQhFEqBIA8IKunN80bnDhh2nqnmn1qqJ13NuI5t2jiVCfrO0o7Fxs7ZWkOsVMBx3he+2cG0QuORRkTwelxPGidNY6hZzgqNirnFkj1Ki4fdBbdmx/5snVMgeOLIjkUwPVrKaM1eqYpd3ZTknJTts66VOWgr67TLuEuj5E46liQok/Ig6B0AQ/dAt/nq55EkaPMxePpC/FX5XF1mK93YGXTQEjHWTxZCoRQI8oDw5VG8miwHsQfpT9M5aaJDgQM4dT1e/kWlZlzQgop0Ncp16OzKaBN9FO3NsoXxuE0uG3La5s8tm4fq+fdZn6KwLp55lraMMg8BJFo2aUb4xjuYbakFlAHMNrh5NyllTwkTZocL7kW3TZpFkQUCQQqZWfm00Co5NK+d7DIfeRDaT5Ffuy0A5NqVPmhUeUi4Ll9P9s2Ttzd9AjPrwM6vneemuLJZ3BXuXpVlu7+Fb5so3dhqCrOdrL5PwWOBUCgFgjygV51AoiU/mhsiCdWfoIUhkmjJD5DQATN61pQnajz9T5N60DhpGu9bwlhprUdF/QUK6WQltKL+IgA+utvYO60lSnItu2TJIB/WcBKAl4x/scZ1PL+UWEpwoA/9q7k4gv/TMrRFBQY0LM1k41yOu4U5XHD+B77ULIosEAhwNASID34J4q9yN3iQs5UvIzRKDiU3GI7kU1reKFQGfOWwlOCS3rypH8M+61PKHVq+q9l3W9UtnZ0OP3bFsVJ7+bVweei7wqHkCp4MhEIpEOQBwRHvKRQze7b1JONcJOC1H1MSbNRqxgG9KrtyVSoESLhiUT1HYV0C3roEANx0cj24q7rCqnMXJDZFMidS9eJyR/C/CTMg8WbbSgSV9GbryRuaNStFnJRAoI60Um4IUOCgbBX0PDgXvm2ClNWHsN4/s7loD4Voirm7sp1iuvP9zFjHQ6NDvn2GujWx0Uh1t7SWK7t4LfCrrlSIuy2El9bB3WswcB30/BGKVYKVw+D2xay8S8FjgFAoBYK8QONibc/yLuxpSu1Ok75mHFDx2Nccdwtjj+trLLFoKHkqlOSak2yKuTuNb/+J7mM/h2s9rYL7e8QFwpdHcfJqPJFSeadkIhEnJRBo85VGE4OZcY2ydgDfytSxyA+YVyVvIDXeum8VoyNZz3FcjfMt8R0l/xKZUq7IXsj8wGL1sBUtV/alA0qvhL0s0sl/5DjvE/9AwRKwb36mvcIFjxdCoRQI8oKAUK7XVfbnTpvlvffszQy709gpprvNgNI3uG4rmO0lpE0G0rI8Pt1nLDN7h9CjdkmHrJNBmUwk4qQEAm0irWWdmhh8a25PpErijCqSxOwibzHf0gZfXVxK3PNrmEjm8sZvnJS2Js3b8o25g+IQU8zdqdb6RXmjmOwa52JKQp09rlLNYprRd9vulUgf5715CvwvEDZ/Km9n0Ctc8Hihk7T6vAkU3L59G29vb+Li4ihYMPs3b4FAgSTBzLpw/bhDdNwWQJvkKYAc+Pj70EZypvfmT2HDR/d/Ls9isivKTr1XWWh7hglb7lJSdxU3kujaqimvnR8LZ7ekzksTc9Xys385fV0O9K+vO8TbLj8yKHkMTxUxsTgs2BG/JRAIlNz48RWKHHfuaX2jQneK9J6NI9BZi5XDYf+irJ2sVn949jPu/e8p3C23OWwrTTX9OW54lKPI2APydef8LpjX1nnfwRucPQ1Xj4KLm1yEPe01KG085oV9MCcLXhK14wvyBVnVf4SFUiDIC1aNUCiTABX1FxytDvvWKyUrk5BqJXAvlDJT/Wv7WtIItlurOg8kxsmvNVJc1ac3sfiYfBNr1aAuAw1reW1LA6UyCbB9huPXIc3LY8/wbmA4Qg39WXobN9C1aW05VkogEKhSpNnL6vITP2fNapeJl0JBirXR3XIbgGr6cwCcSCoku8aXDVJXJosHq/fy9q0sJ/zYr0GefvJrWsulmmvcNZ3SIcJingiEQikQ5AWZxFDuPH0jtfVit4Xw4l/gVRyqPgfYoGQd5Y7Fa/G163QaGv5Tyk0F5P1HHoRWE8E/CJ6Zwsw+IWwZ24KJnarRsveb6mt89nPHry/UDmSOzyKnRKIua0KEK0sgyACpRAhnCVAfvKvdvUreWQK/6khllHGRU8zdme/aVzm35buahwnxuCa7xl3Uy4hx6aD29zglS526L8PdK+q1KB0KZzH5NUlWaKkzSDkueKwRCqVAkBeoPNWnjaE8ee2uHENpD3hf8yZc/Q/+S2m7GLNHfrXHQ2mUFrGWbYZUtjnYbLKF4nIknNtKhSImAgu5A+B30tkdB8CZzY5fJUni6zvqwf5pM7wvxd2jy6xtXI5L1H7vAsETRPjyKHQ2s/pg09EZ75wSn6g7u1Uhftm4mob3/pU30hY21ygLZLoTLf9yIAPXuValhlVyljq7Z8vb6WtR2hXOopWVoTUAe+ZCtS6ifNATglAoBYK8QJIwR/ysEHU2bANSn/p71imVGvB+OVL9OJ1nydbH3j9x1rWi07Dh2B/oJheHGbXgTkomqD1I/rMKcnaolkstzQ0mfHkU+63OGd5/+Q+GgFAkSSLJYmXJrmj2R9/ix93RJFmsiBBtwZNOj9olGWge4+hMZcfsViRzN7DGd/Nt80CGmkcQHviDsrB5QGiqlTA7ZOSSzuz6YFc4rx9VnxfcQ8RYPyEIhVIgyGUkScL6+3BcYrVjKN9sW4nggndTLZFq2G8CKUWNPVLiprLM3WtIe+eTVKQK+/2ViqJU71XFDaZXXbmvuD3D216+pGniJkBWOCu9s5bpG+Tad9PXn6DSO2tV6+QJBE8So3+J5KQUwF3JVSG/muiSeSkdlTq0U80v8IetPielktxw8ZeFaQqbY1Iqrk7UGZwaj+1XXX6N+kV7fkAotHhbKSvTJLUWZWYxnhf2i7JBTwhCoRQIcpnw5VE8v8vZmgj2GEqJPw+clUuBXD0CpdPVqwuoLb9GLFHUoIt97ntmW9pnay26zVNw/V9xyl1arZBfjVjruAFIkkTl4l6EBHozyjzEUb4kokQP3Ht8B5JEzzqBqsfvUVtdLhA8KQxpVo4pxtkE6m8o5AFczjz+WKUO7RsuvzoePEfVLaCsQylJ0H2RHO+oxZ45qSEyVw7Jr0UzSaxLk6AHyAl8H/mSsGyYZvMFB6Js0BODUCgFglymZ51A1QLhx6uNYuabg9hR7Xf+uN01ta7buW3KA1zYC1Weg3JNFTXoKteow9PG+7MI+qR01LHjl3TWcQMYl2J97HbpM9a4judF4zoAal78yRFLtXTPedXj/rRXXS4QPCm8cOlTuhs3qQ9m1mFKM3mvBUXdJKqcWSBfA7bPkK2AK9PFO2aVxhkk5FiSoGwz1eEfLS2w/j5ctfmCE6Kb1mOPUCgFglxGVr5sdDYoA+29T64g0MeN4i1fzfwgR36HvXIrN7sFQFo1koluY+mbPI4VloZZXs8Plhaq8uQaPZBsNmLjkwC02y7W7EUvDQtlzzqlRKKO4IlGChmgLq89UDVuUfF90Uje62XYwF76oNv1jSzcOUu2AmaWNa5GRvGT9hjuo6uchqaYu/NRhLumtyXL5xA8NgiFUiDIZXrVLcU/pjepoFf2uPVLOicXO9dqeWan9kBVcf+IKmy5VYSTtgDaGTKIvUxHX+NGbtic465MC9uze0Z/hrWsAEgclUpxxebjfIB57QiKmEC/+qUU4n71AqnkX4DZm0+zP/oWczafFok6gieO8F0uzu1KgStRGxTb9sQ2p+9LSsmdtJ2tCuvuqJ9Mr4PiNTNekEdR+TVtdrgWGcRH2pMII6Xy/FboReWgPTFIrW6l4LFFKJQCQS4THOhDVJkX1Qcbj5LdTJE/Ow3drSkrkuYzW50Uzt0l+jHeMoP/XMNY5fo27jqNMiUaJOOiKv/HvS3BgT584T6P425h+Olvqc6bGdeI73dGK2Tf7zpP5Xf/Yv62swB8t+0Mld5ZS/hykagjeHLoVbeUI5ntF0sTAE7b/Ln1rNItbQ8tSf99+cJnPIw8yOWG79M4aRpDzSOYaXlO/WSN3oD4qxkvKOG6XMonbXa4Fhk83KZNImwryWE5CVV7AmDWmTKuWyl4LBEKpUCQy0iShOtFDQvi2e0kLBvi1EUH4GjMNRonTWNxqQ+wpTzxbyvcBYByF5ZRRX8BD52ZYjrtbO9VlvpOsinm7vQzhzsl9Ewxd6fDMx2RJIk1pnbab6jluzRu1kZ7PB2xd5OyPFcgyO8EB/qwt85UGidN403LazROmsbOujOoHFRXMc8eWpKeI5biJHkFsmlvBF+6zCTQ349eho3qJ1vxSmp5sIwI6gHfNIWfw8Atk1bCGVgXl1pbUMTThFuvhVzos5nfj8jXHpf4C9p1KwWPLUKhFAhymXHLIjEkxaoPHlzMhYsXVIfev1CHGMmXiTustIl5iSmVf6JyURMARdMl1ahxR3JliqUHp21yqZG0LrSTUkma6SMV8s7G7QQH+hC+PIp1cQFObrtzHtXkX6J+ZYlGUo4aQ1tUyPJcgeBxYOEJN2IkX7qFliRG8mXOUWePgBxaooaOGu+s4pnkvwjVn6Dmtd/51dpUfWrsycwX02yc3M/78kG4FCEXHzcnalsQuy2ULZoq9DRsxMNkYPePHxKwuCm9pD+1zyuSch57jHm9AIHgSSP2bjIzLc/R1rBPdXz0pVY00fvxpkuq2zttFx2Ak1JJvgwuRfJvu7N8Xi9dElvcXudPS236m98iRvLjO+szuJEMwFDzCBIxESP58p31GXyMFlallARauue8w213QypAEV08JZNOwcC/wbUgsWs0YrrSUcTTlNqjXCB4Qviqdy0Mej0/7JJ7a9cqVYgkixWTQY9OpwNkS2YRTxM37iY79iviaeJ/LnMp4pbazWqkcTkjjctJ8K6IR1waT4ZPGbh1VnsRxSrDtaOw6X9K+ZbP5Z+QMOg03Wm3S66l+eJiU6aw3GlsqbUl52/e45bLZTBon3prqSHU8auJSZIc71fw+CEslAJBHqDlsoqwliVSKu9Q3tJaEVORMGHm5j+fUzzpNHut2bP4tTfuZYhhJQAxki8npZKArKTGSL4O+SFzCcKXR6ZYH6WUGpStKaKLJ8JWDoM1EU78DYXLMqzFU1k6t6erUSTlCJ44vtt2lj5Tl/P8nt6sNI1n2/4op3hiSZLwdFXaeDxdjfyoUV3hXkK8/Is9uSYzOs+CHou1x9NZENN2v/r5ki87i3VTvidz2zQPuepK4jmbfD0pdnalaHTwBCAslAJBLjOsZQXePdqSXkZnpbKQ7i7gbC20WxEBJhvn0Mv4L6TUSa5tOJHtNSy1qpcKsuPPDWaaprM07kNuGYoy2ThXsd6a+tPyL5unwOYpBIWEUdijA7EJGScDRccmEL48kv91Dc72mgWCfIkkcfv2bfoa/yZIfxaAfsa/mW55ntj41FJa4cujiI5Vhq5ExyYQ5V+OT83dnTwWnboMpkigr9wlp8EQMCciLXgWXYJz6SCp3qvoAkIhADnJZsNHygkqZX3Cl0cp6ssWurID9PJD7ovGv2hsOAxWeWympbOqx2W4eTixeDmuX6LRweONsFAKBLlMUElvzrlWYp5ZmciSUKgKr5pHAZKTtdBuRQQ0S4ZYs2H4e9GwVmNEtn72Mm4gVH+Cprf/YHizUizJRAGdGdcoU2XSzo272ctAFwjyNatG8PW5ZxlmXOkQDTP+znG3AUw2zXPIetQuqbY3rzUrz4sFdgDwk0UuMD7Aa4+c1FOojDwppfXiDYvc3vGm5AlAnOQOwOUDa1NrW6ol2ajI0ne/GmoeQeOkabxvCXNkm9uJlMoTa/NUzI+1FSBSKq+4folGB483wkIpEOQy4cujiEu00MVV2QHH4+YR1riO50dLC8ZbBuPPDeZ5fsWLd4dzhcKOeVrWAINOzuLuaNyZ6RoSMWHCTDJG0rqr0lsiO976HhZ8zwDXp52sJA5avkuTsm357PA25zEVdAiXt+AJInQA7F+kOlSk6WDH76N/iVSZITHu570MtVWjE+e5TBFaJn1GWQ9X5qrEI157dgGdlx7GjWQKcYebeJGIiXalvdl/TK5t+VaXebjEX0JXNCVM5cZpKFjC6czpu1+lfai1P+ymJY4CFOauw4IZh6fTnJ51SjnJBI8PwkIpEOQyverKF9W3zS+pji+1tnBYCataj9HbuIFArrDM9B41OMUEl0WqhciBLCmTAL2M/3LcLcxRR86OliVyQVIzR1yn3fpx15BSbiTqV4IDfShfzPkGoobI8hY8SUglQrA0G+8k/87YU+6DncKQ5uWd5kw2zuWvu93oZJY9CiONy9ngOoanby8nfLmzArrwpJvDIrhHqkK85M6XLjPZdSyGZaYJrN62j4pfnmXk3sJ0WXKBy3p/eKol+FZ2Opb9OpVVws0DibKV4RtLRxonTWOwebRivKJfAZGQ95gjFEqBIJcJDvRhTJuK/GFr4FSKR26rtpHjbmGMNK4A5JvIFrfXCdWf5B3TYkL1JzDqbAD8ban1QGtZmi7gf6Bhjeq8noaNDDWP4PmkiVyUivBy0kjOP7dMURg5K60VfdxdxE1F8EQRvjyK+H+/dJIPtCxV1GZ8oXYgtUr5KOYcKKZewHyptaVq6EiqEmgPXVlPqP6E47rR27geE2YOxdxif/Qtftwdrdm9Kqikt1P3K3XkczUwHKGG/iy9jRu4KhXipBSgmHUvWXTJetwRCqVAkAesjLgISIQVUJb96WzYlmG8Yj39UQC8U+pOltFf5KrNWzHnZ3MTLqdrkfi9uSXfmDsoZMpSRPJN4R4m1fMaQ/sTLfnR3HCQavpoBldMoHLVYPAp7bBufNI1KKO3DEBBN5HlLXiy6FknkCnmbqpjUkhqZrUkSRyKuaUYX3HFlxXp2hrav7dqoSPBgT6MqO3OHtfXUh5KfwNSrxsjjSs47hbG8LgpLDNN4Kf1uzSzr8OXRzl1v1JjsnGu0wPwcbcwvjB+xTLTBPyQa+6ev3lP1arqIO4CzG0Ft7NQmF3wSCIUSoHgIXEp7l5qIHw6ZvYJ4VDoH/gmnVXIK+ov0NOwUbX3rxoV9Ffw1ccpZN1dtuCf0iLxoK0sAD2NG+mREhsZL8mB+2lLEdlvCj2Nm1TPUz/yHcVNo865OfCRr8LC8mxQcbzdMg7Ljr55T5QOETw5SBK/7DpFef1lp6Ep5u6M351a4Dx8eRRmm3KO2QZ14+We3+lLiDmFjkgSkjmRYseXZtgtCyAJ1xSL5QZMmOkR6pwQlDYpx58bCuUwLUs0yhrpQXEOkNQT8iQJLEmwfQbE7JFfLUmiVWM+RCiUAkEOY6/fNnvzafZHy4Hw6d1KFfy8KNBwkOr+S60tnepQ3i/B+jMAuOgkR0miAjq5xdspmz+kWDm0bgp2TM1Hqw/U7OW48NuTjTJDBOYLnhhWDufjw08z0OhcVeE5w3bFd0ErZvF2hzk8I81QZFcXdDVQIyBdy8RVI9B97Ee/5J8yXVZP479AqjUx+fcRTnPs9WcDucxy1wmE6k/wsnE1y03v4mevWYac4a32APyccYfiHJOMc9UT8lYOlx9Od30tb++cJW+vdF6T4NFGKJQCQQ4zbrlctHj+trMAfLftjFMRY0AOyK8/VCGaRXcipXKKEh32Von2ZJicor1xL18YZwLaNwUA6r2Kf7OBULym89i8dg4rZVaC+INKeosYSsGTQ8INVfEWazX21Zmq+C7YY6vT8mbbSgz9+x5HkooAqSXEbidZafXFZuVBQweonitJkr0GNyX1RD4An8aDnWSxdxKZYpzNFrc3KKGTLZMDjWsJ0Z9igekTh9URcDwAZ8RSawv1hDyNz4h7GnLBI4tQKAWCHCY2PkldfjeNXJLg92Gwc6ZizhB+ZpJxrqIO5cvmN3g+aQKXpMKsttTVPO8+a9a61aTFXj4IJMdNwSLJlwWbvZfa6RQ3+L2b6gdJ6bChdkNMz62E5AzHBYLHiqZjVMVNDIcpeHA2NpvSxy3HVsOAhmUA+D3iAkW9XFWPUaxAOnlAqFO8JYCrTvYaSEh0TprIvHRej3+Kv0yFWs69wf9n+o7uGiEwVfQxaapEyF20Vlnqqc6108+0iaCS3s4DGp8RTTS8IoJHFqFQCgQ5zLCW6mVx0j6dJywbChE/qM5TZl5LREt+fOiygKr683QwOvfuTpJkxa+ALtFhzcwqqeWD5jhaKxp1Nq55PIUeK9R5GbrMBpsNevwAAbWVB0jXYSP9DTEtL4QG8F1YnWytTyDI1wSEgt5FdciUFEvrqUqFbWafELaMbcHETtXYMrYFM3uH8Hb7Kqr7j1eRt7Nt1VxKYd1dWhgO0kSv9JSUuvAH41WSZYo0e1nzWI5jcpvJxrmscR1PR+OuDOd+n9xcPX46IBQ8iiplHsWcOvcIHn2EQikQ5DDBgT4U8VRmSxfxNBEc6IMkSZy7cZehR2qo7htVvGuazOvUZJnq+nOa53PVyf3PTthK8LL5dVokfcZ2a9VsrbmI7g5rXMfzovFvAIolnJQH9syGb5vAzLry64W9yh23T1cEz9tviBM6VqVMEQ/F1IPn43jKV9vtlpaMEpoEgnyFZzFVcRvDfuYU+l4hq+DnRWBh+XsTWNiDCn5eBBe8y/J0CTEGHc6hI5KEW/FKGS5lpHEFFfTKLOqK+guMTvpaOTHuAqx5i++kjhkeb5a1c6ZdtCC177dm/LRrSjxogZSC6a5emR5T8OghFEqBIIeRJAlPV2W2s6erEZvNxthfI2n26b+0SfpLdd8yl+Tg/cr+8gU1s2SZtMy2dmCgYS0bXcfQ0PBflvebYu7OTEvnjCc1eV1dnhinyPS23xDHLYvk7A1lX+ITV+MzLhtC1hKaBIJ8Rb8V3NOrxz+vcc0g6S4l+1naN5+QdAkxRQq4yt+JtKV2Vo1Ad3T1fS1xqV0ptGdc71sAMXsYYFC/TgHckjyJlMrTy7BRc84KSyMAGhsO07deKdX46Uu3Enid17kbPBDir0LdV6D7QpHlnQ8RCqVAkMOEL48iOlapTEXHJtD6i838si8G0FYUZ3gMoVUVX45elvt1qyXLXJcKqu1KT8PGbCmgF2xyO8fnDNszTspp+S7U7AO11Tv72GMo0xJ7Vz1WMrM+3llOaBII8gu+ldF7FnUSTzF3p3GzDBTKVSPgI190mz8FUhNi5po+59adO4z/eQ/SvvlyqZ19C+TvqAqHrUqr4GZrdcX2LHMHIqVyinOyeQoABpt2zLM9yUfrmjM46Q1etwx1ZKbvPqMsOWR/eLz+46t8cXM4nge/kwd2fyt7Q9I8qAryB0KhFAhymB61nWu6AbzStJzj90ipPPPMypvJzmLdmR1bCzeD8mtpT5a5UU7umnFXclM9/lJrC25KntyW3LO0zqK6246Lfdrz2LPJHVmhUb/Kr+ecMzlvNwqny++JWXZNZ9bHO0sJTQJBPsP0/HTMyLGU1yXZ+9DXc7d6koqdEOcHNYAa+rMcdxvA5COtHcommz6BeW3Bv6bT/KdSXNz2EmT19EcAiLDJ16Puxk0Ma1pKtghqZIqn57TN39FaMVIq75Toc0XycSip9sz0p/yU4S7hKQ+Pb59PF5dtR+VBVfBoIxRKgSCHGf2Lulv3282nGd06NTGnkeEwADeQLY7FrmwBYPUhZRFkewmh7tde4kj3LQw0j3FSRr8zt2Gw4Q+2uL1BQd09xZhVRYfb6dWWEeahxEjFOCmVVJynW/IEuiW9S7fk95hS+SdHa0W6LYTCcnynFNwLgOT9Pzm1cJMkiZebOfclhsz7eGcloUkgyDekuJA3rFmGC2YibOUoqrvDfEsbBt55WTUZxsH+hdk/X+xJJ5GrzsJflhBHHcudNjm+uqb+NABFdXcIWlBRtggGhELLdxT7W9xl6+ovliaArEy+bH6DeMndUey8kV6+li20tAbAT3dLUdAc4JWmymuCvXC6qnckXbKfIH+QpwrlxIkT0el0ih9//9QsVUmSmDhxIiVKlMDd3Z3mzZtz+PBhxTGSkpIYPnw4RYsWxdPTk06dOhETE6OYc/PmTfr164e3tzfe3t7069ePW7du5cZbFDyBDGmurky92rQcs7ecSdmSGGV+jYWWVhRB7mqx01YFE8nYL8D27hTuUhJfuszk9boFqFI1iD5Nq9ErpeuN3erwgnGrZpalQecsq3/nL741femoQwlQUrrCJtPrBEjXOS/58onLHJ6tWcbRWhFXL3Bxh4F/MznpBaJsZRh6S1Ysp68/4WjhFr48im7f7HA6p4uejC0yZJzQJBDkO1JcyE9fWwSkKnEvGtexxnU8o5NmOe9jj4us3MF5LIVt1ips8E1nwWs+HjpOV51/iwKYSCZGKsbnFvU2kA6LqN0jUfcVAIxuBTnTZzuzfEbTOGkaL5tfJ1ryo5dxg6MTzijzEFZa6xOWktQHyoLmb7at5PQdXrrnvON3p0YO9jUI8hV5bqGsVq0aly5dcvxERaXGSk2ZMoWpU6fy1VdfsWfPHvz9/WndujV37txxzBk1ahQrVqxg6dKlbN26lfj4eDp06IDVanXM6d27NxEREaxdu5a1a9cSERFBv379cvV9Cp4cXqgdSK1SPgpZSCkf9kXf4k5KJxm51MbbhBn/cczpY9zAcbcBTDLOwYSZwcbVhOpP8L5pAaH6E3RIXguJt3HZvxB3XTLzLW2ZZ2lHrOTp6O2dXeQ6lIn4cIuPXBdg0EnMdv2cYcYVhOpPUPXiMjAnyj/bZ8CVQxD1Ky+Z1lNDf5aGhiMKK0SP2oGKlm1pMdtg1E8HMlyPVkKTSMoR5EsycSG/F5PG3ZsuIYYL+6COc8FxgEaGI7S8ms6C+e8kpDObVBsQ9DBuTrm2zNVOorFbRLsthJEHof0U+bXXEspWqMbsfrV5t087BhrWOvXuXuM6HpOkHh+91NqS3yMuOMnTNkJI28jhSPctqV4RQb5CJ+XhlXrixIn89ttvREREOI1JkkSJEiUYNWoUb731FiBbI/38/Pjkk0945ZVXiIuLo1ixYnz//ff06NEDgIsXLxIYGMiff/5J27ZtOXLkCFWrVmXnzp3UqycXXt25cycNGjTg6NGjVKqUcZkFO7dv38bb25u4uDgKFlRPihAIQP7frfj2n4q+vC56+PnVBjw/S7bcBelOstL1PdX9/7KG0tawLzeWmmP8aGnBeMtgetUNRJKU1oe0dAouzqfdgjEZ9Oh0zqbTt349yE97Y5zkPeuU5H9dg3N83QLBQ2fzp7DhIyfxFHN3yj3/Hi/UTnkAWzkc9i9SPcQ5fCnN1UxP9VX52Qy78THcUi8zdvXZBaw8fo9BJ15zGpMGbUBXMsXNHHcBfgnjyjOzee33S8zqE4q/txvjlkXy395/Wen6rtP+nZI+pIk+ijddfnbIVhR6idr9PibRbKWCn7IUkCRJvPf7Ib7fGe2Q9a9fivefq656bRDkHVnVf/LcQnnixAlKlChB2bJl6dmzJ6dPyy6BM2fOcPnyZdq0aeOY6+rqSrNmzdi+XTaP79u3D7PZrJhTokQJqlev7pizY8cOvL29HcokQP369fH29nbMUSMpKYnbt28rfgSCrBC+PEqhTIJsnRuTJrZSy0oQYS1LJnkr2cIi5c6F2V6MvWedUhm2YFx58FKGWdv3mx0uEDyypLhvLSm3W3uyW0+3XanKJGRozVRTJtNna08xy21b6f0zl1zLOc0H8Fw7QlWZPGINIHyXS2qpou3TIWYPp3//H4eirzFn0ymSLFZ61glUjXmUz13eyXXdTtrqqKeZnvDlUQplEmDRzmj14ueCfEGeKpT16tVj0aJF/PXXX8yZM4fLly/TsGFDbty4weXLcmKCn5+fYh8/Pz/H2OXLlzGZTBQqVCjDOb6+vk7n9vX1dcxRY/LkyY6YS29vbwID1d14AkF6tBSq19IkqmiV2iiku8tMa2fNY5/2rJWlNdyVXFhhaYhRJ/GPpWaGc7+UenLFllG26YAM97ffTF5sVIbgQB+CSnrTr37Gfb2zm7WdWXa4QPBIIknQZQ5S3ZcxYuNnSxN6J4+ncdIXvHJvqDKUQyUhhtoDNQ9dT38UgKuS/N19zrCdoS0qIBWrRCEX9QcwT6u6YcRDZ5a/kyuHy6WKdn0DQIOrP8mNFXa/waEP6vHHtn2U9HblOcM2xf6dDdsASeG6fiFpIm6uJrlGpgpa1TC6h6rLBY8+eapQPvPMM3Tt2pUaNWrQqlUr/vjjDwAWLkyNDUlv+pYkKVNzePo5avMzO054eDhxcXGOn/Pn1V14AkF61Hpav9m2Ei/UDuSpYnIXDLWyQT+ZmzDQPIZIqTzXNGpNlrubcQyiHU+dmeeNsrWglTEiw7nPSFvw1cdpT9i/AIzOpYrWuLQC5BsZwNYT15EkSdXykB6trG2R5S14rFg1Ar5tgm73bAC6G7ewxnU8QwwrOWIr6WyNS5cQw7ntqjGRALttlZhvaYOvLo75lrZMMIwkuKQ34cuj6HBjOD+nZGVnxrfm9gw0j5G/Ywk3VOcE6c8Rqj9B+RPz+S1xABX1ypjIivoLfG2cykmpJDFSMUyYaWI4iO7KITkm1JLkVKhcqxrGmF8zbn4geHTJc5d3Wjw9PalRowYnTpxwZHuntyJevXrVYbX09/cnOTmZmzdvZjjnypUrTue6du2ak/UzLa6urhQsWFDxIxBklfQ9re1B6WeupybP2MsG2d1DNQ1nHCV84rNYS/JBuWQrREX9BTJ1jHvIRdAJ6ukQHb9XkJZJnzHUPBxI7YSjZXmwk1HWdlBJb7zdlEk53m7GTLPDBYJHEg03dtoQEQXdFsJL6+Difhi4Tk5OuXfT+QBAE8NhXjSuA+BF418sld5EWjWSXnVLcVIKIFR/XHU/+8Oq/brT3BDJTY9y8ney6RjVfcrrL8nrta2mqO6O6pyS+ut4ksBk4xxF0g6bPpGLpacrVJ6+Goa9qsXrdbPWnlXw6PFIKZRJSUkcOXKE4sWLU7ZsWfz9/fn779QyBMnJyWzatImGDRsCEBoaiouLi2LOpUuXOHTokGNOgwYNiIuLY/fu3Y45u3btIi4uzjFHIMhp7D2tJ3aqxpaxLZjZOwSAqiVSFaO07qG0BcYBBptHM6bEQqTmb2d6rjPWooxL1uhikwmfWjS646Sl5bvQZzlUfQ4ilzrEI43L2eA6hpcMax2yG3fNmpYHOxllbYcvjyIuJRPeTlyiRcRVPSREz/SHTEAotFB+h7dZq3JUKsWbbSoqH6wkCQqXhZP/yFneJ9fL252mgzFrD5gz4xoSFFCQP0otpbze2ZAC8sNqZ5dZiuuO4zsZEAoezl19skIN/TkOuw2isV7ju5quUHlqNQwJE2ZHGaIOlnWqFk3Bo0+eKpRjxoxh06ZNnDlzhl27dvHCCy9w+/ZtwsLC0Ol0jBo1ikmTJrFixQoOHTrEgAED8PDwoHfv3gB4e3szcOBARo8ezfr16zlw4AB9+/Z1uNABqlSpQrt27Rg8eDA7d+5k586dDB48mA4dOmQ5w1sgyC72ntaAIij9o86pgfSye8gXf24w3WUmdyQPxdivp124t/nLTM9V1nCdRvpDjlaKWeWaVJDltmZOAfY3UpIGfrI0kwVRv8LOmfDf76rHWZo2HlSyadbhtBMdm6DZ01sr/tTJkiN4IETP9NxBkiSkHV8pZI0M/3HcLYyyO8YrJ6dre+iw7K17FyzKZgVqfG7uSoS1HHtm9KPa1VWqc1ZZ6jPEPJKIO/KDrb2LjeI76SpbMH81PgtArM1D9VhafGF5IUuFyiVJ4lDMLSYb52bJoil49MlThTImJoZevXpRqVIlunTpgslkYufOnZQuXRqAsWPHMmrUKIYMGULt2rW5cOEC69atw8srNWPsiy++oHPnznTv3p1GjRrh4eHBqlWrMBgMjjmLFy+mRo0atGnThjZt2hAUFMT333+f6+9XIAgq6Z3GvSwRyGWWu04gJKVAcNqajgBXmk7O0nE7GncToJd75R63lchw7j7rU0CqW72Li1zK6GqKK8yAXMP1Dh4c6boeXpgHd6+pHuu4LYBIKY0CqdOr1uFMj1bWtlb8qShsnrOInum5w7jlUQy73V91rHqnEUqBVvLb5azFFI52WUbH81PwbqxeuxKgo3Ena1zHM8k412nM8Z3stYT/VVzKmPg+NE6ahosu6w8ZcZI722zVnZJ2iPrZyeJor4ahlaAoWi/mP/JUoVy6dCkXL14kOTmZCxcusGzZMqpWreoY1+l0TJw4kUuXLpGYmMimTZuoXl1ZKsHNzY0ZM2Zw48YNEhISWLVqlVNGduHChfnhhx8c5X9++OEHfHx8cuMtCgQKwpdHpaiLEjOM09ni9gYldLIimLazhJ1B+0pB7ey5syvq1bMqr9nkBzEf3V2eT5pIAq74cYNhSa+lBPffThmXrSGDjGuosuxpLEv6wvG1qsd0JZ1imNJ68VDMrQzXmFHWtlb8qSDnED3Tc4fY+CT+sDVwstit8e5BqRrpkmb2L8jaQas9rzm0y/tZFp0uwBWbT4aHWKqixDm+k76VOWWW3d4xki/jzIOyti7AW3eP70yfOSXtcO2Yk8XR7o0QrRcfHx6pGEqB4HFHvohKTDHO1myVmPZi/1qz8nKmZw5QTC8H09uApw0HqKaP5jvT56xxHe8I7lfjolk9SD7O5s5AszKIX6dTr8OZniHNn9Ic04o/FeQcIps+d7B/zp1SLHYRNrk+ZKvEv53jBDPpqgNwt0Y/iIvh+LPLmWdRVomYYu7O6KI7+fjw0/jpb2kew17mKz1af3s1hTgjquvVi6qntzimeiNsdDZsVc6NXAq2TC4igkcOoVAKBLlIcKAPf5T5he7GTarj31taOS72VYt7sXh3NNeemU2CLntxTBlRQX+JYUY5HrK6/mym8wvHH1G9ocRS0JGVbmdoiwoZFja3s3SPdlkhrfhTQc4heqbnDvbP+ZQUAKT28nZJinWOEwwIhXqvKPaX3OUay3cMKbWW/1sFMXuI3rOSxvpDQGq29nOGbRmWCrKHujxn2E45002WmSbgh+wdSV9JIf0Dh71g+YkyvbP+5tOiYXFcGXGRf0xvUiG9V+X6CZhZ9/7OJcgzhEIpEOQyX99urDlWT38Eewzlf5fucCD6Ft8cduFi008yPe5mS/VM59wPZ6QSDgvLfzY5nCRW8mSIeSRp4z293V0IKumtGgeZHtH5Jm8RPdNzB/vn/I2lo+p4cs1+ys/8dMqDZkodyutmd+Zb2uBllUsHeVpvAdDq6gIq6i/wu6W+I1v7lBTAa6eHOp0jQXIBoIAukcZJXzDKPITnbP8QmiZuOy7RrKikkL5811DzCNrzFU+FzWJ1lc8yf+PuhRXvw1FfMx0z+4RQqM1b6sdo8nrm5xE8UgiFUiDIZT4urd2nu6L+glPA/B/b9hK3cTo3JU/N/b41t6e/ZXyWixlnh7fNAx0Wlqp6ucB/Yd1dp+D+uHtmR6aoPQ4ysJB6uRPR+SZvGbFkP9GxCQpZRtn3gvtj3LJIomMTNNsVVpx1VVkSq9tCGHkQ2k+Bal0oZrmYYTjKd1Y5EztG8tVUWj108sPbCVsJhhpWssZ1vCOjOm3cdtpKCunLd52USvJfYmHGr4hiekwFfjM3yPiNSzYYugee+UR+P90WqE6r4OdFkcYvQrnmyoFyLaBmn4zPIXjkEAqlQJDLZJSFCWljKJX12YxYNPdpaYgAbLQx7M+xdQLYJDloXutmlT643255tMdBfqUR/yhi9fIGe7mgiPPqnZGE5Thnsfem9+caw+xlcVJ43rAVsNEjbT9v38pQqIz8e8NhGR47fSxkpFSejV7q31OA2daOmhnVLnVeVIQ79K/monCJ2+lZpxS/lFxK55TKEJok3oKZdWSXfqEy8vvKCHucuF+Kl+XcNu25gkcWoVAKBLlNQChSnZdVh6aYuxNYvRGAU302L512Bm4F/UWOuL7IlGwEz6dnfpogf/vvt/Ry7JaWhSV9cL/d8miPgwwq6Y23e7rON+6i801eYS8XdP6mel1DYTnOYST5ofBP17dx1ymV9Qp6OX7wp70abX0DQjOs8GBveZqWionqFuY91gpMdFnAFcmHz1S+x3NO+zjWiyWJqheXK1ziINGgfBEqF/eiYMOsZ30nB/fNWhhFt4Uw4A94bZv82m1h5vsIHjmEQikQ5AH39v2oKn/ZuJoCrkYKebho12fTwF1nxk8fx1RzF6ex87YimvvNN7emcdIXvG8Jo2/yOPomjXPEZXVPDHfMswfmX5VkZVDthpbe8jhuWSRx99J1vrlnEa7VPEKrXJAdYTnOWf5n+o7jbmEU1sWrjs+ydMqwaL901tlSN9fYk/9e2KzorGXnTse5UNg5g7uO4QQh+lPMNX3uiIe+EzwQgNf9DqZWUkhXXD2tS3zHqRtUemcte5ZNzfhNp+GPOe8RPaUR3FYvZeagcnsokxJbXqaxvC3IdwiFUiDIAxYVGaUqf9s8kC0nruHl5qJeny0TRhqX84bLcid5oP6G5j4vuvzNEMNKALbagjgpBbDMNAGzZEyTxS3xobk3VyRvfHVxXJG8+dDch7RJOa5GPZWLeyksEhc1WvoJ12reoFUuCETP9IdB4abqngiAzdbqFKjbL8PPPCrZ30k2yLKUO+uncM21jELu7WakUo060PNHaKeexFdDf5aK+gvcLNsRr+enwsiDuPRclFpJQaN0UYj+pMP9HWw+oLne9DQzRFH63mHYPiPTdoqiDWj+RyiUAkEe0KDTYD41d1PItlmr8retNiV93ImOTcCfGwwz/gbIWdVq3JbccmQ9ciykMmYz1d1lY4pxNj+4TsFPJ8fe+eni+MH1E740zsCuVCZZbFR6Zy3jV0Q5YvXO3birej7hWs0b1MoF2RE903Oe8F0uHLSVUR1rpD/Mop3RGX7mqwp0U5XPvttUu+e9b2Wo/yq0fEfzuIWeTsmgTh/fGBDqtN92a1Uq68/T27iBQK5w8Y56LHeyZHCSOSyzO2dptlO0XyuW7Ipmf/QtftwdLdqA5lOEQikQ5AHBgT686rJaIbP3+B12d0aKYrced10yEbZyFNbdddSRS0tBXdae5k9YnS0ddiKsZYmUyjvFbNrdXf+Y3tSsm/mccSf/M84mraWyZ51Sjli96Fj1WD3hWs0b1MoFpUX0TM9ZetUJpJzusuqYvch591BlLVfiLsDcVnD7ImddKzt5KZIkI8W8XFWPqfj7aZTqAWB/BjGKKfvd85G/ow0N/wHy9WCL2+uU1V/FgvP/kEknt2y1SDqnMQfxzi1cw1OuFdM3nARg+voTjgdTQf5CKJQCQW4jSUjmRPbqglSHvay3UhS734DUYsihhpMZHnZ+us4ZaalgUL+pARTSyVbEJdYWquOzNDK87fQ0bnKUD7L33c4oVk+4VvMOexkbNUTP9JwnOOI9vDQe+t63DABgzK8p8cQpCTFsnwExe2D7DIY3K+WIefze8jQArjoL77gsZlzLEsh9r2RebVYu9e8nSdBlDlTtrL6w0DCF4qogpXSR2wvfar6vjCpOGDPq/a13VjZ71glUmYgy+12QLxAKpUCQ26wage5jP1pI6q0XkTJuObbYolT8vjO3pXHSNN63hPF80kTu6ApmeSmnbX68ah4FSPQybFSdM8S4KtPjHC0h9xe29922x+r5c8Op/IhwreYd9jI2aoie6Q8BjZjEmzZPR4WE15qlJNGsTEmI2fW1vL1zFkELKnJWX5JzNl/6Gdc79i9weTevbm/OP6Y3aeKXxDLTBDbsikh1Fa8aAd82gf9+cz553VfArbCsTMbsgX0LlPGNKaWLwne5ZDuGO1OajHYSLd2jnuWumf0ueGQRCqVAkJtIUqYFe2slaiiaKfQxyorfdUlWHBsbDhMjFcOEmeaGg3hJt7O8nHL6K6xxHc8Xxq+oqVe3gMZKGbc+jLSV44MhYYq+28ElvSnialOJx5RvWsK1+mjR+Kkiomf6wyAglOt1xzqJb1EAgJBSPrxgt8QlXFc9hGSx8KXledWxby3PUvvGSkL1J3jWso4a76wifFkkhISpzgfg4FKYURPupFgmN32iGt/Yo3ZJR2WHjLwfWcbNB0o4/49ptWoV14j8h1AoBYLcZNUImJcDF2egqO42v1iaYEXHNONXivjH7JKEK1X050lMadOWlrqG4xnu60M8kiQp+m5LK0ewT9dXtSOHvT2jIPfRyvJ+s21l0TP9IVH0jFxBQQruCcBpmz+DzbKlLirmVmrySdMxqvv/ZG1BH+MGDljLKeQ3DUX51DTX6TvW/tz/tGMkC5aEJPWi9oSmUULjLmBa2I4J5jAaJ33BZEvvDDt1ZYnEW6pJOUElvelXX6k89q9fSoTF5EOEQikQ5CYaLrC0XAp9k3nmrCmd3YxbqKo/T3X9WdXxa7asub97Gv8FwE2nXs7nTgbZ5JG2Mk4u7K/iGqnOXWptydFLt0VpkDwifY9mEDGtD52UmMRw21AaJ03jZfMbjnJcZhup352AUO4YCil2vSZ5UdNwklD9CYJTYqkTXOQ+2d62W6qn82/+irYXpLh63Da1B8oZ3vY4zn0LqGY7RgPDEUYYfuO4W5gj1vqBCHW2nI5bFsn3O6MVskU7owlfHilKCeUzhEIpEOQmAaHQ4m3VIbMkfx2LR6/mOe8TQNZdTU/pLznJdlqrUEyfdfe3Fput1bml89Ecn23t6OSeirSVcyqwvsNahXPG0iRbbczZfFqUBskD0vdoBhHT+tBJiUnsVbcUMZJvmtquMmm/Owk6+cHN/r0vprvjSM6z57N4mOV4ZF2ZRuyhmuJY83mOCjHLtL0gx/5Ul5/dKiuTKoXNtSo8ZJuW78rXvzRIksT1ePW43ut3kpm9+TT7o2+J60U+QSiUAkFus+MrVbGLzka83gee+4q3eJ3GSdPYV/kt3jdnHHOpRX3DkQdYJByxybFd9fRH+aDAO7RnBvPSKbjfWdpx0lgh1YUddwFm1ufrs+2cCqw3MBzhoKE/k4xz+W7bGSq9s5bw5UKRyU1EvFreERzow4Rm3ooktfSZ9Tc7LeL5pAkE6U8zJnlwhsfTndlEHQ4rZL2kP/gmrl72F3f9mOyO1vCg2DPMHVR6Fjx9MzzkhZTuXLeNskVVrYxR+PIo1h+9qrr/P0evMn/bWQBxvcgnCIVSIMhNJAme+VRzuIDtFsx9mlmmaSx5swczvBYwwWVx7q0vDVX05/nbEsxr5pH8fb0wZ62+NNLLNzC7BaWx/hBJVkl+X8n3YNc3cO0IRqyax12apjxR7N2MWwEKcpbgQB/GtKmokIlyQblAiivZ5cAiQvUn+KTMfkyY+f1AjGJOpSpBtHc7TKj+BIH663xp7qx+vKAeqmI3nYXXTg8Fd+1Wq5qEhqkWNp9i7k5d/TEg9XsvXY6ChNTuW4etpdPt041B5tHMt7ShoCVWzizvMtupU07aB5y0FSEMGpqJuF482giFUiDITVaOgBXa7djsmBoOIdDHjZm3Gz/0Ja221NUcq6y/wAab7KZKMFuZYO5PlK0M31g60jhpGkPNIxj19FOyq2ySP2yfnun5eqYpTyQKnOc+KyPk7N4BDcsAOV8uSMS9qZDiSu6b/BMAzS/P47hbGL8E/KSYo/vYj8GSbMkbaVzBSJff1I93cj0LXHppn8+o3g3JQe2XlNtp3dF2S2LdVwDoatiMBT2dkybyvqUff1rroIuLBin1obGa4RwAKyxy7PTLxj9Z4zqeF43r5Am7v5XLGKVLygkO9GF0q6ecOnQV99SDSjctcb14tBEKpUCQm2iUBnHiz9FYZtSheWh1LtgK59jpbSohSB2MuzXnT7d0xp/rLDO9Ry2OMdX0DTX0Z+lt3MBVqRAnpQCWH7hAcs3+WV6D3UJZxNMkkkHygJl9QtgytgUTO1VTlHrKKloKo2ihlwEarmTvxoMcv0sh6nNUSbjOAPMSAPZbyyuGDlccCs9/AwX81Pet9yqck8sB2ZXG6E2LUv+e3RbCS+vgwj6GuXzIdls1qumjaWGIZINpDO0Ne1QPu8lSndctcuLR32XfUj+3SlJOia3jnDp0bTX35BPTd4p5RTxNwpL+iCMUSoEgN2miXhpEjfWFurF/xTQC9LGZT84iWo7o15JGYFNpmfapaS5zTJ8Rqj/JCrf3KaGT15K2DFB8opWKs65y0FY2S2uwWyhv3E0WySB5QAU/LwILewAoSj1lRmYKo2ihlwEF/OWftDQaqUhSCd/lwvdmZaziZmv1DA97wKUWIYZTClm14zNhzTiIvyIL3HzkV/eUDPLTm6DbQqQRESS1mcyX1X/lpYShcuKL2YJUqAyc/Acu7OUr87uOguojjcspp9fuuHWq0suAjeI+nnQz/06Sf23lBJWkHADf5q+qHm+tSRmv7elqFA8njzhCoRQIHiJO1pz9C7K8b9vTk+lv/jlH1+Oi0mb3hs2Tr12no9domVZDH60qB/jbGsoqj4n4cZ1CZC2jfKm1peN3pz7GaRCu00eLzBTGJ7GFXqb/o5IE5kTYMxfiU5Qxu2J54IfUDjU2G31qFqKrcQsAyZIBkBPiAG5U6OZ86Jbv8mFCFyc5ANfSJOQl3oKyTaFgAAz8G7otAN/KjNt4h0rvrOWLvcmclEry3bYzLH//BXQf+zmyvLPDS6dGcMJ/At97ToML+3C9vFc5YfsM1f2aNGvDztLKMKAf3PqwMV55bYiOTSB8eWS21yXIPYRCKRA8BOzWHKeyF9lxa+US7hq1JzNjsaUlNQ2n8L8dxRrX8ZTS38h0n+/MbR0t5yBNH+M0PCmu0/ymMGemMD5JLfQ0v9/p/0dXjYCP/WDr1FSZXbFMuJHaoWZmHWp8Xx0PnVxCx6STfQk3JE++rLSYwv7KpBeAK1u/Z7+1XNbaI96+CFcOyZbHwmVBkoiNd05wWZLmYe9+cLl1Crfrh9UHn/nEKSkHgGWDqH9utkLUN3Exk4xznabeuHt/1ypB7iAUSoHgITAuxZrjVPZilwsUq5ylYyRKxswnPSBHbIGOm5gaGRVG72Pc4Ih7KqyLz9L5ZAtM6k3F0cc4DY+76zTLysgjRmYK45NUkkjz+522rE0W2qwCclxhkzdUh0ro4xh5rA+6LZ85jfknn+UL41cMS6lTOd/SRvscN1LaqqZps/h6vQKKEkYAkVJ5LoVkPSxHQXqXfnpWvKJMyrEXUXdxV52+VEW51akk6ggeHYRCKRA8BNSe/iGl7IX5XpaOES+pX2j/NtfIcL84yZ0YW9bKhnigXYZjnqUNCbiqjt1vopCPLoFJxjkA1Az0pquKy/txd51mSRl5BMlMYXySWuhl+P22szILbVaL15T7W9fsA8VrZXsdVYt74a5LZqmlGZ4ZfJedqNmLKheXObKqTZgBiSKeJnSH5SzvW5JH9hYTrx1f6SAlKedS3D3+/qSHrNwe+N5p2qXQNxWeDDsiy/vRRiiUAsFDQKtn8tDmT0GPHyAgXcC6R1HF5nfmNvQzh6sqbq1dMlY8vHX3KKm/wSZLxgH9AFG20pous5eM6yitv6Y6FqCPJdJaRiGzSFm7nBRJsWZGnI9TtTo+7q7TLCkjD5u4CzC3lewKzSKZKYwZtdB73ND8fqdVeLJS0eFSRKrV7vJB1SlXClTV3L3SNbksT0/jpqx3tCleC+a1Q7dZroebNsHuxt1k3rDJTRU+MPfL2vGKVsx8DkDtgUglQhzW+Rka7VkB/KNXiRah+RChUAoED4HgQB+KeCprwRXxNBEc8Z5cj+1CuoD1lJuPvTtNV+M21riOf6AM7wXWdo5uFVqYdDaeM2y9r+MHGc4qto06G9stlWmcNI1uSe9wG/Xs4ZmWTo7f1dyhj7vrNEvKyMMiTa9mYvbIr/bEkEzITGGMvaseOqEV95bfYkjTovn9TlvWpmkWXcf2UjqtPlAdtt5NiU22Z2nrDJqHSvJ5KvPz3bupKra7mLffKUaM5Mt2W3XibOpeEgWxZ6DhCKWsXHPneee2K6zzvdLUo1VQrQtf+IwXLULzIUKhFAgeApIk4emqfMJ2ddFnmpRTRS9b4aKszkH4mudSucFcsBWmseEQAZkkyhQwJFNRn3UrVWb8z9qHGMmXLoZtFOSO6hx72SCtDi2Pu+s0S8rIwyJdr+a0MXWZkV2F0U76uLf8GkOaFrXvt1NZm4BQ8CyW8YHSltJpNBzqKkvo3A4ehLn7EhgRAf1XQpXn5ILiFdupHs4gZfy3kCo+A71/Uu2Gk+pilhyFxr31WQjPsZlh17fy73XlbO3k09vk7SrPya8+paHbAoV1XjMBqOEwnm7aTHXocXmofFwRCqVA8BAYufQA0bEJCtnFW4mM2aZno//ATPf/1NqTb8wdsnQunWQlQS9bA//2lPcJ0Mcy0Lg2030bkrUn/vQJQtdsXmy3Kl1xU8zduSr5sNI0ntop5U7UiK8mJypodWh53F2nWVJGHhZaDzQhzgWns4pdYcyq5TW/xpCm5a1lkU7f7+jYBMYtS/c/aiogv6YUEEef8ncPTulyk7a/ddyF1LJiKfMLXtyGqURV/p79luzZOPK7PH7c+bttcS/KtwGTaJw0jVUu6grnwSvJUKgMRCxRyDsbtmFPlptsnKsoNG5ns6Uq122eqsfFKiuKVnMiX1b/lVeThzOz6lIsRVL+9k+1gsJlGdYi1YIaKZVnnjldjGm9VyEgVLQIzacIhVIgyEHs1herzaY6XjvqfVpc/k51LC29Det5ISUm6oaUeeFpD5tsDWx9d3U2Vps1fjCn9t5eY5FjP4vp79DQ8J9i3svGlfQ1/k2Q/iwV9JeQSjvHSN0OHsTLvbppdmiRJInr8fdnCcsv2JWRtL2LVZWRh4FWHdT9CzPddWgLdXfqkOayPKikd5bi3h6JGNIHZNtJ9fjIrenlvZbCyIPQfor82v17+fX5b+TXbguUYQiWRFmZbPMh0vAIkrt8x+zNpzHFa3sRdhV7AQBLwi0W7b9JjORL1aQI1bk149bLZYxilcXQK+ovMMk4l+AAL36TmqruG0tB9kmVNNcB0G1nGb7Ym0Rr/QGG/tcT49aU7PS938FHvgRFTFBY5xsZ5BJDUoplk9OpcaAPu0WoIOd5+HVJBIIniHHLo/hJI6kEYIm1Ob2MGrFDaeiZJsC+iE7ddfywmW9pw4vGdbQz7sVNZ2GhpTU2VCqjp+CjS2SYcaVjW3dum9Ocghdlmb1TS3rGLY9i/dGrqmOPS8mQrSeuOfUunml5jq0n1BOgcpTQAbB/kZP4eqVeFHWerWDJbvUC90v3nKdmqUKEL4/SjHub3CXIIRvWsgJ/H3H+G+enDN7XW1VUraH6eqt0CSq+KSXC4i7AskHQfREULCHLCpWRX1cOV/5Ndn8Lu79ld6GO9LjUk0CuMMT1nOo6Bie9zqbzNQk33uZF4zp6G9cz2/Is223VKJ9BVxs1llpb0uvKVHq5qF+fOht3ZnqM5a4f8KOlBUusLVWvczPjGnEjTejEUPMIEjHRJDGUySOHykXg7XP7hODmYiCwsAcDG5cl0azV50vwqCAslIIMyc+B83mBlvXFzlSXbx7auaeYu2etyLEK7yWH0ThpmuwuK/YKyYWeontV2b1VNEWhDTP+zYvGdar7L7K00j54j8WyNabvCtkikwEZfX75SeHIiA/1c5x6Fx93C+N9vXMh5xwnIBTqvaIQfWduy6LoIpnGMW45oW6V25KiCGclmUqSJCoX98LdRXnryW99ml+oHYi7izJ22d3FwAvpS1tlJQlKIwzhH9c2TDHOZovbGxTTOXehuq33oaUhguNuYY7v5UjjCg67DXK0S8wqB21lOSqVYom1ReaTM2GptSWRUnnna1HLd2nUtLVCdFIqSYzkK3fMKlQmVQHn/luECvIOoVDmYx6msvekdCvJabTiyOx8Y+2U4fiD0NmwjU4GZ6tgWuabW5OsUyaE3MSbRba2tKpfh6tSIeJu38J08ySenlm/gNfTH1VVZtd494Bt08BggqdaKm4Yamh9fp4mw2OTlLPDRz02dlehZ3NnASluxfkWOX6tseFwlorHv9FavTyM3SqnFvdWwtsNv4Jujm170fp7ZmVISJIlf1mfJEnCnG7NZqtGp5zMkqA0whBGJ0zNsBSQh8HywJ1t7ATrz3DcLYzexn/5PqOHw0yYRXcipXIAdDJsB9K4s6N+ZfQv6mEdatZeQf5DKJT5kNzIknzcu5U8LIJKejtl8KblV2sz9lmzUNrjPqiov8AJWwCDktW7bgC86PI3JkkZo1jQxcqWsS2YqPuW425h9E36SR444OwaVeOUrTjvmcMcN5C0tEr8O1vlaYIDfXA1Ol+W7iZbH5v/vXPuVZyU7ynm7pxzq5I7C+i2kOPPLiNIf5rOSRMZak4t+ZJR8fgXagfikc4q52FSWuXscW/96stVCi7GJSquT1pF6z/oVC1fPayGL4/Ckm65FhvK/9GMOuXE7EmtARo6QHWK2+0zGa7B2OFzLrhXdvpf2mzNvP6sFqtdWlM3g4S6zBjCz46WiUPNI2icNI3xif0c8aJDmsuZ5Gnjh/25wc+G97JVE1XwaCIUynyIVpbkyKUHsrR/Viybj3u3kofBpbh7hH74tyJGSI3q+rMA2B7C/XO2tQP/2GqrKixaNxpDQIjsWtK4sQFcldStg9utVSmvv0RDwxFGmYcwPHkIUbYyrLPKCTcuSSl1NLNYnkaSJHw8XFTHHpeSIUObleO5dJbkzoZtDGlW7uGfXJKgcFnO71lJqP4ELQyRREt+2DN8MyoeL0kSyValVS453YPszD4hdAgqzvc7U2P+0mZxaxWtf+OXyHz1wJDevW9XkPpWTfMwuXK4eqccj2Jw9b/Uh6wSIXJZneyy4hUm6GY7HuTsFud696kQHqI8773cl+GWEZy2ZdJGMQPs9SzV3NldQwIILenBYOMfhOpP8IpxJaMLbaHIrYPZqokqeDQRCmU+RCvOLOL8rQwtldmxbD7u3UpykrSfa2xCZpnIEsPNQ1huaYReO7/lvnnRIJcTSX+Tec6wnc8sPdR3aj1Rfg0IdapP95O5MfMtbfDVxXFHcm7DaM/0HmlczhrX8bxs/IMa+rPESho9wO1FnDV4a1kkV247/3/XCCiYr2LsMiL5t+FU1CszVivqL5D02wiNPXKQFBfs01flrO60XVJAVtrTPnCm/f2tZZFY0hUvsNhQZKdX8PMiSSN5IvZukmacpf3c+YVU976kSLCqdml5qlKUoFEDNiEl+SobNUC1mJvQ1GEJfN8ix0G/Zh5Bi6TPnMp6ZUYhXTzfbTvLcVtJxptf4rbK9z0zlPUsZdK6s/fM6Mey650dJc1eMq6j272f5cEc+DweV/JLLsN9KZRbtmyhb9++NGjQgAsX5Avj999/z9at99dxQ5A9tOLMomPvZVjPLTv13x73biU5SfrPNSMmG+cy2zSdLsaMYx3Tcs0mK2cbLUGZzJQzoU2YGWoerrjJDDWPIFIqT6yUro6ciwf4VU+1CkT+AsDdosEA9HDZ6gj499JlXtalhl62TPU0/us82Hy8bI3JAK1yLEcu5U2m+8Pgbzf1/s7/aMhzEq3C+kutLelXL5BK/gUcD5wdZ2zh83XHHA+fWzWSctKXysmoHmVwoA9hDZyvIa+3rpDvYmRXRlx0rtmYVinKaqecWv3ldqwZdMBR4zefMCKlcpyUSmKRDCwzTcAsGWmtP8BG1zFOZb0y4ltze8ISR3PjTiImkmlsOETBLHzf0/OcStjLa81SFcyKXlk4Zs1eqdej+2gR+jiR33IZsq1QLlu2jLZt2+Lu7s6BAwdISpL/Qe7cucOkSZNyfIECZ9Q6baRFq55bduq/Pe7dSnKSG3ey+tQosVKn3gFCi2uSF5ttNQAoqo/LdH5n4w6Ou4Xxk+lDzJIRf27wpctM7kjumDBTgHRrNScorQLF5KQZz+vqfYUfiH8nZWp9cCq7ksKoVo9HhjdAkzt/qsvj1eU5ybhdLqrhEJFSeb7fdZ7K7/7leDC6Fp/Mr/tkg8F3285wUcM6kv5vllknoBUHnJWDL/4+ka9c3iC791v2Gas+GBomW/wNWbDy/faqXLRc0k5MOmYLcJJ1vrWQScY5TiWofrWq15HMiBaGg5yUAuh0/hOOuw1QlP/KEkE9kV78CzejjpWm8fghh7rUDPSma2hJxzSftuGZH2teO1g5Qrb0bpwsx5v+O/mJdIfnt1yGbCuUH330Ed988w1z5szBxSU11qlhw4bs378/RxcnUEet00ZaXm5aXvUJJrNOFmnN6o97t5KcRKdT912nDTwH+MRlLksMEzWPcz1NAfOfLLLiWUx3h64p1ky79S8rFNHF85vrO7xqXEWo/gTfmT7juFsYJp36TetujT7YbDZo/JDdTWmtDyp0DS2JW7qkHDejXrOodn5kS0H1bO4tXg8/yzs2Pkk1HCKrpP9PdzPqFQoDZN4JaNLzNVSPnd+8HxX8vPCr0tApTETRTtGjSOYHavK65tB8SzsaJ03jTfOrquNFdHecSlAtc32fg9ayWXoPduyFzT0bZN7F65BV5e90fB3/rlpAadt5gvRn6Wf8m0Au8+6Vkfzv5w2p80qEcBONcJi03L0mP+hGfC9v718kb6/MhbCQR4j8lsuQbYXy2LFjNG3q/ARUsGBBbt26lRNrEqQjffyEWtuvtLzwzQ5VN7ZaBnIRTxM1Ago6xVY+7t1KHi6Sk9XAhJnFFu0abzclD4rq7nBXkh/SLlOYrdZqD7SK4rpbDEhxV1fPQBmdYu5OtW+v0+qLzapxlDnKvHYZWinDl0eRmC5QL9Fie2SfyLNC+u/vGdfKzLMo3dtLLM0565pxF5KcYFjLCk4xd2mzvDMj/aOA2t8ms7aEHYJLPF5t9eztEz39lNsA/VZAg2Ha+9Z9Rc4ET/+dK1kHgEb6Q8RIvqp1HaeYuzPT0ln1sD66u9l5BwAspxUtn36GxKIZh9ZUN6gUuE+MpcX11HaOw4y/s8XtDUL1J3nRbVOqdXHlCArhXFNTQYlacEnj+35qg7r8MSW/5TJkW6EsXrw4J0+edJJv3bqVcuVyIUvxCUIricapvZcKN+Kd3VPjlkU6ZSDfuJtMq6mbnGIrH/duJTlJeutZ+rgqe+JDT8NG1vkOUsy9YZN7/RbSyTdgT505ZZ8VNE5pS/awedm4mhqc5I87PeDYX7BZbpdmt2BdsKlbWe753KcbOqS/5tDjFLurFf8EsqIAEGGTr5mtDfv4P3vnHR5F1bbxe2ZnSxJSCUlIQu/SCUWkI4IiUlSQKihFBaSKAuKrfq+K4itgARUQRERRISgoICBI7y2h994CIT3ZzOyc74/Z2Ww5szu72U0W2N915YKdnXKSnZ3znKfcjxaFPg3p3cjMx3urjuJOUBWbnLuzJNH1wYBDW0UZ+89GTVvCB6atHiHAs/MlozD3FtB4IPDsvKLPMaY2yNmNyscfWCTtm/qb7XZjFj6puQwjrYx92bMsKy700OzEbRLh8P2cwffBW/wwXFH43tKYwffBfqEKpq5MRU6m6/nFHeIOfV6UVpOr4tz59wBRQSnD9HA5NO6356HbBuUrr7yCsWPHYs+ePWAYBtevX8fSpUvxxhtvYOTIkb4Y40OLUhFNYkSQ64MZx482XUHOJrtAvajwg9KtxJss3WPr/VPqNqFtOhiP3v7JZltZNsdr43Clb5lP6HI8/8cPwjTdjwhCAbBmAiAUYGNoT0wX+qO1cRYG829hIe9YMBKUcQYAcEkjPdzSRJVC6JTWfzI0cez71XullP/EgOAckXLiGrHnAUjdiOZe6OqTClfrhemhKxnIy8tz8J47+h4dySwQHHKoaZ+NUh6s9fY5A5pI2qfd6yr2db8vWDVGyn88vFR6fehH6bXV5zgzYio+4PvTj2/3llR5n3bKdnvaKQxj/rAy9gnG8SMtigsLhc6YxI9AP24TElipmvwHQepC01OzAy01x1GBvYss0flcsVp4FEBR2kPfZhXxRcx/8avQxo0/gkqSBjvmTNjTcjTQ75ci5Ql7nnjX26Pya+63Wga3Dco333wTPXv2RIcOHZCTk4O2bdti2LBheOWVVzB6tBPXfgC3USqiCQ/iHPLM7HHHk1i1HL2vcojOtuow3MD57Y1cmvyZcsPqFcFADb3tWYsjbyMMyqkKxcFIOJdhLg0cFw7ppAxm6r5FC/a0tCHzKgCgU/bvOG0YjJGaVThLEtHKibd0fN5LaG2cBQMjKO5jgwvpoAfFe6WU/0REgu+Ep+gHufjbeIL1wlTJey7LBrniTrb0THL22SjlwVrnWj4wbfXyFDxuVp64k0I8Fpi6YZudDuwxQ5JUCa6g/1r20X6oVlYyCKdzC7BWP9WiuPAytx6r9P8pqi4H8CK3ARfFGNRkr2Es9zsAIIzNVxz6CbECXhfGWNIe5MXBc092QkPWuai6uxjLJAJlawCtJ9J3CIqS/j37j9RNq2F/OFqfjHn7w8P9VsvgkWzQhx9+iDt37mDv3r3YvXs30tLS8N///tfbY3voUS5EYBzyzOwZ2d7xWKWinClP1XHIrdRrGOQW2hogmQWCoiTRw0zV6CIpnuncAsV2abr2Cg9TL6BnBBxk6+L/eHpnjsnGl7FLdNSli2Kce0hlkWIp724WLuoc76tk/fsYqfkD0/iXXA+07rNFBQsK+Kv3yl0tOKX8p+6XP8YK/fsO2y9oa7r823iC9cJUqVXfMpUt/LLyeWyc0BbvPvOI4mfzIObBKqIkDdS26LsuP3flDjR5RHrW1ik0/z0SkooMKmsWd8f8nFEAlD83h0OEzqr2A4BgSPdFp5bNcZYkWhYHDRLC8K5mLBa5ca7NQn28WThUMU9cn3MV+LiCVNEeFGn7pkYH5Kcjt9FQTBBG4mZGvuS1dXCKkIdOo1IpquivtQweC5sHBwejadOmaN68OcqUKePNMQUw89NeSvIz1ASngJ/3OhZhNEgMd8iDCjdw+HnfFYfcSqOJfhUlSaKHmfJWKQiKD/66zyKu7cs4VsN3aSG9sRH/0S6FSEl3+Fi/EAyhL0IOmei5z3tQFxwRcFT/EgykEOP1q1G50DF/GpCqTT/XzXU9yNuutfH8zXvlaatTpfynR5mj1O0V+LM+yaG0XkjSijuuiWVxi0TaH0Ylp9CETjO3osl/N0CrYamfzf2W91UsEpKAkHK220LK2SwMGlaIQGQQhzH8KPwmtEYwU4jf0Q7s8wuKPm8NXQYus9ErAAhSSDV8w9v2gKd1viqvN+KE6LoCOE0MxTT+JRyK/wTvtY+0WRzs+3IQlpFJFm+oGjpwqWjCnkUXzX4AwDVR4X5qMx4wREj/N0uUwSTNPSGHv8PMe6/j9s+vwthwEPVw0sT7Hvz7EX+tZXDboOzVqxeeffZZh5/nnnsOAwYMwLvvvotTp065PlEAl2w/k0bdfvx6pkOemcOxZ9Mdtk1JTkVmgW1YMrNAcENHke75fNixDsykkKqYyT/nuNPt48DqMah7RtnootnwskTHXW1c0YPYBayC4diWczTmjpkq4BH2svn6tiGmFjiGZMP7KMMY8bP+A+wz0tvD5REdlgsqte+ifV/J7G3caQhgjVL+U34runYhBxHEBx4YW3UH4tD2MYG9i+Hcn6pzKQHgXh6Pb7acRQEvOBjWD1IerCp0ZodK81fMr4uMbEIICngBH4qf41vd5+jNSc0/emIL8OuLRZ/3i38AITEOp2585F18xM1HBdzEUE7SKT0sSkLhtBaLI8hvqMO6rgAux2Zjif4TRKYfQc6OBagQpkGNGOn3CG81zMXRdPpyWxDNSA0IEth7jjtU7SAVL/VbBry8HkRBbm3a5STU+jqNWtU+ZQ89D/xBRSlK6a/zsNsGZXh4ODZt2oSDBw9a9PcOHTqETZs2QRAE/PLLL2jYsCF27FDfCSQAncRIem5jhchgS56ZEvHhjiteJc/BiZvqC0P8Va6gpDly5R7q/mcdUq5m2HiApnMLMEG7wvGAqOpAI+Xq5stiNLaLjh6HeprL+EN4FGceX+iTCscE9i7G8KPQ2zgNa2p9oLhfKFOAj/WLqO8FM4WYr5+FEyYV2mj3YZWmOw0BrFHKf5p7rxnyRfrEOCezlWeDdDEOOQIxnVvg0PYRAIZx68y5lPNVn/f7nZdQ+52/qYa1fR7s8gNX7ovWcR7Rbxkw9gjQdYb0b78i+ZwpK1LQ4J0/kWWif97fZDaXvJQxtYF8RycAAJRjMrHNMAFaRlooNmLPAQB2mepgUqFnxp81ZfZ8BnwQYzFuX/uXcTDmXHHJpFxRflw0zzuXdlh6yePYSjC3T2C/yTYNy7p1I62q/WGLkD3wskFxcXHo378/zp8/jxUrViA5ORnnzp3DwIEDUa1aNZw4cQKDBw/GW2+95YvxPlSEBdEfQmFBWkueWaiBcxDQBoDrmY65F0qeg/FudCF5IMNWbiCKIrILeExJTkVuoQlTVqSiarkQyDUIiiHvU38CS59VPG9F9g7yFXrnfmfqik23QiBUVdax9JQIJg/f6j5HL80OPN13JNbGeD5B1dFIDzl5AqByq/Tz6NzNhXTVEEAJpfyn7WfToWEcvcjSZOp96TXrcfxsau9037KM+y0uaZO8/Hx695lHsGxEC2QXCPdF6ziPiKkNRFaW/h9ZWXptZlLhXEkyjNaKFMBr50ZZ8gJJ7x8gNLAtOrliqIknNIeox35hehaJrEK/cA/4+l4zgBCMbF/NYszJDRYE4txUiGUzHLYl8y3R2zgNXQs/xkjtf4Hei5G3fKQkIbTnawBAU42kFCF3AioS2betal8kdME4fiRG+alnzlfcb+kjbhuU3333HcaNGweWLTqUZVm8/vrrmDdvHhiGwejRo3H0KD1PKIB3qBEbisQIAyAYMZz7C0nsGQzn/rKErRIjDdTjaBW0zyUlIszguo+sP8sVlBSPz9yK+u+tx3Fzb+ljN7JQ/731kGsQUkg1nBbj6QdHVHZ67rmmntQwTz/NZkw91A7cqT+LO3xFlpk6otPMrah5U7qGPJF4QgyTia2CYwEQAPBt3iw1Y8LTvrhKDQE8/S4kRhrwKj8Ol0Up926NIIlY99Ds9Iksl/XvN1P7jYu9pagTbZGqBG3MNWJDkRgZhDeXp6DvvD2WRgn+3jrO26gqpjFX9u9b/xO4FFtZsQoFp6mHnBdjkax/36bKu7iMvDAaWD0WzyUlYqpmPDoY/4ebkIqF8uC8haSB0oHrWe0u9DKnV7R5vDsKqnXG9etXqcdfJOVtRPbtq9pf4v7GWv1UNDj8cMkGNawQYZmrZV5qVdlv00fcNigFQcDJk465GydPnoTJJN1UBoNBsR1dADdQmOjkrfu+HIRUbhCGcusAAMO4tRYJkMlP1qYeS6ugnZKciiwVWpT+LFdQUuQU0EO2HFs0CcvVkw50nw3E1KG+dZuE4xaJLPIMsF0BSEaG2gpPTzlmqoB3tYvRRbMfFRhJ0P4myqKQuF5kKEHL1wSAS6s+KjWlAE/74io1BHD1XVDybE7t+giadOqHl/lJaG2cjZHCeLQ2zsbb3ESfTBSM1eJ/rtDd6b5zhO7ULk/WuZXWxmZ4EOcw5huZ+ej2xTY0+r/1+O0A3YDwVw+Lx2ReAxZ0ArJsU5HatO+CJcLjiofdSJpkKeAJbz2cuk8KpY1ilIInWRY5XyQ46saqolE/TFmRguf5P7FZ/4bFYA1jJPmhLKJCA9kKWT1gyu/HUPudvzHh5hPU/Soxt2xE9reFdaXuNyfzMbeu/yCw09wQQDYslRoH+ANuG5SDBg3C0KFDMWvWLGzfvh07duzArFmzMHToULz4opQjtmXLFtStW7y2cQGAEzfpD40TN6TWVTVD6YZLFLIwcbk02dmH92gVtEpudRr+KldQUrxFNdQJXm9b0TIJbxYb4x6xVT4gweVA4psAd89RzxvDZKI/twnj+JFobZyFMh0m4ISYCC0EfKD9Dl/bVXgCQD4rJf/fDpLCQEQXCnT9DBiwAmhMr5KkkcCmIYk9i7cy/wudORQ7lkuGjjEhVyEM7ylzhe6llgflSV9cQohiG9J0F98FWVXBxgAza7n+cegazpJEXCVSIcZVEoPbhio+8d6ObF8URm9GKeSQSRfL4JUy25zoVDq2FI02AESU7hm5AOWHnRdx9HoWMvPpuqQDW1RETJj+wcipJERqK3jge+DqPulfuc0gpHugJ7db8fC4y6st5/nhfBnsNDl69htoHDUhIxhHPdvDpioYxk9Ea+MsvC8Mxgd8P8XrFhB61yMsfBKTjHOx3EQvspMNSzVY50PKpJBqSBNte3nnEh1qs1dsFi9r0uMdihtn8s/jiGh7vocBf5VRo+G2QTlr1iyMGzcOM2bMQNu2bdGmTRvMmDED48ePx8yZMwEAnTt3xrJly7w+2IeNcY/TPRzy9h+1vanvzzN1Q1QQhwJeUCV10rBCBCKCFB4wdvirXEFJ8WyTBAe53Y+5BRi7u7VlEh7EbUSkWd9R9hRczGExNTkF6U/OQQ7oq/yxXDLW6qdiYcIadN3ZD3XYq6jK3kQD9iJV2zJIlBYcMfmSx40pzAbWTAROrJImNwBoqDypyEQwypP6XqYB7j2i3ji15qZoGxI+aqqIZLGdy7CuuzmOavEkwX1KcqpiG1JlnVjzsStSkF+Qb2OA5RfkY2pyCuIjHe8B637X3mTir0XnbMMqpyJlIhjf5rSmvrfM1IEqiv5Pfh/s/VJyJExJTkXtd/7G11vOOx3P7vN33U478FtWj5FyArfOkF5v+aSozSCAt5YfwaeF9Nzp4cYJmBUx1XKeD489jsc0rmW1lGikuYC1+qkYqfkdAFCNuam4r7MmBGVv7aDqpLrLK9wq6nb5+SfnTYYw0oJNXrx8zc3EPv1rDsWNE7TLMejOzGKP637D32TUnOG2QanRaPD222/jxo0byMjIQEZGBm7cuIGpU6dCo5FCZBUrVkRiorr+sAGUOXA5g7r94BVpe5v2Xajt9JL17+PZ6/9D7Xf+Vi11kl2grsuJt+QKfGU0+JrHP9viYFL/pBCSHm6cgPeFwWhtnI3h/ERMKJiDqL+Gowycr/Jr3tkAJt9WMsqtYokmLwK9FwNjDgPPfA5EOobM1NIB+xB5fIlbx8hGdAyTCaCo5WMN9prT3ENP9R7V4kmCu9IxtFCvPXJBhr23b4JxLq5dOocVundRH+dschW3+yCcNbJ9kVfnCimnuF8V9rZijmVfzWbFlqLzzEaokgfYnrNpuW6nHfgtCl1ukDQYIARtT7yP/9M5fn9OmBKwgTTFcSHe6Xk2aegGvjPasFJXq/Um5yL58/kn6W9EqPscXbFDrE+VohrOT0Rr42xM4l+lHleBvYNyTBb1vQYRD2eE7H6ZLz0WNgeAsLAwhIWFud4xgEe4mgAbJIShUEMXlV+m8PC/qyCB8kh5dQUGxZUr8LXR4GuiQx1DwCmkGr7X23aomcH3wQbSFIAUziTRtTD0qKMskLtc1Kko2tj9tVRpun2m5C255902agCwVmhK3X5ejDMb0bPwf/wArBAeQxAjTQIbxCRk5+Zg8vIj1GM91XtUiyd9cRtWiMDEJxz/5uFBWpf3bNl2I6jbX0mthX6m35HEnsFHugXmgjpJB3K8QlTCU25k5mPpnkuoEyd5NeYJjqkT1qQpVOhHIQv9NJup771dXvKGK3mA1eAs7cCvCYkFwuyK8NpPBeKbAKvHoJu4iXpYsPk7IacvISEJ3+nsnyHPowLv3NtLY5bQCzrwaKShp9fIDNeuc3RIBEcDnbxT+NJVs8+mrWewVjI35FSP9Ii6VHmieqxjUw6Z8CzllI0HkfttvvTIoFy+fDn69OmDRx99FE2aNLH5CeA9GlaIQM9Gtg+rXo3jJc8IIdj/RX+EixQBWUgeBRpyrZT9iue/PdXlvBY3md7XRoOvOXaNvnJumS+FpGXv3HOarTaep5uZBUgh1bBE6FSs61culGQ2LonRyjtd2AKkXwSaDCnWtWgUmuVDTqMirpjHwDNSBfQ9EmKu0iQYpVmF93RL8Ry303JsN81enDYMwWMn6XqXnuo9qsXTvrjztzka5JfT81171RKSsEg/0GbTCVRFsv59DOX+BgDUN0+esg7kczf+5+rXUIV1RfuhK5k4cTPLpZHxP74P5mrpnUjmmnoqFodV6Sx1f3InF9sef9XVU0TOnVzWz6EQB/9+JIW8FbyOK4VWGMpLLRvHWi0gnjBtAwDw5mK4sdzvqME61xum8aH2exvPuDMyiRRKtUh9CUZgoYcFPQrIhTl5vK1U1tV7BZYiRLUsD/Us/cYfUeN1vN/mS7cNyi+++AIvvfQSYmJicOjQITRv3hxly5bF+fPn8dRTT/lijA81x69LBoxc4XXM/Bqrx6BZxlrF45Q8lK+2rUpd8fy0R3lVKOMNuQJfGw2+Zlgbevj4xwrvo7VxNt4XXkQH4/+wU6yLJPYMVur/gwq4hYZmL1hzJ0UR7nCJxCm/mZsGfNEQ2L8QaP+2zVs5Ir3Fm1qsi3YqsFJ4VkukHKhIJhdr9VMxi/sKjVh6i0YAKNPyZep2T/Ue1eJpX9yPetWnblezuOofvFf6j7mLSmXmhtP9j5913yNFw76i3T7/kcYw7k9sy6uENGIbdUojYUgh1ZBCqmEhb2tsfMd3wdS9kperQWI4qpWjN2NwxX1X9S3nTt5UWIwkDQYSkvB3rGPldgP2HD7Rzkcs0vHtVvPnLYr4nOmPHKKHljEhh+jxg4eLTzkiYM85k+Mz4x+xCRYLnRDDZII0GwE8/ZlH11TCVVvPUfwYtDbOdmgrSSOPaFGzM93rfz/hjnzZ/TZfum1Qzp07F/PmzcNXX30FnU6HN998Exs2bMCYMWOQmZnpizE+1MgVXq+0q4q68WF4v3tdaXXcaIDT4/orCOkOXrSPuuL5M0V5ovOmXIGvjQZfM65TDYcvDQvgvZd7oWb5SOzTv4bN+jcwiPsHABDPpGObYTx+vPE0WhkuYRQ/BledeRdV0lajQuf18I/Atk9tNpVh6UZVhtax7ZuntNEcQx32CrVidZbYF493okuCeFvvUS2uCs26NYz3uJWgvt8S4OX1wPWDwND1uNXuU6f7B7WgG9vuYp/PqEZ6agb/AgAgxywNI3vbQ5Fn8bS30hyzea+15pjFGJy8IgXn0vJcaljaf573pb6tUu4kAHR8xyIF1NYoRS5+E9oAkPQj5cVmf24TRrWuAIgi8FUzfCZ8jDKMZCiUYYwYrl2HAlFZusu+WtoV1TSORToDuM0YzG0EADD75gErRwBxDVWfU+mbI7eRTWDvUqWnZM6SBNwmkXjeXHQoh+BpzWODGf6B0KF0R77sfpsv3TYoL1++jMcek7SggoKCkJ0tFQsMGjQIP//8s7NDA3hA9ZgyiAnT4+c9l3HsehZ2nU+H6ffRLsMSPwl0D6VcLWaPjqPfCg0Twx3kCoqTIFxaRoO36DRzq8PDTgRBs/+uRcPbvysmk7PEhJnkY9wgUfiIfwG5RIcf+OKFv1XRTl3HKqHQe8ne0ea/Aa1itSu2o5fCveOp3qNaitMXl9YQwCVym7mzG6Wq+7P/oFKr3sjRKHtsqhYcBfiCIg1aBX1DV/y81za0n0KqufQCNTbcgg6FGM5PQGvjLEwX+mOR0BkGRrAYBaP4182eeKnY7JMyky2GdXqO0aWGJQCkXLV1PKjVt/WrwoT4JkD7KbbbEsx5xanLLZuC+i/B4mZ/YJLwGlaZHkVV9pZlsTmWS8aza5sAc5oD6XSPvoF11Ae+bVZPCGdyvfCLULhJz3GmoaQ2rbF6Qy5Gm27OpbRecHwTthinDYMtPcBl76qSYXLsjHc8+KWJO/JlDStEUOfLB0bYPC4uDnfvSu2eKlWqhN27JY2tCxcu+G2i6P0MbTWz8eAJp8d8x3dx0P+Sycinh0OmPU3vbPJ/PaRCkgpRwageU6bYCcK+Nhp8jXXFrMx0bgEOYoDLnKVYJhPHDMPwme5bhDCF6E2RAvIq2mBJNujRkS53jVYwhL3NGTEehxTuHU9D0mopTl9cj7TgKJIyzIexgCBpCPK0dnbbPgM+jAVWjXGqb+iK9DzrvxmBDoV4gaPnVcv0FtfgtGEIRmlW4g/dOzhtGGzpVCIbBS9r1tloZ+7JLaoaH3RnphMNS+c4+4z9sjBh9Rjg3+m2267tB+o+C/T+vmhbTG0sPSVZVysFhYrtNuPdunQGyqC3cRpe5cdZpHdo8B6USJAQZRWA4vKzqYPDgmN+dku3zvFH6As+Gl3J4c5ziGRexWLyto23P0TP+a2t5fYd17FjR6xeLYmxDh06FOPHj8cTTzyBF154Ab169fL6AB92aKuZOUJP6r5yv9XW5rAUjYRwA3XFQ9NXZGAbnvJGgrCvjQZf83zTCmhdvazNthPx7t33QWYNOKVcJ6/B5wE/vwDsnuv2oVtN9Ip0uRjI0y4680ySl8yde8fIq5O0ckVx+uJ6pAWnEBaV/7aZCnqkAIC8O071DW2geDFHWS18pnPzcdowBJEqPVoN2Isoa9ZRtWeDKQmrdFOxSjcVsUjHx1b5pbEd6DIwy1SE252lHfhlYUITevESWo6y6eUNAHP6N0ZiKItGGkcv5HzNC0DD/kDHaaovXZO9hl6aHdgkJsEA+vMUALTUwLFzmNw07DcVTxpOJHAQJf+W74p+mk0OC44V+vdxhNIJiEYaCUO3p54p1tj8AVXPIXPR1/bF76KeeMqmrbKv9Gq9gdsG5bx58/D221Ki/6uvvorvv/8ederUwfvvv4+vv/7a6wN82Fm274pDTlIKqYocxjZEbCIAx4jIIXpM5/uCnoUCXM3Ip3oIO83c6vBIJ4BNXoeS5JDSdne4nwTT916QPgdZimXJ5bKYydPFi9Ug+vJXv+n+pPsLOqN2j0nU93aJkjG01tQUI4Xx+FWQOmrwunCcF50UCpmxVx+Qk8sJIRjRju5VjwjWecUjVeJ9cROSgA5vO2zuyh0AAEQrGXjtpwBt3qC/Z+77fCMzH8/O2Y6bdzOpXkzrIjulNn1KVGPpgtif8c8iSXMaDdiLaMBexCBuA/acuW7xmi66GEXtRa8ULbFmeJuqip+vXxYmHFxM3bxlyX8dQvI19r6N7XxfjOV+d9h/uOkXaZFgDpNnE4P5X+cdqmQj/RjxXGNWiaYUw9cdjNA6iJK/ol2DsqDXWJSVoyMN6XUBcgV6HhN836RGOUOVfNmq14EPYtAmXbovitoqzwfgG71ab+C2QXn16lWLgDkA9OnTB1988QVef/113LyprMwfwAMIQf+kWAzn/jJr1UmrlOncfJQhtl9OOWelDGPE9/r/YaPuDdCSoJU8hDR9RcD71Zf3W5IxjbkDmuCXEY9i7bi2WDa8Bb4J/wETtMlOj3FmNLIu2t5nie71zy0uTcUUpOz5h/peX3OxVw9uD+Zys9CH2woA0BZmoqqCIWKNvbdK/twnJ6ei9ze7qMesOnLDax6pEu+Lu+sr94/5d7pkHLafbLu95WiQ8o0t4d/eN/6HuC8rUr2Y289KaUlxuIuKDL3Tj7tM1CZjtFX3k9HcH/jgWCeL17Rf84oWGRi5aKeHSlmY3t/uVpRh8stnhoL3+XousPDfkzDygmQgEwLSsL/TU5Emg1H47EL8p/JS9Cr8P/Q2voNtonJhzFy+m9lIJ/hO8D9lFaXIS2fukIM38jP+Oexkzekjt+iffwyTiYVCF7xqHIMpK9Tnd/orbynIl9l4HfPuUo+VIwfjO9Wkvl/auG1QVqlSBWlpaQ7b09PTUaWK91dLDzWrXkeD72tiKLcOQNEqpYLesY+rPdXZm9TcpWrl6ELoEUGc60pWRQ+Res+R3N/YGrm/8f1Cp0fi0KKqFPb+/fB1zMly3c2CZaRKTxNxbj3uCSsqtrpr7gd+D75rtSWnSawQWlm2VWNvolPaD16/VqpYCSdJRcj3i3UxlpIXyhpveKSK0xfX3aIQQgj4Jz3Ulcy7A/z7se22XV9h3xcDUGvaWizacVGxctvYcCAKBZMlX60OewW5RJ1clNLC56wpVvmgq/uArOtokBiOvx/52KZoR9IlLaJrPeXzKImb+2UhX0IS0NwxxN+P+xdTD7XDiveflxZAq8eAWaTQkQbAysiXMXmPFjU/v4gfTjI4SxKxj9TBN4JyaLcPt8XiWFDTIjFbNDhs8zRlRS1rhGbU7RFmr7y84JioXYE+2CC9qSTBBOBl7m+s1U9F10szvDvQUkBpESt7HQkhKGw1gbrPHKEHDByL55L8sxOh2wYlIQQM4zgp5uTkwGBwvHEDFAOFVUpuoUjtMGAPLXcpIYL+GY1sX92hknX5gSu2Eyjlcze/4XIsMlOSU5Fp1+Yxs0C4b1uv9W1WASmkmqrPoze3DRpGmrFzREeP8CKhCwbd7ochhW9gpfAYyjI5WCR0wav8OLclQhwIoyfvF0CLVaZH8Ry3o3jnt0OeMKypz16yCdtYF2MpeaGs8YZHypNcSHd046yZnJyK5ct/8nCk9O9U84w1loUi7b6bwfdBra/T8LHOVndS7pdsdLGgUfSWMwxSxcr0924fB3Z+ibeXH8DMwwwEosEK3bvgCYezxHbiW3P0FkL1dGNm2b7L1O1+W8h34V/Ft5aZOkoLIAVPZpZZmulJsh0k46qDzJL02famHhvNZOO0YTAi4TyVQa4PD2EcF0A6xrF63F3SxRDF9x6j5PH/EfUyhvJvoJfxXTRgz+ONwmFuX3NbqP95ZN1Fybsob5+cnIqac287PPPTREkPtkAQ/Xa+5FzvIjFhgmQxMwyDd955B8HBRfIzJpMJe/bsQaNGjbw+wIcZ0noimFNrHLbPEbrjU+08p8cq5i4x9DXEL/uvYM6AJjBoNUiMDMKgRyvhq81nsfLQNczfeh5vPlVL+WLq7Un0a16RWuV23wkbm5F/l+4a9wyyMqyjt+0l7m+8ZO6gYr9NnoCckU+09HBTw/5A82HAfMcFxkd8fxwlVdFds1v12P8SmuNpbi8EwoBjbI2q7/guWCQ+hRuIQX32PJqyZxyOty74kIuxZC+UveFgOaYUPVJTklNt7tkv/jmDL/45g37NK2D6sw0Uj0vPMWK9KQn9XFRXU2kzEQiNlcTp7bBeKMoh5tskHDFMJnpodlq62nTC3w7H6hnP8lCru0pn2D0XH2EuGnBtcQtlLVW8c4QeKAQH64dEbiHdmFEqzPPbQr7eiwGtATe2L0H5A0WeaPnZ+98ONYCECPwdOxxdbs23vP8T3x4Lxa4ogBZ9osMwocwuxF1x/HsN5xyf/dbMNfXAcVLZIV9RRgPgpJiAZUJ71GavoK85PcVb5MGAdDEM1VlHDeP/8EMwjktGVfYmfhPaoDe3DbXv/I3LpB1GcVLbUT2n/PllMOGIsEvrms33wtOd6Rq29xPPJSVi2u9HESGkYZ5OEpIfZZpk8TpK0RqCHBhQDkXqGzkwQIruMH7bqlS1h/LQoUM4dOgQCCFITU21vD506BBOnjyJhg0b4vvvv/fhUB8uCCHYu2Im9b2+ms0YxY/BwMK38KepOXWfEdyfaFstymZbtXIhGNG2Kv2czSqijIHD2GWHMHbZITw+cwtWHpK09uSqSiVXvaV7jwoaVojwWCTaH5Er9s4RZfkOay57KGr+Cf8Czorlqe+dNcVhpVXP7DyYvZ96swF2/ZAUoqNUksayGThHylNFyEnTodTrPc3tRToJQT4cvaytNcdwlcTARID/41+kHj9H6GH5v1zBPSU5VdGYBErXI+WObpwFQvB62wpI0pz27KIHF4Nccsw/XBr8IlJINXOh3n/wX34AFgmdLXlm4/iRAAie6vy0Kq+5t+nLbXUpGxQepODHcLPoqtQL+WJqA5GVEXf5TwC2eaPWCyBZ3Fx+v4XmJD7Rzscbmt8w5uxQxB3+AoDt38vAsXibf0nx0utih6OfZrOiMSlTm72G93RL3TImr4llXe6zlG+PzWIjVGdvUOWvvtDNxXGxIlobZ2OS8BpaG2fjHEmw8ZrXYy9Sz71BaORgTALAOO1KxP/cXvXv4a9MWZECUSjAQG6DpcDtBWY9pv66D0QUMbpjDUznFqAKa5v7XIW9bfkuLdrp2A7WH1BtUG7evBmbN2/G4MGDsXbtWsvrzZs34++//8a3336LGjXun8IKf2dycio+vPUo9b1lpo44SxLxNLsX3TR7qftEMHnoesU23+RcWi56f7MLNWJs8yiHPFYJtcuHWnTeDl/OoJ5TSfw8MdK9dmseiUT7KQ0SwxGi0+AbwXXrMAAgHmjDHTclIobNRHX2BtXwq665iV5WPbODYfZ+1n8eGLUP6L1Ien1kmcOxY7mVOGYY5iBCTsCC2f+d4piimFyE2oXS/hEaWuXMEZwkFR1y9+SwjUx4kFTB3aepa4PcFx4pNXmRHulXrh6DBotr2RSxuANpMhj/C5tiqZy/Q6TQfNOcf6y0/M7iR/0nFq1IOc9sZtAiPJeUiH5BewAA6UQ5NFkS2KfeVFfI41YyD5XSIUa0reYXenyfhU9Fa+NsfCt0Q6pYGf/hB+NubqGlyOLrctMsbVl7G6chlMlDEnsGBdBSz7fM1AEFggkDyipXW7czbsHPCu11i4PA6jCYfwutjbOpCxK5k80A7b8WgXYtQ1cUmWd6xkaz1FleqDVPcIcV38tvTpHN8jNcPVMmFc7FacMQhwK36SeewN4vX0SDxHCs0dEbl+w1SZFCUUTpa7FScHt2YxiGmkOZm5uLl1/2TtuwAJLbO4VUwQ/84zbbf+A7IcUsFeGqndqe8Kep269n5gMoMuiSD16z0Xm7fC+fepxWIcEq3OBegndxCiP8jbdWpCC30IR+mk2K+5CGfQEA58U4DOUnIk10r8jmEc1Vy6peNvxkT+dtZ+fa/x0wpxmwa64kJ1O5reprMh5o2H1uet6SMyf3jpZz92T0diH51SlSBfeLC/erGJP3Hp7u5EV6pF/prDWfq7ElJOHtXQRzjmkwih+DRUJnRDPZWCh0wXlS3mVP7u8L2mHy8sP4QDcei4TOiGJycdDkWrqnuNxFuCrZoKMKEY3j1+myMg0rRECncXz2PP/NLr/IJVt5JQS3SST6cZtQn72IxzQnoAOP7Wek4tUOrdvgKimHGdw8/Kb/ADFmmZy+Co0N+mo2Yzq3AI9lr6NfsEoHfF1uGvpp1KVS3BZDcV1U7s5kjcYQhpDEurhKyqEHJY1HrXbuDtMjNgV4gPO8UDWcDW2GSo+7n3dZUqgV4C/bTrkf+cagLpi8IgXb8io4aHkCQD/tvwhBHlanXCt9LVYKbhuUixcvRn6+o8GRn5+PH37wfmXowwghBMPbVsVG3SS8qLWVb3lRuxEbdZJG4G0SgTsifbUPAM3u/UndPvnJ2qgbH4pX21XDtjc7oG68ytw0xYR9924jj0Si/QjrFaiUBkAQraCxBrD4MudxtDbOxgh+AoZq1qEcq5xMf06FliMAjObHoIPxU2wQk1zvLItkH3DMxwOAfabiS1DYGw5Ki50pPH1CyDG6Fi93tyjHmafAnX66qnTj7IlvgpOgp5dsEuo7NfCYawfw0bHHsVE3CWv1U208kE9pnBve8ufQ6uQH+CZvnOXYJppzTo8rDouEzgAkDUU1skGVy9IjGjFllLUXo+yqvGX8Ifd6ScxP1A5BS2KlVsQTf0vB59xX6KOyM1YT9gz+NjVV3qHTO+jQqjWWm9QtEGPYbMSz91zvGJqAWfEzceRKJqZzC1CT9Txy1EpznJruMMJFXiiNQka6LypmH/J4PCWBagH++Cb4TuPY8WcG3wfdnnoG6bmFmM4toKYztGBP4phhmMUGKFUtVgqqLYGsrCxkZmaCEILs7GxkZWVZfu7du4c1a9YgJibGl2N9KLiRmY+mH2xEn293Y67QnbrP1ugB0KEQA7kNiGbpHS0AepU3xwLn03Jw7Ho25m89j5gwPd560knBjQ10i7LUc5lKCNoKVM53eYJTetiJeDl3Pu6RMjhLyrucBJREpa05bKqCfprN2KyfhAFmXUjnOK+aambO87shRjndj8ZJUcoj7KHZiTjctXRRuUUiqd6qv0T3Wq3JuCMtpcZT4E5e5GQF3ThnOZ1k1RjUBr3vMM9oVRl4St9/Zzyn2QYAWIES6BNvRo9CtDbOxuZGkkyQM9mgl1pVdlB5kDmTlqvoJV4ytAWGt7GVpfOL3Osr+1HlOn3hXqXzSIAQTGqmRWuN+vzf2uxVLNR9ClKP4s0LKQckJOHakhGqJIPcIvsaXr86HrFIdxn9Uov0vJM/T4LjDR2F/l2hI0Zk1+6DO13muJ1nW5KoFuBfPQZDTb847PeK9k80SAgDgevoo/xs8Df9ZtUGZUREBKKiosAwDGrWrInIyEjLT3R0NF5++WWMGjXKl2N9oLEOwcnFCcliW2w31bXZb5upLoJu73fIwbAnNbEftcpbEIFFO6UuGvIK6ue9lx103mgomSX+4CUoCWgr0CnJqS5by5W5uRfHDMNwRO+dSSCSyXXvgd+oH9DBdWu38qwkW3KVSOH0DNF1bqwWPFLFSvg/vj9e4VZbksxf5VZZQma/CO0AFBk7BrtcXHtdUhruSEup8RS4kxfpSZXxVwrapKuER6FGFuGC4RH8KbbENzw9bUWJHWJd6MCjW5euIOUbuXWskTj/HJTm8rJMNq6SGPxwLgjXuEo2eXNyCsQj5SUJlB1n7iAxgq5YkFtoUgzj1YgNxZZTUgjZL3KvRREoyAKW9QNjcjQkDpuqYOoeDvhjFJ7a3BVlVba9lGEZgDn6m+MbulAg8xraiepVGdxBW3AXX9Y8gpOkYrHC0zLJ+vexT/8aYpGO6dwCtEyZ6tF5Qk/+ivi/X6G3HvUTVAvwK6TDhCMPe78cBIAuCSaz21QLA7hNqGnI8jv9ZreKcv755x8QQrB8+XJs2rTJ8rN9+3ZcvnzZ0pIxgPvYh+AAKQ/Nvi93G80xxOuUhc3/ERoBAHSXpcnbvm0jjW1n0pxW2MpUiQ5BRJBjIvmOs3edJgi7KwjtryitQI+QqlgquE6Qv+phhbc13/Jd8RY/DO9qf8DXvLpCIPwyENj1pfT/5q+43F0u/HEhWYgsosdOsS7qs5ewVD/DEl4FgJe49ajJXsNqoRluQvJ87hDrIkJnQoFgKxuTWSBAS8mRs0ftwsWVp4AQguea0IuAnFVu23+XnHnmU8Sq1AmhFnvVpspdiSoFx3HaMARDzH/TSyrvnRe5jThtGIyKu96G8eYpVcfI6BnnaQdKMrSESPm22QUCeIEuCXT8hpQ3WC2mDKZ2reP0OkphPL/KvZ7TDPi4ApBL70IUyeTiDeNc4PBS5+eJVNEMRFcGGHsEGJAM9FkMHPgeoUQ5MlVcml+ej9OGwRhtkHI4/+VcN25wRjkmC/25f/C76bHiD06ph7ofUD8hDFEhtvNjVIgW9RNs9SRJfBOsYOlFN/Ny21iWm3L6iNwMo8C84GvKnkYSewZPC+sx9bf9IKL7+e6+QrVB2a5dO7Rv3x4XLlxAjx490K5dO8tPy5YtER8f78txPvDQQnBKXqhtcS9SJ6sf+Q6IYHPR0/geRvGvW1WDShpncnN5e3jzHODK+AwL0iKcYlAq5YqoTVK+X1BagU7nFmCACq3BuhonVcEq6ag5jJaaE0hiz6C3ypwsAEBBpiQj1HocCsIqA6CLjwOwtFOMZJx3ZApjjJZKTyWe4fZZcste5DbiMDuI2sGJN9neE/b3ojvhTVeegsnJqej9Ld3DQ/NQjmpfjfpdGqnQe1wegzwh/Ca0ASAVZY3ix6C/kwIuewzmIohKrHstIjfrO+D7svRuG87gXa0iKNRlpXSAqtEhEIjz54hJFBW9wzJKYTy/yr1uo/y3Xc63wo7mc5wWX8iIZmM8Jc6xAMNC44HAimHAkZ+Ab9sUtdr0MUHhMbjVezUShi/D1mjHnD93GMutxC/6D4s/qP2Lin8OH9Hxsy1It4tapOfyeOHTFcCCTkCWpG4yJTkV9QRH4fcZfB/klG1oeX7J6SPD+Ql42zjEItMma/+O5ZIx/Xgn7PuKLs9WGrhdlFOpUiWwLIu8vDycPHkSKSkpNj+eMn36dDAMg3Hjxlm2EULw3nvvIT4+HkFBQWjfvj2OHbP9IIxGI15//XVER0cjJCQE3bt3x9WrV232uXfvHgYNGoTw8HCEh4dj0KBByMjI8HisvoD2kFXqhLHmbrxlsrKmK7cPSewZdNCkYIRmDTVR3H4yDzNwCNIyqozPEzeysGBwU7SuTtcps/csOAs93o9eS6UWcHvLqpPD8AY12OuWzzSacd4pwwFjJrB9Fq5mE/Q0vov3hcHIIcqFEM44ZfJ8Aek8RYDY3IufVD4IHXj8ceiqk2NscdWqz1mbx95Jjp7Lwt9fp36XjL+PcdjXegxjhDEWHb5exveQDx2ySbDLDifeYPLNCegbtMftlDOtB8LnV0k5AMCVu7kunyOjOtRQrJoHJI1KfwvjUWk0AKja3maT0dzOsCu3D7+cMgHlG1O1X2Vm8H3Q+dYoHAnviAY3nehJXtoptbfkXDc38Crp5xB7eztqcGlofe8Pl7snC0UeyD8Fuj6yPQXuLmCcdCcqTQghuOEwl0nPsvY5a4Cr+5CzYwEgGNGvWQWM4sdYJMHkBWcPzU5Meao2GiSGg2OBsyQRkSQTX2m/wHu6HxCpkDYR0Xq4L381t3DboExLS0O3bt0QGhqKunXronHjxjY/nrBv3z7MmzcPDRrYdp2YMWMGZs6cia+++gr79u1DXFwcnnjiCWRnFz2Qx40bh5UrV2LZsmXYvn07cnJy0K1bN5hMRaGX/v374/Dhw1i3bh3WrVuHw4cPY9CgQR6N1VcoPWRpVZPXMwswin8dQwonYrFQlHwfZe5AMpZLVqwotJ/MC3gTXsv+UpXxOe7xGqgRG4pJXWpTz23vWVCauO9kF7jdxs4foIlv380txKq0uFIRkfaIvfNQnVzCf7WLoQOPt3jPHkaV2NtYYidppYbDpir0Dk5mZLkh+V5sf3MhThsG47cExyR2JVy16nPW5nHwItsqakII1hnovZg3BtG338jMR9J/N+CUmAiBsEjWvYMXNP+iLnsZw7m/sNzURtXvkWvXnvOoyb1c5YgrG5W7pXqRTLPO5Zj8OU6fI7JR37BCBAa3rEQ/V75Q+i0VXSAvhi3C86wUtdGb2xkGM4X4I7svMKc5kLrc4fgsIrW/fU6zDWdJIv4Medb5BeUe14eXUN/OIO7pALvFlk+ALxuDNble+D9r1sK9IMaiG+eoj1xAaYRgUFjAmJSmgw5TXI6jNJicnAqjYBt6lp9lozTJAIAyez4DPohBg8PvwlC+DkbwE2yE30fxY7Bs32VMXpECQRQRghws1P8PwQyvqPW5IW4EajZp5/PfTy1uG5Tjxo3DvXv3sHv3bgQFBWHdunVYvHgxatSogVWr3BfxzcnJwYABAzB//nxERhZpZRFCMHv2bLz99tt49tlnUa9ePSxevBh5eXn46SepP25mZia+++47fPbZZ+jUqRMaN26MH3/8Eampqdi4cSMA4MSJE1i3bh0WLFiAli1bomXLlpg/fz7+/PNPnDrlXo6RL6FJk9THWSQytzHUOMGhanKYZh2+132GwdxGxXMuEWwnfJomXKGJKIbW7Y3Pg1cyLGO1L6SgtcZTmrg3nkxTJdfib7zQNJG6fWzH6hbD/5SormNOaVOfvYjThsHoxB5EGnG/T7iBEfCcB63cYrV0jVNZ4lTpXgxvrV5/zlURTYPEcMWe1RWjbL1Ak5NTsfBCFDVScMlgq45gKazbuBvzhSlIxC0s0H2GJuw59DVX4w/j1mK+fraq30NrzmmUF5M1zDIu+QqC2O5i8iC8TUN+Trh6jshi34QQJB9U9jgrFTuVdlTDPoXnl8ofwDjoT5BnPqcf0Ga81J5xYDIuDNiJlGYzcEEsh/VmSaCiAqqncaPxOI/HFeEiNaWkqcLeom7XEPWNCQqhdVhQGVkDjPX6+qXzgeY8Ufo+zMlshfNpuThLEh0K2O7mFCI9txAbdZNwzDAC5RSiUJdEKSpQ/fY6v/p7uG1Qbtq0CbNmzUKzZs3AsiwqVaqEgQMHYsaMGZg+fbrbAxg1ahSefvppdOpkK3Nx4cIF3Lx5E507d7Zs0+v1aNeuHXbulCbvAwcOgOd5m33i4+NRr149yz67du1CeHg4WrRoYdnn0UcfRXh4uGUfGkaj0UYaKStLfXtBT3jLRppERAjyME23FCFMIUZr/8DvumngCWuumiT4W+u6yvcZzS6b1z01O0DLoVQKrd8mETa5UH2bVYQoipj462EH6Q9aazxa6DFMTxdB99fepNZM/I3uOZm//SJG8WPQy/guWCVB8BeWAvX9z4tZCA655rD3HTcF14NVihzLfMt3xaB8eu6ZaL4tU0hVR0Hf9lOA+OIXYMhFNG+tSLFcz54Pe9a3eS331bUXee6p2eGQQzl5RQrqT1sNzaHFSGLPYrthPOqxl9weZwHRopfxXVwmMehpfM+8mJyFvaIUGQiCdzoGaTzs621PY8056MAjN6oefgm1LZq4JpbFLVLkKNh+9g4mJ6ci20gv3gEci538JRfbPoVn8rFE1JqfhSnn6zuEv1G1gxQWj6kNVOuIKlWqo/6VH1GFTcPz3HYARQVUDVZ1RvlDs6nXlDvTlBihvquF0DIi8sOrq9p3Mj/csqDKM3fbYky8X4p5AzTnidQpzL6zmeTUqYqGFSJQH2dxTP8S1uressyxBYKIvRfuYKFAj37I5MOAnsb3MDx/tF85Y9w2KHNzcy16k1FRUUhLk6Qc6tevj4MHD7p1rmXLluHgwYNUQ/TmTUmPLzY21mZ7bGys5b2bN29Cp9PZeDZp+9D0MWNiYiz70Jg+fbol5zI8PBwVKvjW4LHuky2tToahBSt5UBuz59CIPY91+snQgcd0bj4WkXdcntN+5VqTvUYtiKBNmL00221yoZpXCEbDxHB0mrkVyYeuU69nn5D8FiX0mKUwkThtY+cnjGxPD9UOaVEBl0kMumt2oQZ7w+H9zWX74eSK/0K4ckDa8EgvxWt4mtMokya65218gduKyqz0HY52IrheHG4TyXPdXpOCsyQR3RrY9iS3fk0V9P13ultyIaM60Cetke2l7Uo96QHbXOYbmfm4nJ5HFXmuyV5D4R+2OZRPX5zusouNGgwMj//Tfo/q7A100KRABx6jNH+gjcYxkd8fkEPbw7O+QHfW9jmSwN5Ff+4fSy7l+E41neawAkWfk4xqwWgf41Q9QA5/x9aT/r1k9XdYPQb4IAbMTfqC9E9tZ+p2QH1nGhr3RA9absZ7lrZmDw+6DF1QpnI7SWs+183FHrE2fhNaI5gpxG9CG7zOjwZA/E7MG5CcJ9ZCFXK4276l7QjuT4xsWxVVyFX8pP8QIYwRddgrGMz9DR2MuHQnByvE8fhIp1x8lEt0qM1eQQdNCi6TWPT1I2eM2wZlrVq1LKHiRo0a4dtvv8W1a9fwzTffoHz58i6OLuLKlSsYO3YsfvzxRxgMBsX97Ns8EkKorR+d7UPb39V5pkyZgszMTMvPlSu+NXjGdyrqVqIkaBzJ5OG0YTAi4bm3NIrS0YU2YVoXf4zlkvFrWk9g9VhEl1HWq7SfyJ1N3PbcD1qWzyUlomEF27B+owrhqL3/HZw2DLGRzbGm9Z1fUFs4iTW5NWF8ZTdIz6+BRNtOGDP4PmhtnI2P+H4ej++8GIsclHDivgpimEwsE9phHD8SbzxRA6dvSoarrCd4+lY23ugs3f+K/YmbqK9kdKUxaf1ds+dujtFGE/bUrRz8RhTC8I8NtXkd1/E11WN0RX2zZ1M21npr3KjoLyViNTlUg2EstxKnDYPxsXYBujUsr2jwy9gvLlULRvsYpRSeS3fzkf70AmDIX8BrO6R/ey8u2sFJG87P+OeA/AzvDhTAbRKGLHiQW9lmAlBXecGrFi0c004uMfSUIcWhaI6ht9mb25vbhm91n+MjboHfiXkDwFvLj9jkfSqFu2cwLyPhp7b46MYwhDJF9+9IbjVOG17Cq9lfumxoILezlZ8NDQ+/W/xfwEuoNijPnpUeFOPGjcONG5IX5t1338W6detQsWJFfPHFF/joo49UX/jAgQO4ffs2kpKSwHEcOI7Dli1b8MUXX4DjOItn0t6LePv2bct7cXFxKCwsxL1795zuc+uWY05HWlqag/fTGr1ej7CwMJsfX/JcUiIMHIs43MUAbhNuO/E0MQywROtZ+JShtElULZKdNBhvP/0I9a0wg8Yhh9LZxG1N7dgyqBkb4pUQli/zrKYkp+LIFVuD/PCVTMRwzjXh5ITq7vxa6L99FMxHccBV2+KPEdxq3CYRiGeV9UJdUZW9hXNieQwrdE8u5pipAm6KETbbbiRNwjyhq8djsacvtwVr9VMRt+0tqp7gqsOS1/vd+H30ExxU39bVVe/t55ISlaXFGcZBE/agiZ4SMnKL7VlqNG6LOYznCwJncAzBFTd0TM+X74bJhUNd7+glLovR+DfSifQNgJ+Ejqj9zt/4ee9l6DWMoryQ/eJStWC0j6Gl8FTk7uGjexPww4VwGBNbSs+wyq2B2lbfnYQkQEFkfqJ2BZ7JdKFVqcCffFMsFp6gvhfDZKESm4aLYjm3CgbX//gp+JvHXe9oR6azyIpZ+7Z8cPGf739xnfHe6mN+pw7yZ4qtnZJCqiJVrOyw30f4CuUKlfOHl5k6Illsh22mejbb84lWOSUpyX+0OVUblDVr1kSFChXw999/gxCCixcvonHjxrh48SL27duHK1eu4IUX1GtVPf7440hNTcXhw4ctP02bNsWAAQNw+PBhVK1aFXFxcdiwYYPlmMLCQmzZsgWPPSbJEyQlJUGr1drsc+PGDRw9etSyT8uWLZGZmYm9e4uqzvbs2YPMzEzLPv7AlBUpEAWjJcwczSh7IesylzGI/9Wj69BElWk5lFvtbuh5pmeAhCQ0SAynTsZZBSaHXA6nE7cVJ2/loM5/1hcrhCV7lWZtOI2DlzMwe8Npr+dZKRkqYZ2LX3l4Vkxw2f1IDXcRhq1iAyyG+rZ9CewdxLEZAGDJpyx/eTWeCzsJwE6vUo0QsxMq63NRI6aMg56gbGQ2KUtPiSi4d0N127WGFSIs3k+Zl1pVtuhYTklOVZQkZ0ComrA0tYXXKDmUnUxSQwE5zH/DzRQEZ1Qwa1Eq5X8CwAGT5P3jrx1CstgWx00lEw6ryN7B+/cmg9dHUt+3Lgjcdvo2iKmQKi9UMSrIQW/UlQxUSWGbwiNJwgzGaiSxZ1Dm0DeoP201pqxwDGsTQiDmq+ilrcA1hZaobbljGMxtoL4nM0fogWfd8G5/lfkY5pd7B6bwyor78MQxD56eGQ+gTk/gqU+AiMrQ5arvbGQiwA+wbdwwg++DHQWVcMgPNY2Hta5s83o6twD12YtunWMm/zxSSFUABM3ZEzbvBTE8otls7DLZKqzcaf6WtGDxE1QblFu2bMErr7yC69evY/To0ahWrRqqVKmC119/HcePH4fR6F74ITQ0FPXq1bP5CQkJQdmyZVGvXj2LJuVHH32ElStX4ujRoxgyZAiCg4PRv39/AEB4eDiGDh2KiRMn4p9//sGhQ4cwcOBA1K9f31LkU6dOHTz55JMYPnw4du/ejd27d2P48OHo1q0batVS28Pa90wqnGuTf6VUhQoA6Vplz6ozCokGKaQa1TMgT5jyRPgoK61Sz5m1sl7QbAYEIyYvP6I4GdsX1jibuGkUJ4T11ooU1Jq2Dr/ul1Z/y/ZfQa1p6zCZ8oD3lIYVIiyhWZlJXWph0cUo1bmLmQoSH0016nKLXPECtxWnDUPwAlkjbSjj+l6JYIoqr0PkMExUdbyF8ehlfBedwq9hdOFITA5+D8i7q2ocKabK1O1NjXuo+ZCyaPVXpp7U4wwX1sO0aozqCWSnOd1CNiyt0y+c6SCObF+dGjK371H9FjMezyXZhvDuZhdgHD8Si4TOiGEycVpMQHnW+8V8zp4NYUweWhtn4hyJx2nDYDzippj+HbFMscamNdINpx5Wurlv8t8oygvRPl5XMlBq8Ebkwvoems5J3WSGclI3mWHcWpw2DEbXi471AJOTU9H51ijME56y2W4fFVAimnFMUwKAMKvvrRKf6hY4dU7YM1CzHpFHF0CTeVFxHy3juOjLJgppayd+l77v7d9UPQYA0DDAi5B6pC8SpBxT63uotPJolbiVbTt3KUX91gjNFM8xQbscs7ivsE//mkWCyp6WGmmRL6uJRF8ongPC26g2KNu0aYNp06Zh48aNyMjIwObNm/HSSy/hwoULGDFiBCpWrOh1A+3NN9/EuHHjMHLkSDRt2hTXrl3D+vXrERpa5PqdNWsWevbsiT59+qBVq1YIDg7G6tWrodEUrZmWLl2K+vXro3PnzujcuTMaNGiAJUvoml6lRVQb9XqAtYSTuC26vzq/Q8IQqjVhOPcXktgzGM79ZfYMiDYT4S0SigJzUnU1VnLlhyMH+CAGT1/6WPH89hOxs4mbRnFCWNvP0PM1t7uRx6kGOTRr3U+4X/OKltxFWaT2lsLnE15CEh8GuY1ejjndQ2MXknJlaJ76E59V2I7v22ShQu5RfNhKj2H9+gBV2jo9zESAocbxeJ5/HwUUTwYApyGaFLEq7hF6MUGv3TVUTyDO2vQ1rBDh0A5N5pf9V6geyrMkEQLRYIXuXfCEw2FjeQePfPcrM7BWP9WSS2ufl1wS1GCv43vtpwghnhlO0aznLf0KytC/76fEBEziRwAQUTZEhzKP0UPxy0wdUZ/idfSkl7qMNyvErVN4ohTkXBpEORoC6TlGnCWJ6KOxldmSowI0Lonl8IL+aww0TsYhUV1ltBLhKgxPmT7cdrRlDyvvULEldXN5lm70ApC+7xQheLV00+w2d39zbCTgLwU66Xm296JSL+5q7A2nzgcj9CinYgGQkvSR1I6z9/duj9WXuF2UAwBarRZt27bFpEmTMGXKFIwcORJlypSx5Fl6yr///ovZs2dbXjMMg/feew83btxAQUEBtmzZgnr1bEOxBoMBX375Je7evYu8vDysXr3aoSI7KioKP/74o0X+58cff0RERESxxupt9iXPUr2vnjEhxtkXmEIhYZBKqiBVM8hhVb1RN8lmIoxlshHG0CekUFH5uvZf7gaJ4ahaVl1iuJ5jixXCSoyiXycx0ruiv9aGyorXWkLDMogNM2Bnsy/R2jgbnwl9kCpWxhh+FDJF2wIZ+9clisk8KYebJ/38e8DYI7hcXVngP/zULwjfK92X4ftmofp3jwAn/3R6GQ0DfKL7DqcNg2GgrLL/LveyUwmg0R1rIIM4esnkkKnaCcRVm77MPLox0rdZRYqHUgpv2i/E7Ksrd0Wq663+h/Coqv08JU0sgxugd7NSg/OO3sowOdeR/dhkh+212GtYpf8PTuhfApd7ExsyEzDLZJseJX++r7RVFr13uJ6K+Ic3K8TlPHcAmCP0pO6zVPe8wzY5B/Rt/mWX1zhkqgoA2CI2xKHMIOxHbRvZJSVkD6GiILgbEOUANnDtIH7QuZEn3PGdopDspZ3O91WgHJNlqWi2l73zlwKdke2rOmyTo35y16BLYjmM4sdYnA9yeoo1sl6tKzodGgNodJIslR/hlkFZUFCATZs24Z133kGbNm0QGRmJMWPGICcnB19//TUuX77s+iQBqGxQ6LrhLXQMQRcNXdbJHW9ncEfl0IX9l3tycirO31XnkTMKYrE6ZLzdtQ51+1SF7Z5SIzYUiZFBMAom/JlyAyduZGP+1vNYdFqP2yQSn1Q+iPrsRbyn/QHhrK1nIJzNx7ESymlzoM0bQHRtYOjfRVWokZVRMVOhCKYYOAuxdUlb6FQCqEFCGKawEy1eSll8Ww532UvKeMp3Q5rh+Sa2IWs5z9JewF4pvNnw0H9s9ksLq6eqAKKdRtmYuS66Nh5c0ZI7o3piosG53oXKXbEM7u7+SfH9IIZHf24Tdp++jqcZqXpXTrHpodmJno3KUz3HrmSgnOHNCvEpyakoMHdDSSHVHDxNaWIYHmvjWCQj54AeEGvimmhr6N9jpN8/P0J6djbWnAcga1QOwUn9EPTg6H3nZVYlTES+OaKkUZO07oJE1klai8mIFwt/dn2SGmYpJOtOQb0XA93UO06soXVvK408WiUm/uo4d43iX0cH4/9wC1IObBmmAEaixXBzh5wyZqfNSqGV29eLRCZw4HtAMKrOLS8JVBuU7dq1Q1RUFMaOHYv09HS8/vrruHTpEk6cOIFvvvkG/fv3R0LC/dElxB95+sluWGhd/FBMrpnUf9E+NvXHUkFBrsWOjB3fUbfTPIyu9ObsURPCskfOjYoO0TrklrEMUC/ePbFuNdC8HkPvzcZpw2C0uynph9Vh6ZV8CeaHtexJOC/G4YbZiPhFcL+Fliox8qCyAAPgzknpIZTYDKhlzucyd/JABL0VnjX2hVq5nmpmOgl57/tyEJbhTUvfWll8+4IYA0D0il7pjcx8vLn8CPZfsq0u3nYmDYQQBwF7pfAm8u0mXkKscpEdDaPzYiwmaN/Bu7yyBFI863nxRmnzP+EFDMsfjdbG2Q5VqjJjuWRsKeyLs2J5S4rNQqELxvEj8fvh63h85haHcLQrGShneLNC3D6FR/Y0yYVaoUwuQhZ3ArJsdXqn/7wB8/m3MI5bYfn+y4Z0SGgEMPYIgp7/1u3xAICo0aP7tc8Q40aepLewF+2WyWHDgAG/OYZka3cFmr4M6Dx/Ji+zkhVzN4/Wl9Dk9IZq1mKz/g3LQrQsk41thvEYplmDq6ScJS97vDAKrY2z8SN5yuEcTtnyCfBBjFsavb5GtUG5c+dOREdHo0OHDnj88cfRsWNHp7I7Adxj2b4raMVKwsWLKIblDL43fhGc569ZE8nS82bsOy+kkTD002zGAG6zuvO2HkYt6jEKIt5afsRmX2c9k2moCWHJ2OdGtfv0X4fqV5EADd+na0MWB3qbLXUGuSw2L3sSIpks7BSlB3MbTSrGF75q8VKdN7n+fqkSI8+/C2z9VPq//BBaYW5lWK6WJHNSzXVf7jbsUQBF92cI476Xh1iHwCisV/DUP8kdxEbdJPRJck/LzubaVvfMoSuZuGjnPT97OxdTklMdBOyVwpt3Go9Gty+2oduX23AjIx9Hr2Va5SI7TvBV2VsYaVyAz3VfuxxrLlHWe/VXmrKnLe3kmrNS8cB5kX4Pd+X2W1JsXub+xlr9VHzELcCFO3kO4WhXMlDO8GaFuH1R3nB+IlobZ2G60A+/Ca1hYEyoKZ4Dts8C+AJAFAHBiAEXJtu03wQkbdZr2krQ9ftRWswd/N69wZgF1FlT6eUQyqLdchRBnltyWXPKSmRlx5Bs5jXAPGZe5/5n0FdjO0954oTwBXIkzHpujAL92dyX24KPuPk2rRcFosFz+AcAkK6QQ67I/SgblJGRgXnz5iE4OBiffPIJEhISUL9+fYwePRrLly+3dMwJ4BkvNE20qSS9bO7Vucqcb/Uq9ydeUNk7+bypLK4TutTEPSKtDu+Y/y0kGjRi1ee+1rjyGwZQ5D4A4M8U2y4xDRLDoXEjqcKdcKa9l1BQsEULvZFUZAfNUO6n2eTRuSKZPDzHSV014pl0zNJ9g1xI+VDhrA8LeM5vAdIvAqukLh44sNDlIQwDHBYr43OhO/50Uq3ojLTt3zt9f82d8lgr0A3OuUJ3vLHcc4+E/T1DIz3X6CBgn0KqIZ2xnfzE4Gh8cTIMR69n4ei1LLy4cA/G5s+xyUVW+h3UkEPo+bbFrcL2JctNbQAQxOEurpByGGEci46Fs/Cz0N5mvx+ETtTj5Z7f9uFomgxUn6aJDvJCNGjduuSe4p4gF+UNblkJZ0kiRmn+wGnDEIsANwBg7zzgw1hgTjPggxhU4s9Rz5XAXwK+bSN5mBTEz7Nga1wY5T7ud88pFsiUNHIUQe7qc0dj1Zku8xqwoJP0L18A7J1vyefWFmbCyCo3NaGxzK562h0nhC9ZtvcydOBtpLDmmZ5W3D+eSTcbnnfNx/2DIKYQhABRTC41v5JK5TbS4sJPwt6qp/uQkBA8+eST+Pjjj7Fnzx7cuXMHM2bMQHBwMGbMmIHExESHgpkA6pn4W4p5xVIOOvDYIko9hWPNlYBKISQaVTV3UZ11bCt53hSDofxELBY6IdocxstCCOqwV7DfpM6byBz+Ea9T5D4AoEq07cNv8ooUmBRaW9NYtPOCamkPteH0V9s6JksXF0evB0E85722hXL7xrJKoVYXONMptJCXBnzREMi97da5G7EXcdgwCt04z3IvteXrKeb9EELwQ8xSPMUdcHjvuhiJZLGdg/ajO6i5Z0Z1qEEVsM80SRPfofJSMcmlHA1+2FXUp/vM7VxVDQLasUewwkXOlIkAO8W61PeKU4Xta5L1/4ePuXkYzv2F6uwNtNccQbLuHYu3UvZst2CPYy551ubY2XwvpBBJ45QWjt5xRnJY1CkvLYTXH7upqlpbqVuXp+oPclGe0ZxLqZgOAaiS7AIgeZgSkoCG/W23x9WHLkRayBRUkiIgTEgM0HwEIOQDZZ0/szNEqSitgGixV3DeZOKg6L3iliohPJCfCdw5JxmTV/cBP/eVjOwdtjmUelG9GsF3fBeLlqmMt3Kqi4u97N9YLhkr9P+nuP9NEoUk9gx+0H1iPu53ANKiHQCSzDJyhHFSIAUAF7f5VdjboypvQDIwo6KiEBUVhcjISHAchxMnTrg+MAAVOcwm9wAdxEkerxbmh/HTHk7g1pRjs7BW/zYGcxst2+Rcv6aaMwCKdCfdQV41xkfYelWU5D6U0GpYHLycgZ/2XnY5WagNp992M49TDfZej+ncArSDoxFUWjjTKXTg9DpcCyo5PdbIS2ulB+AqRwmQycmpmHCO3ks4mslCowrhDtqPrrDWH7S/Z+xTN6KCtaifEEYNsQ7nJ6KX8T2I1w6ip/E9DOcnOuyTQqpiJu+8W0wPbje6afY43UfDAL04zypiS5u+3BZLzlh/7l80Yc+hPHMXfYzT8L7wIlobZyOY4TGSSbY5bpx2JTbqJiE8iKOGo6ubq/RP3JAMuIx8QbFa2/ozV+rWpbaLlz2yeoB8jyilQwAAnvg/oJ1j1bsNHd9BWnYB8t6LgZhi16ziZioMuZJH9E6aJP+ly70meUAB4JDz7lE5MGCR8AQMDI8k8/NdibrMBefjtCPL7EGnSeAEpx8DPqkIfNUEyDbnkyr0MXeH1pRe9t7IqfYU6/usbFv1sn9AUTV3LYVcexmG0PUoHfCTsLdqg1IURezduxczZszAU089hYiICDz22GOYO3cu4uLiMGfOHJw/f96XY32gkcNs603KkirFJVRBCsgaPZznpKTVGmDz2roDBq3vujssPyDp9n3xzxnUmrbOQefPGlpuFI27Oe4ZtWqw93qobl3pp4TnXXK9k7c575izm55jpOq3/cS3x6v8OBy+kun0nrCGpj9YK64MyoZoIcsA2XdqSc8rxBOztlIE7AmMhMMc3RdIYs9YJEzicMfGIJ3OLcAE7QqXY9Mzngrz+Dc3FdQighkev+o/wH79a+CJBrP4Z6n7zRW6IzNfoBZaCAqhDuvwOO0z79awvEXqR8bAsW4vTOyR7xFatTcAILgccGAxsIWu2yuY8w7Fwz/DsHwggmEES5Tvi8Q899shJrLpeMncSUcOSyuhZwRsEdRFwfKJFsMLpUpluTCpWBgiFN8abpSuM9A4mapDqSaP1lOUxPBp95lp//fUc9wV3cyH9AChyUsgTqTYShLVBmVERARatmyJL774AmXLlsXMmTNx+vRpXL58GYsXL8aQIUNQqZLrStEAdKasSMGJK3cwUbtccZ+TJnVV9AJR/lh/dlFJ7EwyYk90b5gubLfZ1lOzA3IOZZ8k2/EZi5m/+GzjBEWjlNY9g4a9kVtcCCEOni4lEVsl/vIw/9CGhCT3k7cVKKNioeF1wh0nAvnvat+1KUlzFptEKa9S7QRCq8Sv/c7fuJvLW6IAtE4tcoqEnCtXo1wIZnDzsM0wAfFMus3+/+jfsDFI1RZmPaiEuLiPopksLND9D3+LzZDG2UZCtprqIVmUnk20Qgs10kFKn7ks9SNTIIiqFybOkO8R1kCpWtaHAnnKYXXObOCx6WcRKqQr7ueSaO9FFz4zvYB0igasPUEMjyc0B3GbRGI4PwG9jO+p0tgljMK8VJBB3bxU6IgNJAlXSQy2kwaoXa+pzfvW7VS9ias2vrT7rNceuse7LJtr8zqLGLDQ3PnHFfKiwxXn9m/wm45Bqg3KTz/9FCdOnMDVq1fx448/YtiwYahWzfN8pgC2yDkY9Vhlb1FtjbrOG7dJGMYXvoKToqMB2o9T39fVnlppaxBXaDu+muw1Sw7lxN9SYBRMEEURRsEEPad8e9Eqxe3p/e1uxQe/2nC6fcVucZmcnEr58hL00OxQdfx3fGeMEsZjYOFkXBWjAQAmxrnyH09bINxMhU6NBHVwtKpxqX14eYs7rd6xeU0IQe3yodBpYNO16TYJx3/5AQAIEiMd+zwr4SxfUsmjvMzUEQcuS7I9cq7csvI/o4/CdyaEke5B2cDsq9ns1sLiQSOUMSKfOL+X67OXcMwwDOUE2xxvSeFCmrBphRZqpIPckSnzhmdLvkfKDkvG7R4/48KAnZJUzsCVQL+fgbZvFPsaLrlzyu1DVgqtHO7TGXxv3CPBCEWuwlG2yFqswzR/oZtmt0VzNxvKjSQY4kZCPYAB3CYb3cltTtqpehNXbXxp91kKqYYlomst6RSxGp51MlfkmNUdRAKwKguOzojxftMxSLVB+corr6BmTc/yTgK4pmy7EW7tn+NEAzCUyUNL9gRqe7n123ETPUwk51BmFkh5TY/P3IJa09Zh4wlawQc93GjfAUHGvj+4u6jNsVHb65f2MJnOzVfVZs9EgE9M/QEQnBXjkYUg/CK0hcZJqAsAtIz0IN4pSBIcRkMc8OwCnA9t7vyCLrwkMjtNj1g8JiWBSICvT4dTV/3vM/NtKqVjmEz8qP8EH3PzcM+Nh6azHFuaR7moE4/kHZNz5SLdaIm6zNQePTXbXe/4ABPkYThfwxCL8UArtLAXm5exlpFS8mIOsMuJndSlVvE8W+bK5RpB2VI3ppjaiGncFVVq1JWkcqp3lORyEpKAkHKKp7mRNMmtYktv0ZA9h9Fm77xcKDWB+w3bDBOhVXgOFCpEvfpyWy05swAQCu8qUzRhz1icDh/0rK/YTtWbuGrjS3+2ELSA6zzRaCYLMxQWnTmiFqdIJaSJYWAZ9bnwC01PYZSfFCd5XJQTwMskJOFL9LXZVKjQC3m10Az/xw9UPFUoU4g+KiWG3OEx7hTu2smWWOdQylzPUDbKnIUbaSgZhEqThz2uPBFyeOPnPZddFgQRQjCCUmWspDdmj4YBThuG4GNuHhboPsMj7BXVUlAA8BgnFWjpy4QBv72IBjnbFPclhkig2xf0N8Mkz/VNfWXpvBr387OKwx0Shu92nLcpqpANdSXvYV9uCz7Q0O8RGrQcW62ljYijR1lO3bC/rzr9koMjYhWX11sqdMRM7TeowV53ue+DipIckFpk0Wrad95ebF7GWkZKyYv5Z6r0mZQzi0//cdjDhTYhkkLBge+lymU1nUp05udlnR5F2+pLBkXs5dWWCng1eNJRhUZV9iaCGB7LhLZYInRCHtGCc2G8bDApa8f6ktrsVfTn/sGwlvF4pkF5p+1UvYWrNr71E8KgtbOcpnMLUNPFd99EgNrsFcSymZhJySPmGS2S2DMIZdR5iWWS9e+jweF33TrGVwQMSj9icOh+AEC2uYJOR+mFDADPcPswQ0fvWONrCu0as1nnUMpULUfP7dNzrGKe2TKF7c81SaQad0qThzW1Y8sgzKBBr7k7kHIlg+qBnGL2jH2xSZJpcFYQNHlFCnp/s8th+xxTT5djsaYvt8VpaoNL7px2+vYJUzxukLJApUeBjtNs3+z4jtQZZ+wRvE1e83wMxSCGzbIsIORQjbzqTyHVsEJoTT0uGeqLn2j6g7w5p1d6+NsaFTXZa/hE952D5+q1tlUQAddSPQO4TW61MH0Q6a7ZiU95x17WMv+aGjg9Xhattl4E3sjMR6852xUjFdYyUn2b0fd5u2sdPNckAWk5hXg+KRGzXmjkdsEgAGC1WbN16wzptdwkYEZVh+44RYP6GRi1T2ogAEjGZI+v8HHNZeh89WW8xo9Fb+M7OCEqR2JuieHoaXwP44WRuAz3VTiU6MttxSbDJAQzrsXBvaEy4iljuZWYdqh9iUnjTH2K3h97inl7p5lbwdtF750VZsrpRPJ6diyXjAnaZIf9Is1NLwwK874zvsp4zO1jfEHAoPQjFsT9B62Ns522ZitNboiRKG/WxZSxzqEEgAgDh8QIeoJ2UqVI/NSEviK374Ag8/w3u6gJx0qThzUnb+Wgw2dbcehyBqYkp+Lg5QzM23rOxgPZ6ZEY6rG0CUypCCiFVEUG1BXIFNeLo4Y6muuIN56VPCipv0kbm78i/Zu6XAqFrxiGXm2aOoR+sz1tp+gmcprEpbv5uJlZgIYVIhAVxEGHQrTTHHbYfwbfByc5egECLV1BKb+KgfLDfzlx7BZUaddUVGLVNW342DSgVEKYalGlT1oMIpg8S+TBnjOmOAzh30Jr42zsRUPqPstM7SyFFtaRg0NXMjF9neNzIypYa1OtrbTIfHNFKlYclBYQyw9cxdNfbPesZZ+C+Djy04F9C4C75yXdRWvjcs9cSeBcNkJTfwU+iMFjN37AWZKITWITHCHVUJ5RTk2JZTPRTbMHM7h5qAhHfeH7ieLcg3eqP1ciAt4/7aEv9n/eK22ntVlMIdWwROHZ7ut0ohl8H3x9NsKn11BLwKD0Ix5v2w5XSQzasa4fdnwJF1EAQFkmk7p9k6kRZC9lRoEAXqDnUb3xRA2EtBxGfc++A4I1d2mtDlV4KK05dkNqhbdwx0VLgrVRMGHGOnpSOy3sdvw6vV/udG4+IlQms/fQbMc1sazNNtGVeK2nbPkESDsF1HwSuH4QePlv4Nl5lpDd0/zf6GXu0iPnUt1FBH7R9nBy0iLSPZTEmMk/jxRSFXqOxalb2Zi/9TyMgglTxG9w2jAE0YyjR/AVbjXefNw23YAm3yEvFpR0BiOCtYo5lNqKjmG9DUHq+uvO4PvgNolAK3N7yuLga8PPlyhFVWpobuJz7gtcJeWQROjPtyW6TywLAfvIAY30PN4mkqBmkSnjkZxYQpKjx19m22fAl41tQ+GiCDQaQN29GXcOsUjH59xXOG0YggiG3ipXZhi3VrE47H7CLY1cO6J/7Q7TqjGeeZfdYJtCDqW8XW6zaI876QveQK6j6KHZiWGtKpfotZUIGJR+RP34UNSO1iEfzislASgmT3sDalUxAB0jOuRQAsAC/Sx8zM2DbFT+e4Zeud1n3m40XXAbS/n2NtuX8h2QQiorjkcUicNDxJ2KThrbz95BrWnrcPoWPZxJy72c8ATdSFGbQwkAe5kGSDBLM100t9dk1YrXekg+9MDVfRB/6CG1ejN7S5itM1CduYa/hcZowJ5HT+N7GFY4EU35g6rOG2WWxJDbhKplgnY5PuIWWLqNfLfjAmpNW4c1Osce9jLhTD66rbfNIaPJd8iLhW4Ny1tCTDI6tijsJEsTyYZ0D81OvNnFMdTV7aluip4Ha0ZwqzEqbBtYBkgjoZjHd3V5jBIsAxS4qJb29LylSQ9uDz7m5uFHhcUjaf6apdBCrXFo/T11Z5F5/AZ9ceiSVGVZNwtyKHxOc2Ah5Z4uE4ege6cwVL8RRhXPems8vS8KRO/fT6VBr901fCqRQwhBeh49BUAu2FPyhI/ix+AakVQ1NgqNfDI+a8ow0hx4TozD7exSkH6jEDAo/Yi101/Aupzn0ZdTLrbwhI2C89wle+SqYhr2OZQyUsN750UTVaJDsIm8hAHaf222D9BuxhG9cpX7P6fSHB4iaotylEiIVJa3qB1bBjVjQxyM2Geb0HRACeaZulHP86fgWIX9BPZa/l9ZZSi1uASd/gMAwAr0h04mytgIdp9p/Tk6GP+HnSb6Styeih78HstM7R22bc5ORKpYWfGYDWV62bxWWlRsP3sHtd/5G/YyqIUicMc8KYzix6C1cTbeFwajtXE2RvFjqF7pBonhaKFx7XmIYPIxqFDqdFKOycYI7RoAQIboXq9iGcMDKn7el9sCLURcE6Ns3whLRMTT71oKLdTkSL/RuaZNzqs7i0yPOuUQAjw7H+SRnup2bz2e/kaOFLYewfyOPm4+6+X74nh4W7eOY0tQxcFXHDZVMSsx+E4iZ3JyqmWha0+1GMmZQuukBQBnSSIGF76J1sbZGCa8iRNi8cTz1dKV24+ul2aUyLVcETAo/Yjt4crN5ItDR03x217JHBGr4o5Ir65zFrYGpH7HCwW6VpfSdpn0XKNNrtzPey+rGzAFrYbBlKeUBYFP3spBnf+stxixcmFAu0//tewj62jO5uZghf59h3OIBOjG7XXY7o/Ik5pccd947zhs1r+BxzTqW6kKbs5XM7XfOGybzi1Affai4jGt4mw9uUqLigSFHF5rzpJEXCUxqI+zWKebDAMppHqlJyenYmThGJw3tyS9QxzvfWd5sUEqCh4eNpaZOqK8WSTe0iUly7YFndKkbc28rbad2ZSkouw9s3qORa/G8arGasPqMcC3bcAc/931vu2nYPK5ej7TJX0kU706xHDjBLzKj3UqNXc/UNdcyEjr9e4tnC1KPuwp5Uc3rBDh0H0JkOaET7TzEUmysUL3H1Rk1C+0i5vCFtdmSInkl7oiYFD6C4Sgb7ensNP0iNdP7c1Q15PcQUSzjiHez/jnkEKkLiPOLve5qTcuiraFMBfEGHxu6u30uiPaVrOR9rlTjJaKvIlg4q+ujey7OQWWHL1DVzJx5V4+7HU0C0Bv/6j2b+5Wvhylu4wv+CRHXd6gNa5kR+yZK3R32OaqhWVZxjZMqeTFigjWqhiBiBDkYZpuKcowBXjf8BNi9YVS3psV6TlGnCUJkgdTaItoJhsZRPJu/yJIXqI+mi1YrlCZrvegYtPlyEt/3rDg7lh2mOrgHCmPLab6AABSmAu0mwI89anNfvUTwtC/ufOwt8FOu6V+QhiiKJ+9/RiNgoiG/7fBvYEDykU5NP6djqcvfeyQWkFt06iAUUE2zh0KiQYnSSJmaOdbQqT3K3vF2ogLZtAgQf3f0F2c6dfKEQxCCMIM1pE6eU74B0nsGUzTLUUSexYhbvy9i5vCVnNN7xKrgndGwKD0F1aPQcPFtUpcE9AdrpkiFN+bqF1hCXk7/2oQVGRsBc8rMbddHvX8N7tspH3+OUkTTVdPZp6aLztjk6MHOOpo9uX+LdY43DL2M81e2XJ0WQuZrGJ4Ik7Vfh3JYlucET3w4KjkgKk6kkXHkJ3LFpZtJ9q8VBK7fqVNFaphYc1G3SQcMwxDC1YqykrCccTNrQFxTnMQQize8L7NK2I6J4mty5qhEWZ5j7pmb6qB4dGBUpnuKa4cDaWdC2nNX6bmuClGAgBWCK6lS1ppTuCYYRg6cJL3nxF5YMt04NpBG2O+08yt+Gmv87D3hE41bdJSOs3cqpj/Zg/nyR/RWVEOhbgOr2IUPwbDjOPRW7MFE43DEWq+dwS4NhYLnS7N1aFjTNhmmIBoRn2ed0kiuJFD2kpzHLvFftj7pe9UUBokhiPcoJDWZY5gTE5OBZtzw9LprWhO+B0A0KIYxTlbTfUxT/Aw/zppsMfX9RYBg9JfcGf1W0qEsfm4IUYovu8q5A0A07l5DhMiywAfcfOLOTr3IC56fOs5euMrV160EkHOhXzEURwXAMKK4YmodfJLHA16DRWZWx6fwxVJmrOK+bayR8doV3wgBEVLE7oVSmLXfefvdWlY0DykAPDGjY54c3mKpXL8k3UnEaUwGddji9IuylIq051xh1LcJuPl9vM+5RluL+LYe7gqlsVz3E7PT5TyM8icopxjmjSLPZNXHrXJrVZzjIzHothqinIAoOM7qN6gFXJ05TBK+wfKMAV4Q/crDIyAQsKCgwkkurZiASQAhJZgHu09UTmn3FecF2MwqnAUdpSlP8eUmJdLjwZ4g7dWpCCzwPHvbuBYxIYZAEKQlZ1tiVD9oZ+G5qz3nEDxzB08zkpFke54/68nTXJ4PpYGAYPSX4hvgos6/2ifpEQoY3TQoZShdcyh0YY9prC9+HIr7lDHxYRiFESqf8ClF83XhMQA3b8Eaj4FHHcUx/UGZUiWT0K11qw3NaVuH8W/jg7G/yHPnEogCz5zBsfP67V2VannSIx0nkMZhzsYyG10kG/aaqqHZLEdfjtw1eKVPn0rB3OEnk7P5wnRbI4/pDx5jeNiJdX7KoVyz+QWGTVK0iz23M0pKjRTewwAXM9wLtNDxVyUsze4netdU37F1Q/rYzfzEhqzUq5nebPsms5c9MjcOem0ANLXZBGpYKyAaKH18fedRlX2Nr7VfY5Wd9U/x2bwffBUZ+/VGthr2Crp1xYIIuZvPQ/TH6/j64tdLRGqOCYD1VjvLb6rszcsjgw1TnRZNJ09qnKh42MCBqW/sHoMKhcqa675Oz006rwTM4XnqNtnKWz3FTvO06WNrCGwbtdXxLMaSQ/umFgyOY025N6GaflwgLu/E+wba85Re7gP1azDZv0blq4RdVhz2DPOUangwOUM6rmrxyjpY0q5Tot1M9CEPWeRb5JppbDYuU0iwNsZQbmi49//msG9BeH95Il0RWdOndQUANB9/8DnwrMwFvIghKiq8gYAMEVTmOpj4GGVt7kop3meaz1I5s4pGIh7LfRktgnez6O3J49owMGEVUILGBge23yQu+9NTouSwkZPbqeNmL2nKGnYjntcOYfyux0X0GuPB/eNm1Rn1YvXy6LpurjaPtfnVEPAoPQX7oOQ92GTrUfoW74rWhtnY6BxMkbxY1SdI1lsi1y7HL9coqfm1JU2x65lWNr1SUgGiWjOf6rLel5pXhw0uTcBNZWmfgy9hzvBcpPCfdDaMeFcWauQbqlN5+bjtGEwarFXqe9/xPdHmF76bKUq/v8gEbfQj9tk8eAsF9oAALSUcGR8gbQgLPBCMcWDjJYRqd7ZOcK7uPJBfUxJTlUvUm51IqXKcK2dq0enYfG8QitHp7j5jP4t7GX3rwGgDef7PHoDTAhmeHTn9gAAnuIO+fya9izmH3faqtOamuw1/C00wcjCMdS2uO6ipGF74HIGtYJbJoVUxUo4dtSikS66VpvwFsNON8eUFd5Tc/GUgEHpL8Q3wd/lXirtUTilkUYK3cjSKYO59ZirnY0zJBFnibpV43RugUP1WwhjdKlhWRrcy7M1GuTk6xqsQt9ePyENUbjb82eka73X99dXWOfdTufmUyWYSExdh/wgQgiWKrRIKxDo4bsoKItZz+D74DvxaeQWClZV/Gex3TDepp3g89w2rBaaYwr/Mk6L8ehpfA/Z5tChbLZ40ov3YUPJOztX6I5tZ9JUexut7dKGFSIw5LHKNu+/ZNVBpHo5yXNdaBLR7cttNq06VeFGUU5a7YHoG1t6zwkjnBellWZhlyzOPpDbpNiqk0Y19gYuk1i84AUPpZI8kKTsoZyGMJ1bgF74R9U1olgP0io8JFn/Prpe+rjErqdEwKD0F1aPQZe0RaU9Cpf8JTS1VAwaGAEN2IsYxG1ABdzECt1/EAvnoWSlohY1BT2+QkcJawPAiLa2Hlm/KMhRgJSVQjX5bAheNE7E5a0/Iop3HTq5x7nX5cabyC0YZZSKX0y3T0mt7Ky8UZOTU/HbgWvU/S/dzcPAR2neKuVZVE7Z+EBjW8VP4xluL4Zza1CTvY4+mn/BovTy4O5HTpnKU7ffECPxp/gYXm1dGS80U2c0HL9u2w52pzkHTjYsd5y9g7kDGmN2nwbIyi+SGjt6LQtf/3sWBbzgXqjQXJSTHuG8WYTpwg7cvEm/P+3Jd2H8eYIe/qt/Kouzaxii2KqTRnX2Bk4bBqPwD3XRMGRec+ytbmZkB3q+PwHjVG/E2RyQUYIeSRqx7V8p1esDAYPSf2hS+iX/ania2++wbTT3B7YZJiCJPYv+3CaH3DhZBDwW6Yp9lNUU9PiKQhNxCItpGCmEZh39SCFVkUmK99D4hW9jSaQuLiJbNBExd88AAILEXKzVv43G6X+5PP6MGI9IoWS69dCQWzDKKBW/cBCkVnZWOmvOBIgvp+fjx92O6QhzTPTzDzdOsKRsqF001GYlY6E/9y9CGM81UR9G4tl71O3l2Xs4bRgMzbqJmPjrEQxq4TosbS9iP2dAE2x7swPe614X297sgK/6Ncb647cx7tcU3M6xNbIW77qE2u/87VYrv7SnvsXkiP8hMpOebwsAl8RymFtuGrQd3lR1ziA/Nv6cYfLSc8xdopv0cr4DIdIC9MD3tr3VrRYOSjrESkU5MkpFmXlEh9H8GHzKO9dT9hUz+D5YdDGyVK5tTcCg9BcOLi7tEXgF29w4WxFw2djsrtkBwLaPsjNK4rHFaaSvQnSIVF1sIsDgRXthHf2Yzi1AOKMcxjhurkh25vB4QbvNkkjtQDV6xxWT+S9gLpNiJQAAj1hJREFULyPBisWbiCpw9IldJhs6p7Im3sDaM51CqiFNoQsTABudNWcCxEqkkCq4R2zlUTKIAa9qVyHbvL3Uq/gfcL7lu2Iy7zy3cJmpA8IMWizZ4zrsfeyGrVe7RmwoKkRJn2WFqGAs3HERvx2g58zKqGnlRwiBkRfwbSpB+Ts7wBBlz9oWsSHuaMujZuO2yNJEuDz3/cYMvg96Gd/DdRLlemc7jGLx84urHPnUwUC0YfUYaQG61dyOUO6tbrUgjQqma01aR6usHSHWdKfMV8FMIX7Uf4Lx3Ao3fxvv0FOzA3ezS1+4PmBQ+gv3QVGOOywzdXQQAZeNzTNigkMfZWd4Wrs2vWddu44GkueRRoPEUFQuG4w7uUXeptO3bLUFXXmvHjFXJHtUvRtZFUhoYnm5RmgGALgmRmF44QRsNDX2St7TabNguUiAZI1zAd0cMQSv8ONxWfRNWNy6u5KMUg9rEt/YJo+yQWK4y7+H/YSwUVdUPS4TwRQgiT2Llfr/oAJuASCWCWO18Kibv1EAV7TXHMF0rfPUnr6aTbibq87rO6x1FefnUlHcM7K96+r8ycmpSH7/eUw71N5l3t+L3EbMvdAVeStG454gFSD+Zi7myqaoA9xv9NTsQHvNEVSwU0lQg54tfn4xk3bCwUC0QWkutVqQ3sii31/5hSKUHCHyTDSKfx3v8wOox3OMiLNiLK6LJestrMlewxMXAjmUAWQSkpD2yJDSHoVXkEPYSgbYPNMzEIgGq3RTMVc72+Id8jbT151Clp1IrUnBOt1zIQMX7+bR3zSTQqphjUDXT/SUJcLjOBbZCbh3vmhFDaArtw8AsEt8BKO53/GjoK6y0BU1zQVFLAP0Na1S3M8IHQbxU7BJTMKb/HCcFel5b8VhonYFZnFzbLZN5odR972bJuWDyrpxo5cecCL8S58Q7pAIxbHEM+nYZhiPj7l5GMW/jtbG2fhQGIA8ol4sO4Ay3/JdMdA4GedIAsKcePkBSSReanPqHJYBxj/hXMbl572ulRjklnrOSM8xup1DvZRvj6GFE/EUvsIk4TX00s7BHUS4dQ5/IpvokUmCUZO95lYxjT1Kz2C3yVUITyckgXSwLZ7aHjsQxthGlnzZsY/TFxEheo2iI0ROzxmqWYd3tUsVh1WdvaWY1uFL+AYDS/ya9gQMSj+i3O1dpT0Er9BTswMAoYYP5/JP4ySpgIHcBjRgL1qKenQoBEAUPYieYG9MeoPHvdhiDwCe0ezClJvKQsnPc9vRhD2HidrlWCp08Oq1nYXMdaQQRsKhMU7gB93HqM7ewHXRMcS1VahXrDEUQGez+v9LbOlwz3zLd8UIfhLO3s7GvC3ncPByBv4+rtx6U2lCyFKR/9qX24JRmpX4QvslhnN/IdhJfmROMVpcPmwM49ZCQ0yowriufJ4j9FB1TpHApYTMtjPOc+IAoHdSgst9Rnes4VY6xAy+Dz48EoyzJBFcQTqO6l9GBJOL4fwEXLYT1PcFd4nUianQnLLijXt1n1gb4YzzRbcavPaMb/W6Ytj71o4fAQCnzPqV9W4mo/601RZpna//PUc97l6+4KJw1Im0WSkyg++DVJReHYJMwKD0J1z0aL5fqMles6zm5HzJw6IU2nyZW4/ThiEYzRV5x0Zzf+C0YQg+4hagXFjJT9JOZMfsIPhKoWWfp7zNDzVPVM712OqzFzGA20x/U++864+97qcaGAbYZpiAlYb/Wjp7xLOOFfyRXB6EYngc+nH/2ulREvQw3zMyHTRHcLAgFp1mbsWinZJUkOCkL5nShNBZpdZeA/YSmrDnMJRbp7hPAeFQphgtLh82NAzBh/qFqKOgASqTT7RuFeh1qhNr0+nEHlddkwBg8CLHQkN7GiSGIypYa0mHSBPDnO4vLapNCEEe/k+3GGWYArwjfI1fdP9FRQ9CxUqkEfo45FagDAi2muq5vFczRD2yRefe+I6aI54N0lcsfFIx7H1VI6U61DIXz0UweThtGIyuF6cDAHKMys4GZ4Wj07kFVGmz0ipQkhnB/Yk7gRzKABYIAVqOLO1ROCXTDcNkmUnypp0j0gqxkbn9mIFR9or9E/QkfnipOcKDvC+j4QwnsmM2TOcWYKLWe+0Ov+O74IBYEyt076oOId005+b8Zc6xBDggzLnEihbSw/OAyfutPevjPDgvPEvl4pzp3ALUZG3lVqwXKGqgTQhy7qgaqrE3XO6jlOt5P5JdQp7WRMa1IZVJlLocOTL+iRrYfvaOTacTQohNOz017RiHmCWm7NvwWfPWihSk5/EYxY9BL+N7CHXhqavJXsMR/QgcMwxDY1byhlUVL7jd890VuUSPe07+ZlqGKMpxAcBqQeqfHsEaEcq6p1Zg0jo3qkuCO7X6On5mhKA+S/dAtiCSh/LNLrWcnvdZzVYAwC+CFD2SC0eVFqsapULLEiKCycMzV2a43tHHBAxKf2H1GGBhl9IehVPC3fDI9NVsQhzuogrjenIGgJmmFzD0hefRd94uZOb7p4zGzybPQ840h1obzVFLnt8+k7qWXiwjoo/xbRxqOgMwhAMQgLQT1H1Pm8pjoHEyXuXHobVxNsowbgo5lxDWepTe0imVPUmykoAexTMAM0U9jpmr+B+UULfcUzvUjzyt2QiypL9YExZUVFwna0zO2nDGodNJ0n83YPaG0xYjU0n83pq/jt6ktuGz1qeU5GQILpNYdNPshoERkGKq7PS8l8QYNb+yR9wlofjL1AKV2TREMs5bPNZjlf8Gz3B7PR6DhlduFFASCK3fwJyToY6f2Yph0OfSUyt0j08FoNy2Vc6/3inWBQC00aTiVeNYCGARi3TcJhG4VgIpC54Q8qhnnZm8CUP8oQHkfUBWVhbCw8ORmZmJsDAfrMyuHQDm+69wtrusNzXBCVIJY7mV2Gl6BI9pitqJpZEwlGNsH0bnUAE/NllmCWn6I9O5eejH/Vvaw1BNBglGc+PXKAQHgMGjzFF8rJ0PLQQklELSuDN+EjpgqjAcADBZ8xNe1f5peW8u3w0zTP3dOl915ipCkYdp2qX4Lz8AOQjGat1UBD1AnsUHGev7AQCaV47A6I41ARC0rRmDgQt2Y/tZ74SOm1eOxN6Ljt+Hvs0q4OPnJAHz5fuvgP99NPX7f0qMRy277lkz+efxr9gAq/T/8coYSx8Gnutt+I6zYnl0KvzM/IpgQJNYfKhZAKQuo+6fjMfx2PifcCurAD3m7HB4fzo3H/0UUoukdCcGo7k/AADpJARRLoz5kuKSqSy+brgSHz/f0CfnV2v/BDyU/kJCEtB+ammPwmt01hy0hHGtjUkAyCN6DCx8E62Nsy29wF8xvu7XxiQAREE5dOSPyHlD+/SvIhG30FJzApXZNGh06sOK3kRwomkpJ7zrwON586RdaPag9eG2OIjlO6fIk5TEnkE3zR5cJrEQffi4M4mlm0PlTQp9rD2qBnuPdHiQDm1rlkPbmpLXb1IX7+SbV4sOVkyxsdanfL5pBcXvfygcK9InaJejr2az15oYFBdXOZ9OYTj4ozEJSK06AUkibJ/+NXx4vJOiMQkAIaZMzN96HrXLh6JtDUdPo7NK/tHcKosxCQBRTG7x/q5epJLmbqD1YoAiCCEg2z4t7WGUCJXYNLzHLcFVEgOBaDBeu8Jn0kHeQ8RC05OlPQhlGGXB4HJMtk1P6jjBeWGEKlzkbdLgGHqyqhzylquzo815ZnJbtmgm265wxznTufk4bRhsKaoZxq3FacNgHDb5rgqSLeUcKm+iU/icSoodptoO+qTHb9hGNOrFhyIyiC5OrQbOLGJ65V6+okj+iLbVbMLeSp2WlCS1Npgal0hTBqdopPSM8OJ40jQlm9Oulq2mekgW21okwuyjXjTmCD0s6RE7KR7uFFINK4TWqsdQjpWueVGMVj9wHxEXaL0YQGby8iOYXfB0aQ/DayxxoZu4VOiAZN07GMetQBJ7BsO5v9z0QpUsG3WT8Iv+w9IehhXmr26keeLVh+ITvIS7YplinbWQMJjHP+V6xywvGKVm5BaMrnT+1OZRRoE+sbTi6Lmm3sAjMfsAVFppTjosHsZ3knKM5cKZBu9vwL181+kLegWNms51Y/HLiEcxd0AT1IsPtemQIvP8N7tsZInyyzVAGnFUVGjLHXfYBgCf6b71TbFGnOuwZoZowEUSAwz4DTPiPsMUfihuihE2+xw1uRZ9BwAIrjVBPUXO4/WEFuxJy+JRTVFjmhhmoyDAsoxd8wMpQtLOg2r2yqxreSpfU/Oa9wpGPSVgUPoJ404NwHjt76U9DK/wHd8FzdlTiu/niVo8x+1AE/Yc+prDm7IXyZ1q3pJkrhfkgvYK7rcLVMbsRbonVc+jIANvYRHKspJ3L92NallreGgxQru2WCPLFN3vd77M1AH3SAhyFYTElwodHbxWygSsu/sd68WDjgXe+eMoDlxKtxTO8CZ1XlSjgor2udu5qFQ2BJ0eiUPD/9uAQoX9XmhaZHRVjAqGwY2+2z7Jr6veGchR1mCViWALUJm5DSztg26PNkA99iLi2AwARRI3dVnXgu6qiK4NtBrn0aF6xvPOOXpGQBzUG3I5sH4uEYxsnYjh3F8Wh8YMbp45QnJ/pTZZUBJ6L0ECBqWfUNhynMfH+ltZVXtNCkbxY/ABTy+kCGZ5xcpDJe9SaZMstsM2U91inaO2xntePVd4kt9jJBqEOBHydsUds5hyOCt5NAqIupDkDL43Bmo2YpthguL1B3CbVC82lEKT/owTWc2HjmxRb+NJKhSBfF7Ec1/vwtodB7BC9y4iTeoLclpWsW2DFxWsxalb2Zi39RyMggkaJz08F+28YJGl2XX+LlJF560efc7Z9UCOOuUMAICpAI/8/gRe4tZbNsleU6951e+cBHbM9vjwPaaa2Bzc2aNjm2jOOmzLZehRmhNiBcgRsOncfIzb08YmLaYPt8WjMfgNbSeW9ggCBqW/MDejBW6Ywj061t/CbTvEurhMYrHHVMttY3euHxsDj7H00BYA8OG23jMjJE+bLDx8jwThkA9z+GjI+T28yiILT2wa62Oi7TT2XGk1FhApN2sEtwZ9uK0ur6U25J1Cqnnsoc0jpZMv5o0+7fcDav6+QVStWuf9lZ2x64JtBXd6nnT+hTsuota0dahZTvle0XMaHLycgZ/2XsbPcT/jMY3v0iYeVlpoTqND3nrXO1IIp0ihhRC61mdXbr95UUoQjUzqPpdMpZ8L6REh5aTC3lImYFD6CXez8hHD0m/y+40XuY04bRiMhfr/uWXs3iFhboQ1S54PBWXpGm3meZvXekieNjlRPJLJRzvuqO8G5wStyiILgwfhp+LYQQaGxy9CW7zLv+hy33n8027dG5lmb6msQ6kWvRshzQDu85epBV4qfAObTQ0U90k1VXLY5qq/cnE4dlNZbPzX/VJU4Yt/zuCdK02LfS1fUeBhLqK/Rbd8zQZTEvbpX8MTSl2zmPvUJNI575ZWUtynf70HjxfTZxerx2ma6B83lDXl3MxFiWay8BE3r/jXDZW8g9Eh3vQ2Efxo6owUUymHvB4wXuC24nPd1y73G6H9Cx9z86DGIxWHuyiEBifEBHwjPIPzYiwAdZOnN3vJB3CkN7cdi3T/A4jyIuddk6NAs7cE72lUjDSo2i+FVMHnfM9iX88XaOBZZb6/Rbfcwd00kSOmymikOadYDV5AtHiVH4csou5+8AfOoCIwcCXQ7+fSHgqAgEHpN8S2G1Gs48ver4nEdnTX7C72OeYPaoptb3ZA08pRXhiRhOwhaaC54LVzPkx5c9li8bvL9OW24CNuvpM9CHQoxEBuA2qx11GHvYbf9dNwhUjahd6ePBXqOAKooCKbRt1uIgy1l7ez/srF5Uya8zaKMht1b2Csi8LJ82JcscbCu6lbeZqVCv1y4X4h3P2Ou2kiDTUXnVaDGxgea/VTkefjTljutDB2RTVcA8ISgGh1ndZ8TcCg9BMydxQvdJNJHowHynlT8R7IALBs32UkRgYh5ar3UghcSdp4gj/kzZVUH+dQ1jvt/Wi9kGXpj9ncHJw2DMFobpXlvfJMBtppUh2OUYOzHsmA77yZD0MYshp7i7rdpJhEQdBDY9vZpKdmB7whM1YhQt134A5xneMugsUbhcNd7qeE1k2ZoZriGQBSE4MA3iHOx6ln7rQwdgULEzC3OfBVU794cAQMSj8horXnDyEAiGTzcc4U66XRlB7TTMOKfY7bmQWYvCIF1zO917ta8pD09ujYP4RHvTYOT7itkA7xq9AKd1VMktbcKabOZXGZI/SwemVbqFEAuuSQuywSpIrTUJR8W7U7JMRjT2oe0eLNwqFe7XRT0p1eZvHPU7dP5+ajJnvNZltN9ppXcigLVaYOZ8L1vV+dvY7K7G3F6MMDG5UIS6Bu9vdfN7dsfZvX90R/b7ChQPo54PfRpT2KgEHpL9S8tsLlPrfFMKeTRSWFMJK/Yr+gIgReCWFtOn0Hv+z3vkTPcG6NR8e116R4eSQACXIdzpdle5R01fpwO1CZda1pZ000q1zA4GvSxDJIIUU5rPaFGn290Gf9slgWIZAWIlwpeJCji6FdGMzwaMkewyGxulfG8ofQApk+6GClZFTlED2+E58GzQxRanvoDZkxtZqWc4SeqvYbzf2hGH3wZlQiWyHXTzBEUrdbU1LOLF9+hQQv/A66u8cAABnm+zySvY89vcddi7v7moBB6S80Gexyl3JMltO2aEqt7UoatQ8re0/MbRIO/13TElXVyDTCVYajJJ00dWTmue5eIcv2+ENo3RuUY3NwQv8S6uMcVujexd8m71fdVmTvqpIwUou38ywviDFO339asxstNKe9cq1IJhdlWe97aZXuxzKMUbFye46pB+UIYC5lu233E9eIoogqZV2nDKWQahZR8JKG5ikOpUjmAABnMisVaJRD+V4vxsm7Czw6yukuRrMzRGl+yHSzGKa4C758ooHWXMz0IKQMEBd//5IgYFD6CwcXu9zlfqnI83ScsWymV6q8fcF0boGqamQl0kXn+Xhz+W7g4LqVnEwE47t2aB7Bet5X2R2CGB4/6z9AEnsGTTWnsMtU2+b97/gu+A/venFWUng7z7KKC4+yzkvXEwnQVlM6MldlkQH7hWU/zWbqvn1ttnumVXk3T8CFu+q+T3cprRdLAk4ht/KiSElz4s1RBJP3cvVcIhQAu+c43UVvdngozQ/hTEGxWjG6S1AxuvTYs0YofUmpvUdLXyM1YFD6C0lDSnsEfkFfzRbUw3nXO5YwxS3KiXLh6enD/YsarGMHDLWi5KWOqN4YLi5lzEnto7lVaKk5afPe89wW/GDq4pVw2MNMaXq1u3CHHLyUamSDnGlVuuu1VKI/Pw3HTRVd7ldQDIH8PKLFG4Wuc8ln8H3A+DiiU9IyacVpxVjSHLZqVNGV21+KI5HYaPCs25A3uU9mq4eAhCSg+aulPYpSh2WAd3Q/IgR5gIfaar4ghVTFTP45n53fvsuMjDxdXHQR6vQ1OaJ3Cl58zUGxJirgJkSUnKcjgPex1ZckOEkqOnSa+o7vYpNzrWR0Lje1tenZrLbDDo2zJAHV7IqDZOTcUJ6wMFC7/agjmOHxvvYHxfd/EdoBAJ7TbMNQ/g2sFXzXIcWbMmkPGo0050p7CDa8GrrD9U4+JmBQ+hHkwr8AHPNlSqsdXGnRgj2JY4Zh2KibVNpDsTCdW4AJWteFU97kTeNw5EPKg3K3eMaenGLKA5Vhpc4//wiNPD5HSRQCdNCkYJthAnRWno7bpVyZHsA95vLd8K72B4s3UfY8NrabwJ/jttm8pgmPnxTjkax/36Zns+S1dKZnqsx0bgHViyYSaTF8g0Tia6GbR+e2Rqmn/WvGMbgJqSBvh/gIbpAoPKo5VezreZssL+jOBnCPKD/Qog4YlP4CIfg8bBIWCZ0c8mWCHtJ2cHOF7l47V3FDXp6GvC+YPPMsLuE7YJxuOcLdyJXMhXJSexkvaZ89zh32+NjSygGOKcXK9AeVQh8Wp/Tl/rXJgVxvakLd711+CKw9jRt1kxyEx2uz16nH0vRM1bDeRPcGyikC5Zl7GKNd5RO5pUtiDL7Wf2EJ6b/I/YNjhmGIdPq7lM4UH+Yl3dkA6hl5pUNpDyFgUPoNq8dg3LmheInb6PDW/VKMUxzsq2F3m2ohWWxneV0fZ3FU/7IH+ZVSon5xQ160Th1qKM/ec/sYABik3Yx4xr1jZbkbV/ibFt510bOORhmiHlni/dMm7UFC56YAtztEmQ0kOQdygvY36n6f6+ba5Fq6swC11TNVA4EORjTTqC18KN2H9kWxnPl/IkjTYYDePb3ZAPcX+USL9PC6pT2MgEHpNzQZUtoj8CuasqehQyEAE0KQh2m6pSjDFDjNr5S9kLKsTCzSMZ2bj9OGwZSQl/uCyN01OwE4JtzfJWWwUOhCPUZtLtW5YrZsU8Nv/GO4RcJLoOCCASIqqd471EPtxQjWiDDWe+L1AfyT+uxlxfescy2TxXY4ZKrq8nxpYpjberdS2P0ljOT+crnvBTEGI/ixuCFGuHUNZ2QTPV7lx6lurlDZSpOY2b8AMBa/+8t3fBfkagKGqT8igsGUJ2u73tHHBAxKf+Hg96U9ArfxZk6cvbwKxxCcNgzBEf0IHDMMQwtWyhOi51dKXsjJ3I9IYs9glm6u2Ru5GhVAzz30RBB5FP86ehunQWOW98knUqFKFglGa7Z4EitcCRQg9dbuRCzj27ZiEgSo+CgQXRvQuc5fnMwPd1kVW1iCciIBJNLFEAw1jvfbv/0SoZONYVgfZ9CIdYxgyC00F5kXfTke9L12J+WlMnMb07ifUJ7NcPs6SoQyRqzVT8VwFQatInI3m7LuCd/Lf7cXYy8iJEyKJuTHNPJ8HAG8TghTiMI/xpT2MAIGpd/gQjbIz6KUAEomFL9QeJK63Tq8NZ37FqcNg9GT2wMAqG6W3xnG/Y3W3HH68aaebo6EYIRmDX7Tf2DptxtkTpzXQHRoC6eGPOjR0fg/jDG+hhwY8DXvfjL/AVN1LBaesNlmXw1bKqT8Atw5CRRK4UulvtjHTYnozB5Q4ck1YZepps2WHNE/DZ0HhSg2F9N1C6FjTMUu6vIFzVlZMkpECPLwnf5T6jMpksnFH8KjeF8YjNbG2RjOT3T7Wu6oPNwhYaiq0Ku8uKSaKmNY4QT3DyzfGOi3DBhz2C3N2Byiw3ShP2bUWgZt3x+kc9R9FkG3D7s/Bj+hJKJBpUFx2zd7g4BB6S8kJGEF97Ti26WZkVNaOXe5RI9lpsexzVTPZvtWUz2b/MpnNHvcOm8GCfEo5NWH20J9ryJ7x61zyQTDiE36NzBcuwZ12cuK53dGkuYsBnMbAACnRMkDYV8N6w9EKoS1H9FcRXvNIZfH6xigpV0HmDLs/aNZd78SY/Zoe6uoy5ucEeMBSMU4xwzDEOOkOOU7k/RsvUpicJYkun0td1QeyrHFbwepxKemftgoNnGoZt9jquH8wBuHgG/bAJs+AJ6a4bSLjjVlmEIpZQh/ADG1pZ/HSr9ndHHYJ5Z+aNjbzOP6o2aTdq539DEBg9KP6GL6t7SHQKW0RI5DGCMmc0utPBESLdiTsPbZzhe6unXee8R9GRlXIa8lwuNun1OmPnsJAFC2GLIP58Q4TOf7eXx8aRKu0ELuQSZdDEGmqD70Sl3TsY7aoJku5Fr2CC4Mj/sIubOUq2KcW2IYbpPwYqo8eKeCNr8YEnA8YXGSVKRWs7fQnFF3Ek4PnPxT6qITpX5RXbatlfcrvgnQ2H+6UblLX+7f0h6C1+nAe69dbHEIGJR+xI/lxpf2EPyOXtwu6BnbLix6RsA+/WuWyeFz0/OqeybnEh1G8mNhP0UH65x/FZxVec/lu6G5OcdzkUJxjq+pxt7EFO3PpXLtAO4TweQinLWVhHKWk2y9plsutJH+IzpqFYa7kGtp9AAJVTPm+Hay2M4himFNLJuF+brP3GrHaI9S60d30ZmN4BMm972kWkbEacNgxLip/mDD4aXAXnN723R1kYx54jO4UeYRdPtiGwbPXgnTjOrAIdetgksKNRG0m+KDXUwUEl/6Fd5AwKD0Kx7tNswjaZqHkXJMFvpz/0AHHtO5eap7JocwhVirn+pQ5a3moSRXedu39evHbcY4/jW0Ns7Ct0I3pIqVsUxQF35w1ePbHWp5kMcZoHSgef3V5iQ/byfo7Q72i7PSIp94s/c7cYhi2CNHAazbMbpDcVuvymgYglskHCHFSCEIYwpwySIL5Hte1G6G8E0HZFw/jbZ3lkGT71mKj69QE0GLY0uiGNFzTuoaFuv4P4K7l0znCBcEDEo/Ytm+KxajJYcYzP9KYa3Sv1X8j7HcSpw2DMazmu1uH7vMboIo4F1VWROM40filJgAzu4BFsnkYq3+bazU/QfDub9Qn72IpzT7VI3DVY9v2eNZ4NUJOIAShYEvWolQAJ3XCn2k7jXuGcr2339XpJBqlhxlV2wW6jvtJR/LZKKilayPJ1QyH69U7OZNDKYcVMg/ge2GCRb5tQDeQyRA7cIjxTrHa+dGgawe66UReU7AoPQj+jWviFH8aPQzTgYDqeBAlrhgAGSS4FIcnf9Ca4VmjX04fAbfx6OinLX6qU69gOWYbMsDN5zJc+v8NNKim6MBew7PG6eBR8CgLAl0LrwdsidbbYrF/U4hkaYIby9oIpm8Yhf6tGJTALj2HuaLtnmL8vff3e5ZBtDbIdrTgUstsYn1FonCu4UDML+wC7I1njUICFC6eKtG4dgZd5t+eJ+AQelHNEwMx7KwOfhZ/zFCzDIqcVa6gd4wUu5X/hYae3ysHA7nzZNjD7MX2B28FfJyh3IVaiGJPYvl+g8Q+hAWrriiJNUH5FZ6N4mUi6U2xcKfuWpwXaCjYyTPvcFPQuXWFJr73LvqYqWxW3D21GyHDoUYy61AEnsGY7kV0IFHHO44MTBFnCQVVY+tJAoZ95lqoDZ7BX247Riu+xuhJs8KjnaaHvHyyNzH37p33Y8UCqX/HQ0YlP7E6jGINl4p7VH4JV0419IyrtCaJ0dJh8zxCVYjRrn6O4VUwxKhU7HH4BaHlpTs9cwQxr/1HTPMnvqSVB/gzNqj8T7KxcoljhXbPqV8I+R3ml6y1/QyBsgeToIemh2K+8lGsUxN9jpOG4agn7natz+3GacNg50W7mzUvYEumgOqxvWX0MydX8Njmpkru+ua80M95TGNpNWb7wUBe0/S+LKIAXdJGABgvdDI4X3v5ts+uFSNDin1PMqAQelPuBA3D+AdunL7qUn559IkHbsKkXQ5F1rif6rJ0WthFJ0/AL82PomVwmNqhkrF16t5hiinEPhDyDfiAfTUhzDqwqneQrxzFjX+fL5Er+ltCBhze9UFHjUWsMdZ4c4dEqH6PF00B7DHVKvY4/EVSoWAQS5Sh5xRSFgsF9p41OwijCmwaHd25g5TxlX6nrf7gYgrG4FSzqMMGJT+REISEBpf2qN4KFhG0ZUTCRCq02BmH3rF3Sh+DM6buyysE5oAACqwdx3207PSA1DOP7PnNf069OLcD7vL+Mozp8ZDIV/7QQj5lhalnQ/7Ld8VyQlvluoYvEEIU4j+3CYsN7X1yfmXmYqUGjLdKH7hGBHNzDJinuArJ9N5MRaAVAi4y+RdcW8dIxZLfSCAl0gqXX3QgEHpLxACCEag0HnVbwDv8JJmDVbppmKVbqpNzlRI4W2wi7pQ86jOkkSM4CegtXE23hNewgkx0Wmh1DT+ZZ+M3VcUx0MRQD1aKHhcVKYapHtY2St7lztpDqLdhf95dA5/YyyXjBX693HEVMXr516i+8Ty/zlutmotzqLPVy1trdtBttRI0ZarYlnVx7sjxB+g5Dlaa4zklCpFAgalv7B6DPBBDGD0b72sB4XG7Dk0YC+iAXsRr3KroIMROhRiOPcXktgzWKWfhgq4BYDYVIPmEAO+0H6BV7jVqMNeRSU2TXG1P0O3ACdN6qRGvAlpMqTEr+mKQNK9CpykGlgTpdDG0hUsA6wWmqMicxvlGN+1BywNIp20XfSU62KU5XufQqohkzx4BtU2sR6+Fzo73UeWJgryw/ab7kAI8IfQsrSH4TPqXvqhtIcAhhA/UMO8D8jKykJ4eDgyMzMRFhbm/QtcOwDML/lK4vsBkZRe+8dfhTbIRgiGcuuwUOiMFuwpt5Lgr4llkUAJiwcIQEUfft8sKjNFA8JZ76gP8BFVoc0ofdkTa86KcajO3sTnwrOYI3THet0bqMyWjqi3QIAlcVPxUl0OiG+MBZuOYdj1aSVy7WeN70IDE0Zzf6CdJtVn1xEIYyl+C1BEAeFUqSz8VPE99H/ZN9321No/AYNSJT43KAHgz/HA/oXeP29oHJB90/vnDaCKw0JlNOIulvYw3OIeCUEkk4tMEoxwJg/nxVjowSOB9UyaJMCDwyFTVTTW+JfxpwQhvgshlzRnmSqoPnU3wOnRedZW/JLRF5GscoFaBglCBJOv+L47/CR0wDJTR6zSv+OV8wWQyEAoIpBd7PPM4Pug4/BPkFQp0tKS1JuotX8CIW9/4pLnhRpKmPQRWMc3KdoQW9/r1wjgHE+NyUw2HKMLR6K1cTZWC829OygFCgiHnsb30LvwXfQ2voPnCt9Da+NsXNVVCxiTAQDgvjEmgQfHmASA6uQC8GEssHos5gxoghCO7guSNVNDkE+V4fGE5uwpJNWrg4Xmzl0BvEBic2T2+R234b4gvaypnE4kqbsemp14/ptdmJLsOw+yGgIGpT/RezEQ5djBRVCoFlaDxpiBJwvWFG24pXzD/cu19vg6AbzHEVEqMAgXM5HEnsGX2s/RWnNM9fGumkg6w8AI6KQ5BCPh8I52CWZq54InHJZoenp8znxS1KkkW/ROu70AAUqauwpyOyVOkxdRo6wO2pqPU9+Ww8Zahi7D4wnV2et4N3YnBpX1vHo9gB03DqPS2cWIUdmpyZrzRFIbiWJysFjohHH8awAI0nNLN881EPJWSYmEvAHg9kng8m4gujoQnohPvlmIwfk/II69h1tiOGK9IaxcuzsQXRPYblXpGdsA+SILXfYlaAruFf8afspOoRYe4+gPxRyiL3Y7ODUo5YReFqNR0Qs5WjkIQhl4J9QFAOvLDkSNzq+gwuoXwOVc99p5A3iPS6ZoVNIo3Du6MKBQuQinNHOUA9BR/Ew6vgNkXAIO+q4Ag0Bq9VscToiJqMNe9cZwHkwqtQaajwDCE4EF3qmd+EnogLqvfI+GFSK8cj5rAjmUXqbEDEprCMHZG3dRZv0ExF38Q3G3PLYMgkXvVzk+bFwQY7FPrIk+VnpqPGEtHXYCmKnfB0j9tbRHcV/yN9MKXYhyVxd3kXNdBcJgt/iIW55smR1CHbTiTnhtTGqZZByONppUdOd2l/i171v0YcCLvysWcGaIekSwXlgU1+kBnFCecwJ4iZByQKP+wI7Pi32q54QPsPy/ox/eHMqvv/4aDRo0QFhYGMLCwtCyZUusXbvW8j4hBO+99x7i4+MRFBSE9u3b49gx2wem0WjE66+/jujoaISEhKB79+64etV2ZXTv3j0MGjQI4eHhCA8Px6BBg5CRkVESv2LxWDUG1edVc2pMAggYk14ggwRjJD8WDVkpP2yROVfothsdMvwdAV5qqajSmDwtBkT6rdkh1lVtTKqVWYo0SwhxDPHImARQKsYkAAzWrkcj9lypXNuX+FQiq2ILIKYush99w2ZzNjEAgHeMSSBgTJYUuWnAwR+LfZrDpio4IFTF1JUPcQ5lYmIiPv74Y+zfvx/79+9Hx44d0aNHD4vROGPGDMycORNfffUV9u3bh7i4ODzxxBPIzi6qiho3bhxWrlyJZcuWYfv27cjJyUG3bt1gMhVpuvXv3x+HDx/GunXrsG7dOhw+fBiDBg0q8d/XbfJKR6LiYSSCycNa/VRcEaORKlbGN8IzaG2cjcH8W0gjoaU9PK9A9OEler2KzC3XOz0ACCoNiFaseoPvYQhB12MvoSKb5tnBftxv3qef3ZkNwIexCN1tK0wfyrgv33RTjPDSoGzZY6rp0XGFevUi6w8U+cWXlZMXln2bObYCLkn8LuQdFRWFTz/9FC+//DLi4+Mxbtw4vPXWWwAkb2RsbCw++eQTvPLKK8jMzES5cuWwZMkSvPDCCwCA69evo0KFClizZg26dOmCEydO4JFHHsHu3bvRokULAMDu3bvRsmVLnDx5ErVqqeu5WqIh78xrwG+DgbaTgJ/6+PZaAWw4J8ahGnsT10kUXjC+g5HcH+jH/Vvawyo2myL7oGOf14FfBko5WE4oJCx0gTC/atTqxPkjB0zVkKR58LyEAZSR71cjYaH3wfc8kJNbsmSQYLxSOB6PdeqJMR1rPLwhb2tMJhOWLVuG3NxctGzZEhcuXMDNmzfRuXORir9er0e7du2wc6ckr3PgwAHwPG+zT3x8POrVq2fZZ9euXQgPD7cYkwDw6KOPIjw83LIPDaPRiKysLJsfnyO3X9z5JXB1H3D+X0DrJ5WFDxDWVcf2VGMlvc54Jh3bDONRFhklNCp1mBSWf3xIeZvXmZDkJPaUex4A0OzeX8C3bVwakwCgeQDFhQtU9Cn3lPvRmNxrkhbSAWPSfe63rk+5RGfzWr5ffWFMAgFjUpGQGGDsEaDPjyh+2VMREUweHtOcwJwNxzE1OcVr5/WEUjcoU1NTUaZMGej1erz66qtYuXIlHnnkEdy8KU3ssbGxNvvHxsZa3rt58yZ0Oh0iIyOd7hMTE+Nw3ZiYGMs+NKZPn27JuQwPD0eFChWK9XuqYtXrUvvFPV9Lr3fPBfhAb29vozEL6xSqMDK8JbvhLXJBb//G5d4AAFwLfgQAEBRWFtcH70GLUd/h+uA9yOn0qeprpOH+Cz25irMYAn3KLYgABvJT8bburdIeyn3J/WQwvV84AHsUWsMGKEGCooBe84CgKJA/x0GqpfceY7lknDYMxhuFX3v1vO7ClerVAdSqVQuHDx9GRkYGVqxYgcGDB2PLli2W9+3dt4QQly5d+31o+7s6z5QpUzBhwgTL66ysLN8blXnqcymMRAN9YJJ0m3+EhlgqdsRAzUZ09GEbMXfIJEEIV9nRIkxhP/lOTsg7DgA4iSpoUEWaSOKr1Aaq1AbE68CmDyzH7DHVQguNo4RSHJzk7gZH+2Vu74MkYO1rWACnDYNRGFQNKCzt0Tw8mAigKcH7NJ9o8a5uacldMIAy+enAz30AU6EXfZOOlG073Idnd02peyh1Oh2qV6+Opk2bYvr06WjYsCE+//xzxMVJwp32XsTbt29bvJZxcXEoLCzEvXv3nO5z65ZjcUBaWpqD99MavV5vqT6Xf3xO2zdc72NGrTGZTehC0pmio6dLlG8Hju4FexD43PQcpnE/+40xCQB68F4/5+oyzztuTF0OADhTqR8AIIk94/6J/dCYDOAZuvC40h7CQ0VJGpMAEMQU77myWmiOLCLNBYdFx4YbAdzE5NvV20L9QCAhyafXcEWpG5T2EEJgNBpRpUoVxMXFYcOGDZb3CgsLsWXLFjz22GMAgKSkJGi1Wpt9bty4gaNHj1r2admyJTIzM7F3717LPnv27EFmZqZlH78hIQkIch1udKeMKlRBqLsMxdPFyj1WBO+JYvsT+USLgZp/UJX1bV/zc6J7E7W3c/CWCJ3w9JPdHN/ovRgYewT3siSVBC5QeOPX3DW3VfNZ2WRQBFAuEA4NQOcZbq8lIiLLO10T3W8TGKBkGExWl/YQStegnDp1KrZt24aLFy8iNTUVb7/9Nv79918MGDAADMNg3Lhx+Oijj7By5UocPXoUQ4YMQXBwMPr37w8ACA8Px9ChQzFx4kT8888/OHToEAYOHIj69eujU6dOAIA6dergySefxPDhw7F7927s3r0bw4cPR7du3VRXeJcoJtc6Yt4I75X0atkfCGJ49OG2uN6xmFTzksF6WwyFSNz/oJqzJ/Hz3suSWsCCTkCWubtNTG2A1aJ8zlGvjA9xjbxzngBUyjKSvqzPwvmtXgf4+2PxmKEQaQngGzIIPUr1mdC7hEcSQC2a+IalPYTSNShv3bqFQYMGoVatWnj88cexZ88erFu3Dk888QQA4M0338S4ceMwcuRING3aFNeuXcP69esRGlqkCzhr1iz07NkTffr0QatWrRAcHIzVq1dDoykquFi6dCnq16+Pzp07o3PnzmjQoAGWLFlS4r+vKuKbuLc/U+ppsPcd90s/6WgmGyxDcJcEu9z3hllTLp2EYBz/Gvacvg4c+F5SCzjwPcAXSD8HvkcF/iJuiS40KZu+7PKa5OYR17+EC5Sq1gOUAAufBGLrgdf7v9cpogRaogYoIoISwZrB90Gy2A6pEfQe4gEkSu2Z9sR7pXThIvxOh9JfKTEdymsHFNtq+ZI0EoZyTAlII/kBt8UwxLAPx+/qCQXaCBj4DKf7kJAYMLm3S2ZAAQIE8Bhv6UKeEeMwhZ2E5XgD3q5SDlBMOAMwzXeNJO47HcoAZhKSkA7fFgBdEstZ/i+3GMwhBlwWo232e1BryP3ZmDwsVi3tIUDrwpgEEDAmAwTwM+wjL7nlpGiXt2SOarA3sRwT4cqYLBD9t4uRryk1jdJg/4gyBAxKP6SMxremXDiTg0tiNM6LseYWg7NwklRERda2gvfhfSyUHo3MvcTTRC8vKjq+A3ScpmrXwOce4H7HH8vN7oplfHr+ULmPd91nAQAhJA8L49/z6TVpGNgH1RXhmtLQKP077Hlg4MqSvzCFgEHph2h7funT80cw+ajE3kFV9hb+0k/Bu5of8JRmv0+vGcA9ynnLi9r8Fenf1OUW2SA80ss75w4QgII/dJLxx5pDDSPimhjpekcKF03lXO8kcywZMEQAERXx8vX3PLpecQlUg/se+XtWL3+/VHDpBwQqOvyNzGu4vOYzrOG74TXtny53FwgDrhit8qKZbDzBHfL4+NKDhX/6IYrPGTEeNdjrTvcpBAcdnMgNtXgVePQ1ILIy0HKkVJADAFoDEFkZv30konfhH94bNIVFpqfQg9mKKDbQ7elhwh86yfjBEByIYPIQweR5dGx5Nh1LhQ4YwG1Wd0BBBlDGDSNUBe7kYpoCcQ6fwzLAPRKCvMenl/ZQLAQ8lP6C3Mf7wPeolH8Mvc3yNr8JrZ0eVhxj8v7mwTQmAbg0JgEoGpMnxUTpP+e3SMYkIP0bU1v6MW/rHnKi+AN1wUuatSjDFPj8OgF8Ry4TYvP6mKlSKY3kwSef0P07RsJit1hHvTEpc9i7XXLcmWlmC8969doB6EQyubhyYI3kMPCD+uqAQekvrB4j9fHeOgOA5DkEAB6cX4SQAtwfVGeu43S3ZKD390730/dbAgxMBiI8NxA+KOyLZEFqDqCU86ljTDCq6JlOg/iln+lBwvXfN4TYepfrai4pdt8K4DnDjRMgQEt9T8+IaMH6fgHoCiXt4v2m6javv+O7IFlsh0/5Ph5dJzDfuUfHtCXAh7HA6rGlPZSAQek3JA2hbi7LZPtFCCmAdykIrQRwrvUl3YVjRNze9TMQVQXIvGorbG5NuVpA5dZANStNufovAACyYVB1rWm6ZXiW2ymdzknOp6c955mHQJokj9CNiJLBs7+vUvetAJ6RR7TYQhpiMj9UcR+Dh9+hf0K7A0Ge5W1as1JQ7ipXn71g87qN5igAgu4a6dlAy6c0OWnYwFi9n05pEUzDGJKgar8HmqTBpT2CgA6lWkpEh3Lrp8CmDywvZ/B9sF2sh1X6//jmegEebMrVAdJOAI+OBDq9B2h0knH522DJM3l0ueMxj/RC4an10Jn8J++x4P/bO+/wKKr1j39nS3aTkN4bEDqSEEgoIj0U6SJIF8GCotQrKqIXQa8/C17LvQo2FLFiAREuiIJ0AUF6LxI6ISGmkZDN7s75/THbZndmd7bvJufzPHk2O3Nm5uzZ2Zl33vO+31edBHWN8xpresggdyM0opyEIcrFmLe6gI4ACvow63HE4t6/1vVCIYnDk8qVfuiVY47oG6Ot/IKktl/remONvgueV36NlswVhDA6XGTj0cigJFJJVD57MLlFVGhQ1x+Cus4C+r3ktd1THcpgxJCF+1vkcADAPfJdGCd3Mm6GQjFSbJgm27OEC6f4aTqw612ueg4r4vHQa0SNyb/ZcMHl3sYVYxIAyuFef4kqCmBcu0SWEueOvUnX3qXjeBNCbw9eQczz3kt2yKPG5J+6ph7bFwDJxiQA/KDvgZlpZ5Etu4Bd+lYoI6EmYxLwnZdbDwaP1D6Fb3S9fHI8v3HwKy4Hw8/+QXrFCCRGLQdmHcaGyNE4yaZDCR06yE75u1eUusKhL4E/3uf+PyGgW5bUBujxlOjmwZStfZ5Nwiuxr0DnwvX1FgnBYM1LOB2aCxDXPJwxTBV26VrindrhWKfLs9v2Td0YZBoSsWpEEjOcoZiNcNxIAsfZxh7ZD8VMJUJEE1ZSZWUOt7/Kxkk+VgfFXyhQNpfc3kipXPwYH4Q4nlY9zDbGKtWLuOvm9wCAXopjgqUcfYEcBF3kx9An7Lxfju8zqm9yTgM/x1FSgzKQSGgJNEhGr4o1aC27giayQjSXXcchfaa/e2bCo88/shBP7i1g8VhtV7X7sVB2Kb8CJGUBvaUJoAcqF9hExDGV+PffM1yasm3A1GKd6gV0Ll/nVj+0TAhmh6zGYMV+u+0mN/gDcsMvS83YkYKSSIKsEuf0ydI3CBEW3N7f+mmzjinFI0SgFnOUq1zeXufkLVuhKXX6GDH6EtF10dUXUG2VlKWziodsylx3+pjeZJbiJyTWXvJ3N3yDn+MoaQylRHwSQ7lmBnDgc5c3v02UCGW0HuyQLYQAjKfiqmRKgPVuf+sEKe2B63a0QkNjgdt/29+HOprTppMAUUeDqSnDUX0jZMsvSu5mIOCpusXu8pWuF5TQY7Rih/2GynBA60fPrzwEiEwHSoU9OEQVBUZT7uNOeReCwNSpFOMMm4oWsmsoJeHYw7auc0UotISBst7K33mQ/Pl2Z5jcgcZQBiMimd5SKROJ23Jl2k8MjxmTADUmDdTAgQxLtUjd7DuGc6/2jEmZYQo1NBYIlyZ0/E38dHTTvI0Qg7fsAutZgWSXUTiWq/GUMXmNjXJr+wmKrY6NScC/xiQAhMcD476BBsKzBRW6ulf7IhiMyaKQhrjAJgIAWhjCIWKYqjpnTAKoF8aks/dgrTJCunxSekfu9ahAkqWPoQZlIJHSHkhu6/rmIjE4pXAuporqgPkWNRwEqJdftVnEKhqAyOxIzrQcAqTmAqyOex3xEaC0kilSCk91jr/yMp6Qr8FfhJPiaCwrtt8/X6FzL5C/gkiTIAGAVFnd8soJEtKAqwGc2ArnVXcINilUpPq4U3UfKZfXxNpLaCwTfpA840Q4w2m9Z+V0zusTee936lp7dP91FWdDb5RaJ+QCNbeAWYcdag/7AmpQBhKLOwKFRzy+2wSDSLpUPtIN9HgfKBKxZyRaor0F5tj34utP/w+4doD7/9oB4JO+QJnV9LX2lujmsSjHJ4F4HsiEPWZHHCSQVGVNQNX9P6M2IsMLnXIPvY9jif+MG8b9E55oqgGckhQv2DYpMQmIcz6xgyKAwZNUDuEHOam0kBdKbttYxikkLNf1c+uYRtItMrUBIElWjlpaZtFv3MiZxhmSxmpofoYalIFE9yf93QMAwFTlz/7uglvYE811FuO0EwGAzN7mFepojx2Dh4QwgL36FvhC31e8QbiwceAMoYwWK1Uvur0fT0NY4aSVtrILgstrZFwYSNXZ3xGb0RLKxl281TWXkbO1HtnPdb20afoOJWuA6MbAuG9My5690V+w7bFrFUDJWZf7VBAeeHJIfuPmWWDWYZSPWQNNouszUc6gYnS4wsZhkmKjpPaOpmZDGL7qQXPZNShhkCBjHBuWtQjBzLBF+E7XQ1J/6ju37RQ+WKnrirITm3GLCQPLBkYpYmpQBhLtJoDN7OnvXgQ9cg/G5BinnRgAKLDQBK0pg14ufQrVE1QYsitzZOewQPcQbipFpiOrbgINUvjLUu1L1/COgwhUEmnVcnyNvUeFNbo7ee936Frjqq4BbhMl1DWFUL2WAubod3b3fz2kiQd66TnKnChzGC27hRpWoreo1zM8j8YoImxwhIgFTYtkhluTWWUnmSzIqQlPBwDppUWHvAXENEaj1GSoSnwnB/cXm+K4kQFXVBFuQc1V3CJ6oGk/QBUt2jYEtXix6RkMir7i/IHqIfaSbAfL96Cl9iRW/OcZDHrrN79rUALUoAwoCCHQFfzu1WPc8lIdXmvpiPqAXO9bbbVIgxjwbagRjmrEagVKKhqpNkxNJWVxrzeOAmEOPJeG6fZIVGKIYp9LfXS1breznGX5xvQq+QD0k3PyPIdYTmYrT34GTWU3EMpoEcnUCO7nD31zLNeZvb0ptYGlVxfthAB0KKOHWiahRF/j7kDbcbxFvfTC1508/WHhzNHwBLuGQ31AXcUZRZJKi7YeBrQZwcUB//5fQF8rPbzFTXoqjnl1/xGoAf76jXvz10ZAU2a3fczRpWhwS9rvTMxG0jH1Q3LOHsZynI8ofsaGW/f5XYMSoAZlQPHsqqOYWjsLz9Y+5LVjeKsElVApMYpj9C7knEYz1TiufgQ1yhjOOBCicTdg8jrg8d+511HLAZVB7uGOe4W3YbVAAyf0CwUgYFDOSvRuGvsjchmylxwWAu7JvYpwN5aB+s2mp/l2htrCYRJu9J3lZzFJsUlaf+sKF3YAizvxFhUq0gWbstAD2/8tsELPeaQkogkX3n+94eZZYM1MTnx67wfcMldVLrwVbuMC3nSKsXYk6n5M8b/x5A3YZv2h6fiEaxtX3XTcxstQgzKA+PuWBpvZPOQYboi+pK5ldpew7gW++wo2xPWqJmsTHoNWKVLiTxnGGZUA99pqEBczN+swMPozIOs+4e1uSQ/4t2Yb8qBmdIiSCXsDeYz+gjN0c8YCYM3SFxaIZTkWsxE4QRoBAMIZLv4wFJ6JQ6w3dP8H723V3QJGI4CbOSI3t97PAkP/K/lwqqp6PsXZ42ng5E+SmxsVCQQj4yTqydqTI9us80wMp07sgbiNyEOrE4j9/jVEjlHX3nB7/4FI7bmtuPKHQBUzKfSY49nOuAA1KAMEQgge7dEEyShBO9k5Sdtoiee+vhoRHbpgJU4mnsEcSChrK1zaboe+Df57IxePHGsj3EDo4pLYissGBIBz0oL0hRB79ugJ+xVheGx8AfiwO3B4Bff+CjfFXsU4fhCIYSoDRo8vKJ/DmvQG2k3gLWqR29PmsxAAKcNfApr0Et4+ewSQPUb0MDoPXp8CHa2jkJ8NzwI10qWoIg2lCk0jmDXS6T6poQGxqkVv9Cj2lB912rtYfMeD+L/asTjFpmG4ZiH+oZmKx7RPQqu2KtUYlgAUnXS6v1KRFGIQjMiUUKMWEUw1Rmv+iTe0oyRvqlFEAmnS4+S9Rf35xQc481YewYQPd2CcYjNayy7jhN7xFJHc8Px6M9wo6+H61xlm8PQEQFwvRQLd5cexQz8Gy1Vv2qwjgOOLy+B3XDpuJVHiGut+CciamBaCy//u4Pgp25XEAU9wmjX/JmvAyRd5pCvpnXxjmBp1SC8Kx0uWIBoA8EfCfbz3uLiLezXG4178nbtQ6DTm2DkrykkoFAyL02zd1rFcpbsLgPnKKxqjXiWsKWkvi5fHsZXAHfeC7fioU/1jQmMBAOWE++6NU8hyhkgvUmEITUko2oUOKSFoJbuK3vIjWEe6IDJ7MOSh3PplursBAKyqAcioz4AxXznV13qPIQQikSnHd6qX8ZTCjiycFbcQ5riRD6ClFyXi7dKLJV8/hrgzKyS3P6lPR2v5FXyv647D7Rbi5bwa4OvR/q+8QfE4m3Q56Ks4bLP8aHhXZFfZGge3mTCELpBQT3f9XHM8F8XnXGVjkSb7G5CHoOjOfyJu3xuQ1zqnGesUUzYD2ttATQUXAmHFxZP7oVSHIzWzFa4VnIK2pgqNWucBp9YD6kgudOLCTm77Mz+7VSa2LqAhcqzS98A4xRbHja3YomuL3oojKGCTMF83GWqGxUOydbhLfkJ8o1aDUXlqCyJQLe0gqihg4irgh4dsNWil0rArl52+7XXguG0N8h/QBx9o7kYNQnCFJCKdKYIatejQoQtm9W2Oiv90RUv2L9eOTUEZUeESSUZbmf3v72ar+xF/31tcKVWPlrPjoKUXg4y4ntKePK+w3BNnazkXkzRKsQMvH+sDHPkWGPK21/pXb2H8/xPJkRfgS10+b9nNTnMxVT8HpSw/hrKMDcUjylel7bhgK/dq9DxRfMoPbC98nPkWMGo5Em+fc82YzLpP2jnKyDivtTGeVoBGrfOQmslJCaVmtuKMSYBrbx2P62aZ2GCniqgwT/sQvtHnO25sxYfaQXhQ9yy6ad7BFO0cDJbtxVLlG/aNSQDoPgfVcU78VjXlwNI+3EOEq3SbyYXK3DVdcPWRuEE4R9JwhXB6vVdIIs6RdOhLL0P3UV+E60pdP7ab/Kjr6vVjeNsdF81oHBqTABB/6ksu4cvPmd7+v1tSONLy8JZutMNmOojU1q2+Cfzo3HSIq+jrU2UE4n/B2ASmAmPkW7k3nbjvOL5gDWb3aY5ohvNIG6fOopjbGN5P4k1u1HKg+QDghndlRSjCzFKswpSCJ4EzG1w30I79IC2QM0K6FqEk0vKAlHae3WcQEc5oMEXxM/5PuRSFbLRT245RbAVgNr4kGaWKUCApC99GuqAA0ncBatSJgqscxuFf3A3U3ubKAqfk2Kx+qWQOXlEstVhCEAItWl34HBlVx1AL30gjAcD3Ok7xQkMUmK55AnN1j+BnXQevHtMLzkD3yJvk18OLWCcUfzBSuRsgQDVRIkxE0FSovqumx/NQNs+H7PR6b3cRACBHHQ2KDmCUxgoVtdXAzEOAToP9O8pwTTscJSQSn5MBeIDZgDimAoWXyzCqY0P7OyQEkKuAs796pb/bdFle17+rM+RN4gy0/H8Cm192fvv850HO/grm8h/ibdK8cGN1o4JOXaC1jJ+5fpjNlKTQ8bz2YSSjBB+FcPHPU2qfcryt7jbwciLugZMPBmHxwOU/oK4RjuFUMiy0RGa+vljz+zvcX2wz4G/hZNEVenMFsVcVH2OcwWAGgCaG0o/e5oPagXiLHQsCBqMV2zFduQbvyZZI30HnqcD1w8Cl3d7rpLfJn+/3xBzqoQwgikMbA4CoMSnGha3L0eebctR0fdoLvfIPNLBXhENfAjvfBhJbYVynhnibHY3PyQAAwOdkAN5mR2OsFGPyp+nAu+0gIkxil5W6rtjQYLjdNj0Vx4JGusmvtB5mvgkc/cH57Zv0Bno8Bd1lLsNedAqumxemwoa+5/l9BjFSjMmt4YOwkc3F/YqNaCu7gLayC5io2IhoSFOlaAQJsdGW1JQDuZPtNtnLtgQA/KlrJt4oIkl01Vi5OYY0lvFiDLAd+ikO4ox6EkYrtgMAWsmclKn6awtgeiALRLNIvE9lLJeQQ45KT+LxFoE4cvWW93VDnGpfQUIxWjMf07QzMOv2Yqh/rzvaXIE2kxBQ5D4AAMjJiMbwdvws2nvbpyInI9r+9mtncoapGHLhTFWjVmkf+QEMuLXaYTeDRbrJr9y08PKNWg40s1Oj3QKTbqwhY/uMmpuOFJqC+yV5ilc8F6TNcJDQOMcNGToRZqRX1XqcUT+I6Yo1pmXTFT+hkawYJ/UZnj8gqwUOLOe83yJ0lXMSPx0UInJ1+fOB/v8S3X6FxZT9Yt1wl7rpLk1lLurnpncEmuQDN09bhDf5P8zJkhJEmhUaBGjA3Ea+5t94O+o5H/ZKGGpQBhAD+g3CYUPZOClEMrfxnepfeES+HnuiBnuxZ5SAwiK79sS1CiSjBDviXkES/sbxaxJ0LXNF4mzUUdwrYQVvQEah4RAa8uAWxjKlWiiAUZ+ZVyS05ASwJaCHDB82eZczQgGkJYhLOfWo2epqV+2y792JYG6XiDdIvIN7JTqH+6IzEkCYoTxoOcQ9+zdb3e/8jnMfADnC9145VSL16PfcA4nAw8Ou2BE4QpqY3h8hTVHMel4FxWtc2Qec3+zvXtglpEl3IC1XdL2CIdisegodbkhXifEW1KAMIPZfLJU89WHJWMU2PFq6yAs9skNoDJDtOImI4gWMBiEhWDK2DX7pcR4ZVcfwa4/zWDKmjePUwwPLhZdrbwMTV3NGypHvRDcvVTuYUq+jaN0MOS8nXEnKSoRhvGYeLvf5gMugNbJ2JvDp3Q73U8hGYrb2CdzZc4gpYzs6TLwwQfWtSq+ko/6qtt9XvV4HdvpBoMtMh/sK9BkJX1QSi2YqcZJNw58d38ayFouxyjpLufNUxJc4KeifPx84sBzMzdO8xSpGj426drbHECKemxKH3rYa1V1/r7JKygFugavyY9SltIdxXL2aLW307kU38tohdI6E7YW2UYhUObMios8coO9Ch+2Sej3mdB88DTUoA4ina5egkazYZrmOcZwpF8FIKHfnSfQ6oPCIb4/pAeqEJ8RoEK6diWYfNUXUXk4uKmrvW2j2UVPH0hHtRTyU+lrgi+HApheAm2dEN0/TnIPWzUuHLgi/CCUce9rsEWX4jcYwVfha9SqalO7gN5CY6Z0sq8DikPeQs6a/pPZxukKvyIn0qLSfBCgvOYP1H84F7v6X3SnXYMAXBm8UU4PWsqvI3vsUPj1SizayCwAsDLPz20BGfYZnQhei1uBhvMgmAACIdQ8j07jXoz+Izki8qx+BNhIkaUhXw7kjUmrzelN+taSP015GN807eFE3CVv0tpnhRk7rUyFjgBNshnezpbUG3U47WpyuGISWKBjuglbrxH4UbC2Wh03EqtrOosevVcdxsm77P7O7r0Xa0fi0wP2CE+5CDcoAIg7CpblkxHGSzndRLshJuMPQd4ARH+NwZC/fHtdNvHHdcmr6yBMYYihFp66N68VY7eBJ9rbjEnFyF+4AR1izh0DBAMe9ETMWRJCccXzXTEp7oMdT0ndgWY/b0XZekBNZXtvLYRt1x8ncP4f9Px3nKteQ6BmDR855kR1F6CUy5dih/geK2QhUkRCs1HXHvPQvgFGf4dkdWnxX2gLztA/hHJuMcoTjMc0ssMZbeZwhsaaqGJh1mAup+HOZ4HHGyzdimnYGumnewn+0wwXbLNKOxrw/DA6N7BG2Dwb58/FLKRfHPfmuxgCAP6uT0OeOVKwMWYDlOvGHnpbyawCAO2SXHYyI9zEahA5RR9tdHSJ1PwDQYiCWVndDN+UJ0eOH1JRw+pK3hLP0jbJP98h/x85zN6Uf20tQgzKQELlqnVW0xEe6gaKbFZNIHIob7PnYFZlhii8sgb88fz5QsA34sDtyKrZ69phBiM9ryxpjKMWmrh1VMAkX1qQzkdDc7uojbGPIiPOf2Vqgt43c/zcSUTw8PSak98csG8D3HC7uCGz/t6T9VaX34NfjTsvjtAqFaDkYSBWPwXKVAf0G4VMH05oRJ77mSjQ27mFYEniT245MgFQI38wlk9kLaDmImwHIHg0iF/merOimOIVwphbfqF6GjK0FG9sMReW3EYJaZMpuoJmsEG1lF3Cn/CQ+THgemLQOmLEfmLyOC1uJacyFVBRsE9z/WMUOPCTfgM+Ub2CWcrVgm+Hy31FSaTH7ZVQi6PSY6f3iCbnY8UxvLBzWBjue7oUlY9qg6aUfkCc7iwnpxXhLO0LS5/UJ+fOBMAmJZELIQsxx5p7g1BrswGNIlJIZf3aD4GKj3JMaGszOt5Ol7yNo6UWJeLv0IgDg6n7gY1uR29dS3sHUa88hmhEuuVWsSMG1B3YjcmknZAroVLpEfEsu8y01F6j+Gyi7wBmYrI67cY1ezpV6FKGWADqiRJjMOQkkd6kkKkQwGq/sm5AAEbKdspkzIK7sB5YKiCI/shlIt5PVK3KeAQDCE4C0jsAZz2malrNqRMnEQzIcrfcL8hDBmDGPY/wuAeDQV8DqJwSb6QkDOUPAykIgY2u5/s23Co95JQ2oFYnBzp0EDBOesnSVZ1cewYOHx6GlHYmW7bKO6MHuc2n/GiL3/cNaAHMRqdila8HTeeQh9h3bOa+Gaf6FZswVvBXyoehxt0cMQo8533Bvik4BSjVnrJZeALQ1vDhg8tMMMAc9U5LzONsQbWSXPLIvE6ooQFOBOhL8xGNv7FB0mmlHvcMNaOnFYCQtzzQtYsmz12ejhogH3SforiPn4Asoj2wl2sZpjEHc1w4YjMkQzphskMyJ7F75Ez9FC0+tnmZT8A/tNKid1NP0BN4yJgGzMXnVUP7SL3R+3GyAHPhMuI2Y59JIWh5Ef/ohDSQ5kc41dJyQVWzQoaxGCM4oWws3atwdclkgWOlW6GsBpXd1NK8qMvhyPu0mAE168dr8qW9mKNH3JJanvgDZ1B1mD5Q1Q98VP5gXprzHdczAbO0TuMjGC66/oE9AbZcnXd4/VRPg0wjXEAM73qwqkSnPdhOgYdQ2ixdpR+MIaYpVbE9ct1PtZ0eERanOxFacMQmYPaAWvFfuuXKHHjcmAUN/g8yYVEnzikZ3m+LljjiGGpSBRpjwxfm/zHj7290uwVJyjxc6ZIA1eGtuGfS+ti/CPWXck6h1QHFL2XUsDlmMQLQTPEGa7G9cdbLcmsc4v9X8v1gShxTjQWF7gwEAJGVLiuNLvfKzwzbhDHfOpMgq0EJ7UrjRhR1oAOFaw84k7oiVkKtkRT6npJ16V0czWXeFi1dlLaLqLu7iXpXctGi27AL6dumEzWwevqrqwN0QxepxZ48A2txnu7zH01x8pofJOfQCflY9h0YyYUMmTlaO38pTgbwHXdp/QMwGBBgMWBzRi0jL9ZgDALhefhsjlvyOwnKz118ooWy4/HcABMkoQTJTJrjLErYBroQ0kZyGnVO0WlI7b1ET7iAuO7apbzriSTTl4tdrAzujhqJFbk8fdUgcalAGEoQA41ZwN3VLej6L8yF3QG/vN919DmY9MAZFadIyPwEAMpHscRGjVgzJAc1+hPWwuHKarMyj+wPj4KeoCAWm/g7c96lFJ/KAzlYJNp2nOhaxJsSOrple1FNuSVHPV4GHfgUiUkXbhDHSp4y/1PWxWaZwwqAQKx2nN4zrSTYdQGD5JuQgwOsNgcWduAWEACOXAq3uAbS3UdFkMCoGfYCFQ+/Ajmd6Y/F4CXGQp36yXbb9DfMxPImDrPQIphYLLj8EcnyV549t4Bbrf9F0X55TdysOoq3ctiJPhSwaJKU9NDo9Ptp+HgculeHj7eeh0elBCIEss7vNNi1kV/Ga4kPMjNgmarzHyW7h/QuDJKsEbIvwrx6yuspBXPbhr33TEU8Taj+Du0v5/3zUEftQgzKQWDMD+KgHcOMof/m217BCOx1ysRusQg2k5aF5YgMkltip52tNeILw8hpDlm9Slt3NT2eMkn4sPyOTIK7sCY6GiMtk2CU8Gci2M56628AHXYHvrMIMzhsC7o1B8ueFA/B5rJ0JXNwpvK475+Ww91BRrEhG466jgXObgMprjo8ngV6yQx7ZjzXGuGNj3eWAdHoZs7XXzOS+X4NRGHl+HRJ+fgRYOwsZsWFonhTheF89nrV/DE+S0h43c+1rTKp7z8G/2Ic9f2wDDWSu/a6riHA1KEEi0wUXH9Y3xg+67mAAEC8kPVmjUYjHrkWyZdj77gNo+c8NWPb7BQDAJ78XoOU/N2DeqqNAn/mC241VbMd4rYSSn2KKElZsKE11mKgFAFo3ZXrqFeoYoNJ+yc2KO1wQvPcC1KAMJMRiYBwRZojpWzvTbAw6os+LwMQfbcXJs0cDoz/n4rQe/x0Y8rboLpIueS5xwzd4/yKWXXvY+Y2U4cCta1xFCkdYGwajlnPyIIMWmWVCHCHmWVJHm72bE38UNXDDdGWclMV2z4npJ8sq8JtKWtnBukRFandTtjYR+f2LLRek51M2cZho0pufEe4pFndE/AHxRJ8/5e2AdhMwW7nS88d2k3BGg6M6YUPRBpHZgxz5Bdyn4LREmWsHuIUxxuloz0uJVSAcb2jFHzo3hgobciW3NEBaHm52eoa3vKz1ROkHdxSXbWB2fjN0kx1z2E4ZBLNaUrlt5SU/pReftXGJmlL76yPTEDPKTvy0D6EGZSDhStBQ9mjg/h+5/8UMBWNt5g6PmJdV3eCkUYwXQiPXDgItBnBxWgDY3MnQRwvH7BzXB1vFlAC8iGX2Boa9J7FtTyDHKpbWQZC8IGl5wkLTlvViE1sBhUdt2wAIh+czshXQoo9mk8f3GyjcVicJLo+8YZ5ReOKycOb9tMu9nTuYMQ7TOMNgqPftcbqLJNw04D5rLjkBQgj+qhavQ+xPshW22ekX9PH4uOEb3MPZrMNcbfVy2+SQ83oR6a2RS4Fp+4A2wyT1wRlB7QTddcxUrBTcTtP9ORSEtBTcjhACEIL4An44RHTBGsH2gkhM6mq0ax5ayK5K328dINTKS95K7plZG8lUXPVK4QJXoAZlsHPtIBDfgvs/NRfoJTDlFZkK3HEv8KdFiaw9S4BXkoGSc/y2JWd58VZ939qOK38LJyd0VZxEMSthGo4iTkgYkHWv8PdmTcE2blrUExj15NqMNC9rkATUVJiTRAYugqhX13jOUSShVnNJNjt1ZoN/r6wdZ4AYEh7y8+9GMeFPaxaTSPTu7XgKkceo5eYZBrGMcE8gkJWOlHbAU2eAyesgG70c81YdRZHOewalpx8RG8tvot+ld7j48pWPAJ0eFWynYFjs0lspFzTuzomIL+4IHP9RcDtrQ9DZ+PNqJlx4u+2LsPWMsCf7ZGElN3tVzC+/KHk2K6GV47hsAy0j3ZPaYgMzKMVtamA/Jt2IyyU+c8Z6uX6lNKhBGUg4UyXDiKUBuGYmsPU12zbJbQG9E3I6FtOqj/dsguOksWjTBJkEUVaKOD3mcBd7oe9NiNslnjnuqOVAdGPguMV05PWDwGsZwHsdAZ0Glae3QPSW7QuNRuOh/H+ddItiEom3E15CZZMh6KY4ZVreiT3ExUwaHhL+vFSGW4RfB/kWCcXeC6VwSi641SDTDINoRrinsPaGFp3gHXdcp4ZYrBvutcN7w/z4OXIkV+ruyj7O85NgK3nVUHYTd8mtlAsu7AAOCesA/qZrBwAoJa5LUZWxYaKyQf/V3oOROcmC62b3aS4eA9nmXscH1kmfkYgKdVwm2B7fRz8C5L/g1j7cw/Mm0YfaQSiGfam50yxXKlNUGcVRUumygQHhpaQGZSCRlieeeQ2ISwcYDcAq2zrgAAC9HT1I66oBVvFW+y6WQk4cFQur+xDGC+UVQ2O471xiDWcA5qQZd0loKTplSSKSgJcTEfGHSPxsWDynRtD3Jc/0xQGiyWhBQhVR4aQmCREKkQSSau4h4e9bGkzRzjHVQeb0J+fg+/1X8NyPwuEHfseBNzQnIxonmSYoE5NvUkW7WSHd8zxe8V9zfHDldaBYRPJKjLb82tZfansjWlaFX/W5bj2Ah9nR2H06ZCV6nH1VcN2By2XAfhEv9V9b7B7zsjITGPet1C665hQxcEjfCH3jSoDNrl1X9B5J9PHcvc74UNhLfhjH7voPtiiENTqnaabhaa0DDckIQ4jFHXYeACQmTnkTalAGGnIRgzIyQ/hJ0dIAFIvBlDHiP/SaCu5VJN5q59liLNYPt9/negDjQqlBh+gNt1KxmEZrwhIkTz05ZO1M7s+aiBS8p3BwYaq+Cez8D3DGsRals9T4ui66D2gsK8Y7l0cAZ4TLpxmZnt8c50g6rhDu5nGFJOIc4RJHxnQI0LrnEryh/yf/GNFilZC0t+B/4R8P0msecPZXAMDtKK4U3iDFPuTJzuJvIp6l7YhawmCqdhaOtpgh2uY7VjjWdmzHhtxvVojktjiVKf57Z7TV0uKyjaTlQa+Klt7egmzZJcT9JS4xRULtl0yUG8IASoj/w7A0RG56KPyLpGHgrjHorROOZV6sWowvVXYSHBkZlycx6zAw+jNxLU2JiVPehBqUgcawxcLLK0T0tSzrtIoZjd3ncIaItZZVaAw/o1vAw5ARG44jpCmKBX6knnkirNvoZOKCtOyQd8xvDn/HvTYQnrYCAKg8eKEU84pW3cQRtgne0DqohHPkG+DSbs/1x4C6jpbau0zs1E83CFLnZERDpRC+JH/7ZwDXPXdAk3A74TZsoPkn3WTrq8BtLis3tJyLT49luBj0sWIlEy0oDkkHm9zOZnkIQ9BXdhCJF9YCAG6y/KnzRdrR0CS1x/B2/Azje9unIicjWvze0G8hPmvwCPbrbY2Uj7UD8EHKy6jR6pwKuZCHGe4znR6z39CKL/Ui5WCT2uJAZF8wt0skFTuIk1Ib24tcZ6PxnPYhrAxZAC1R4APdEIfbhMrseEYVai5m3Zh8Kfab8UI1LGehBmUgwbJA875czWyp9HvR/H9aHif9Yok6xuzVMq4z/tDVMQ49DM8Nag2AhRq2MXPyIJd+cKYSi6vMqpmC+2vn4htdL97yt7T3od+vFk/cxhhXYyUiIxFp3NPp/T8C477xXMdSc4Gec/nL4lsC932CJ3o1wTA5Fxt3hbXvFaBI40qXl4UTr0JjeF7nmDDhGYqxHYNNUcFMZP959hskuajdWgfZX52Iy9eEs6RX6POhSuXiOeNl/ETJRxX/w3ODWuPENW7GafJdjQEAxw3vkZZnqzsczs14PNBGiVzZXzbHm6LcgDsuf41W839xLuRi3ArOmzbwdbykfsZxewBVJAShYsEPN44gt4JTgLBX7GCLLlt8pQ9JkZVhsuJX5MnOYrxiMx5R2w8rAAAlWwPEiSQ6aqv5hQnGf2er9iGloIUPqFOzDUHP4o62Wdf2yJ8P3GU1bRkaC9SUcUbj3g/5XslxKwClmnvS6fIEoHUcbJ2TEY1NIU97tEY2CzlkAVCn15lKLK5wrOVMrDvcGYsUH2G0gi84/qTyBwyPIQAM01S95gKrn7DdSZ/ngWYiT+7usHYmcOBz/rKbp4HvHsBVeT+8o52BGFRiSYiIzmBKey6Jx4MQUnfL7bU9MA/QCNQm1vNvol883BlvbzqD9UfNDxYPdm3MeZmClBa5PXHzp0jEMxU269ie8yDbJhz7Vx8ZoDiAi2w8PtINwqMKs87vIu1oFDVojej8TsCntqEm/9Q+jPcyorF4Qi7USjkyYsPwcLdM1GgtrrMhDbg4e+O9QdkA0Glwx5UfRLObYsF9Z0490BinyH+ajhdqvpC0SThTa3ONdJbeisCJM86WXQQAzFKski5FUHJGfF232eb/E1uZ5f6M36WUghY+gHooA4luTlazOLyCXwcY4LxYlkLXll4tVzQLASzRSdNUk4o/jEl/yBtlFa/HO6Gfil4o1yktymTmjAcye/AbCOlOegKWBbIEaj4baB+nw6Py9fhe9TISBIwAyEOcMyadLOXpLC5LbfiQ251EMjCH/cf0LyEEDePCcO7sGawMWYDuSdyswO9nXSx4EEAYs9etkW17FYhq5OPeBDbv6Yajp4wrkGBM7LhHvgtP1S4BPrWVkDqkz8SBCO7BtHlSBDJiOZkmm+pKRs+h8d6Q0pYrULDz36J9WaIfjjapkWibHuX8B6l2QZEiraPz29QDyOW9/AWjlgNjvuJUBcZ+La2ghQ+gBmUgcdmJsomAjWYkAJeNRnv8EdYHu/XCornBQrw/4mrS8hCpE76ontcn4ZurFobWmhlAwXZ+I0/qTlqyuCPwufhDQlpMqH1vgYPgeBvEEgKscMY7+brmPqzS3QUgIOXqeWyLGYlG+Q9zCRsWVN75DNBmhOn9syuPIPufazFY9wvyZGfRoWQNQqBF04RwX3fZ4/ze4V28oBWJ8brvE9yCE6UQ6zhvhCzFWTYN92oWoq3sPIZrFmKadibWKvoLts+KYbH8IQm12q3vDd3sy8xUEjWOkKY4fq0C81Ydce5DAEB38YzvSqLCdzr+A/Q77FigVvp1uppI03a0xB8lH39NfMhGX9ZINStNZmlxuUWGOMty2tK73wNqq7jXyFRb55IfoAZlIGGvJJ4Ylq5wL7FBNxld5KcdNwxg/DKVevRb5MsPCa6KlVUiM0ZpFqMVe5r3lO6kJWIVTow4stBuXeemvP3IXNUPGKHg4jwDVVao1pCx3qh8n0FrlD+1G7FnEfRrZpoSHgZfeBVn1JMwS8GJYs9SrMIZ9SSMK3rTtx33Aodrk/G5vj/e0o7kLd8Q/yDIj1PRAM6F1NxgXc+YDgY+1d+NMfItyJOdxWj5NlwiSRhy9yBbNYjcyVDc/520Ou/WpOVhQ+IjoqtvErNX8u8qO9JzYhz4THTVDjYb7WX88K6Ryl0g9y1DIZMgshUfDaRrXhpnMfxR8rF/0adQGXIQyg2eeuNrmMzxuK7UdcMR0sS8YHFHTi/YmBR5cRf33tq55AeoQRlIpOUJ1NYeY9+gtHaFe4FLzR8QXF5DaAiuq0Qz1fiqcJhZjNZehr6nEZpet0SKgVZyVvrx4ppLb1vHONB1CZhRn4lqxN27pxnmreJiv7Y1EBYg3x4+0Fvd8xk7zxbjVcVSPGlV13vAzWUoLhHRzxXhIhuPRKFQDCeo8tO1q1Zije9Vqn9hrGGWYLxiC86oJ6HhrnnAYStNyINfcqV1XayS0r14heByPQGmaM3Xnmm9mzm/czv6uoPkf6K5jF+iMEN/CXtXvIL7a57GjNon8LcDEfgYpkpyV0QFw33EytRn0E3zDkbWvohRmvkYWfsivmkiXMyiwsrozJJdwNSeFgalWGicD5xLjqAGZaBRaJhaMGZiFx4BUuxkQfpAKqDN+NdwgeU/NRawsbhBor1+7DqP8ftLy7ONNfSk7qQla2faTq8b6TxVmjjxsP9yMTxScMb4DEKE7uW3iQIhjB65V75Eo8zmXOUVAcbKt6DkFuedyyn+SbBNdrETNZcDlIyYMPyg7y647nPVREn7KCIR+CnnIxyX3+H2jEM44x+5Im1InOOqJyJklf1m+1siOuDddsBP0503KgnBl7HTBFe9op1g0kCNaxDiWlJYWh4uyJzTT43u+hAukSQ0k103yS0FG1XWU/H58/FNVQdcIYno1qUb9pHW0Me1wLgHHkdZF77SxjIyBI/W/gOn2DQ8WvskumnewTTtTExa9qe5kVhonA+cS46gLqZAY9Ry20xsbRVwUuBm07Svb6QC1sxAYxnfi5Ap+9sju9ZCCSVcmE5xEZb49mnV7vHy5/O/P1UkF29ozNzzpO6kJXmTbTO8jZzfBgx8Heg0Fdj7gXCb8AQgyzB1mf9PYPPL5nVylXCZz74vAZv8WVLNe1gaN3rCQM4QhBoNFuN0lFI4DjIWFaYp77A7HwZ+32TTJvzOhzzeZ1+zJHI54lTC3rB7a1ZKcm0kMpW457BwbW1v4wkFAi2R4YKyGdrU7nJp+5qIxgivPCW88tCXIDI5mGEiqgxCrJ2Jx0psrwOH9Jn4hB2MkblpWHngKhqoXDcTlKz0UIaNiQ+hdsMSnFFvdPl4gUA4w01vFzAZyCSXgaM/YPGExwSz76PPGe7rDRKBW0UYGnocrF6HVrKr6Cc/gEW6saiFAjO6WCSuiV2/qQ4lxQahpBqxSioVwnplHseVbD2JEKLHNr3v9MN8PfVhPJ6xVisAFBljk47+wG9sL0Pfk6TlAb2f5y9r3B2Ytg8YtYx7X7CVe7UUJzb+H2Jh6Bo/g3EdK5DB3/NZoPVQ3JaFud31QEdUm7WLsCdoiX44ThZyiQibKtLxqY6fxfuJbgB+q0z3aB/9QVxPcUOwhIn2XUdcxBMx2EqGRZsq14xJADhRFWl3tmraKSevo7mTBRfHMLcw7+4WeHN0O+x4pjeWPtDBuf1a8A/mWWzXtZHUtl/Rp2gXW3eE7j+KncNdx0d9Jpx9Twgw4mOg46PArSKQuJaIrynAwwquotYjip9xRj0Jryg+xs0qCx1osdC4ANChpAZlsGC4cZeBC0bXRmf6TipAZAr0Ghvt9q5vkij0lAeOfpi3+FA7GNVEgc26tkhkyvGdbBAw4iP+NJUXMvRF2f0e//2FHVyw9573ufejlpuN2/tXccLqQoauZbtZh4FMgWnNba8B77ZHKFvtvc8T6Ny6gZqQWN6iYhKJI6QpZvfhYkzHdWqIrrLjAMxyMd1kx4Ja1NxEWh6+JX0FV/0Y/5iNIV2f0YiUH1UpZcD1w4LrvtD1RX7+AOcOJJI000hWjPZHuYIZNtJDTrI07L/ooTguuf2q8DE2iVvByHJtHyz4ex5QXSp+HV87E/iwO7DvIwAAUyKc+BrH3LK9BgiFxgUA1KAMAgjLQjPsfeyJH4loVOBT3d1YmvQCaqKbOlUSy2UE4vtYmQqpsjK3d10ss1NqsI5wTp+If4d8hDBGh3wF98Mfza7nLiZr7Ut3eI3B7wgvN06bWBq3zfqYxdWtDd3EVoBMCSzty+lT5s/3eFd9cYpL4SurakdC/E1EJH7yJqHSEGRvNBaN2owHLpcB4IoIrGr6Mu7VLDDJxfzY7OWgFjW3pHuIbdGGYjYSJVFZJkO6PuBIN1UlUH60nA3Fxtj7RbfpLD+FkXlOerJFEsUAILrbFOf2JcKGqHFOtb/vyv/ZJG4FE8bqa6MUO6Amt4FfnwNqKoQlfeyMvyVfhdxnew2wfpCnOpQUqex7dyJUn/TGnTe5H9pDil/w+OkHseqlUaYMUa+jMsh0GJ6IZDJp2YqOyMFJj+wnkGkmLxKfavdX3Eub4bae5x5POycHRAig03AJJ1f2ca/7PvFgJzkCoXoOyygxQUIt5limCif1VokIhumokqGfoZvmHbyom4RumndMWbQm7wMh2HkzAr3kR5AnO4ve8iPYcTMicCxqN6kY+jGusNyD6fc6zpN9C6GY1rs5vkhfiG6ad/A367mwiFc1YwJS9L5c7KHDgpuGQgzrdZzQ99+IxNSInYJtK4gaT9TOdF4rcv9ywcWXVM3Ror0dFQgn6NOgwKn26yLHeOS4/sJoUIUZ4ijtSvocEB5/S4rZSOzXZtqu8OVslhNQgzII+DVUeCpjhT7flCHqdazj++5Z7Jvj1mVS2/sv7mVxR2C7VYWM7W84p2W2diZXaWP7Iu79tteBwxIzv4MMGREXDba291rLL3P/JBgu8obpqFZtO6FDTjsAwBWSiHMkHfe2TzV7H9bOxLrKkTwdynUVI/3nxfYwrdp2wupGz+Eo2xj/1o1BN807+LbZ68jJiMbeW4m4QhI9qhM4T/Wt3+VirNmBHIzSLsA+vUjdZgDo8QyeYWbhJJuGdFkxhmsWYjYzF3E9hONQl2iH4hxJd14rUqTgQEPNWY+dc3Eod6p9QukhvKHlxwce0DcRaR1YVBOl+PnWXUDqRySG1ZIqqBEeEjxmWvD0tB5TENLS5ke2SDsaR4iPprwB2yei7BHQhfKnwXWqaCDK4J0RyWrlobSvMxbo3GAjMV4zD9cNsaSb9E6KfVf/7T/vUzcRcXNnyn/a0ZkLVPQuV8oQNyhFPahD3wFmHuJNR524xuknTr6rMQDg+DULPUWxKbBcYR3YoMLgzU4t3IJs2QW8nbEDRSQGm2/GAAAWT8hFtyaxWKCtA5/VDo0VZThH0tFWdh6ASLzk9kV4m3kLrWVX0VZ2AX3lB1EVli4qPfWQ8leEowrTejppeNmTB/PTzElevB73yPme2HaGsfIXtSIxrUaMXvAwRsSgFyuhu3+Zw2M3lhVhRbKXkjO9ADUog4BThZUYJueyA40ZwvcY3hszRP2BQm0I1jZMgytCY7i6ou0mcFJHYrSbYPgnAOejnCBJVoGvVa8ilKnFWTYZiUwprrEx0ndQdtF/3qdLe4SXO1P+My0PSGnnke74CtEsbIe4sN2nA4Cdb/OmoxZPyMWOZ3pj4bA22PFMbywen2tuLzIFKSrxFEysmQG8nIgR2rUAgLuKv8UZ9SR8n8pJCTVPisDSysfxVsiH/uylVzAajQUkGVXDlgIAHtfOwijNfBxghUX/o2BOYJuu+Ambbo8GqoQ9iolMOY6rpyBnjXBpRlHS8jgJMGus5czcwcl4lfLbWrSwEjz3t5f5pkjZRCNiZRVNiJXQlaiecrvCOeF/f0INyiBgdn4zzNY+gWW6/khkyrFMdzdma58AQEwZon5h3Ar+NHhKNpdocshq2jPUaGQxnDRNpEFCp1kfn3bXW0Qz1WguK0Rb2QXsluXgVtMh0jf2VwylWH1tkZuW+H4c65HqJZXekYanY+K0jJdrSFt9v4LyIUaqRG4ct4LnhiKKyM0zCmYPrZqVXvkkmFAxenyv645/qZ9Gq+yOCFfKsJnNw2WSiFayy9J35OhnJDSt6ogQgVkiazkzd7DnBZVbCYCHxSMtJtRzx/YQqbJSu+uTZBKqNgmV0JVSQAKAstfTktoFAtSgDAIa7X4OP6uew4OKXwEADyp+wc+q5/CKYqkpQ9QvWE+D60Vc/hldgMnrgCa9DLF7hpi7k8FfAcSakdiKBn/9T1rj3MlAaq7DZl5B7GLWw8lSj6l2pvkNnusaVSIus/Hi7ZxA7+FLlpzUOm7kKr2ec+77FfPm+NtF4wmklBaNc6G8X5AwSrEDn2rmAGtnQaNnEQItxik2O1U+0J5FWZXe3WLmxwnGfgOM+xZoZ5iSbTXEVs7MHVJzAbXIrI3e6ren0yC6/zzPHDfQECqhK6SeYvUdV8ij0SK3pzd75lGoQRkERHcXDsZeoc8PLI06ezfExt2APp6XlAlqDnzmvylvoemucBdKPXYT6f+YrzjPdZt7Ea65gQyZk55PEQoJd3PSeKIWc1gcrndw8gamipLedusrwlNdYviynruvSc0FwuL4y8Li+QZ3/3/5tk/+oOomfsrgpvuNyVeS6T4HO+PuE1wVcmWPsDSNI/YsBr4ZAxz6mnt/6n/cLJMz56091swAaux7+EyktRfVxhSi2gf12Mtl0e7vxF4JXSv1FNZgkv2RwH3PlWzgeWztQQ3KIKBF+x74OW4yb9mb2pFomtMtsDTquovcELsZbohiFX/qMxK1yLyCwnCxamfQtwtxQcA4LQ/o/Bh/WeepQGvDtL+2xvX+CZAh46aOVJ6oxVxdgrTz3zm3jca5rFXBqS4x0vIAdTR/mTomICpguM2aGbbT3tU3+YaLSNJJnaLHHLxb1tW1bQ8sR2a5cL1mJbTOKTQYEYvj81R1NGf203ehU9fDUHi/qk4EW+b6xp0MjiB7JXSt1FOKBnyMa5P+QOdpn+DapD+gGx1cqhnUoAwG1s7EwJLPeIvmKFei31+v+qc/Yog9XVrqbRnjcxoker07QYEELTKPY9SPbNiFe6+O5GJbx33t2v7Ob+NejVUbjO8B90QkheK7PI1GQvyTEWU40HU2cM/73E1ALcFb6ax3MdRQTcc4lqFOJHkFMmKGhaXB7cUSrwGBwSM7SrZZcPUluWG2SSEujn89pJHwOsC1GEpv50WKed2tH5yM3monroe+0Kd9VzHJ9oHZArs+4b+2OC6haxU2lnrnSKRmckl8qZmt0Kh1cD1MUoMyGBDRq8oaOsO3/XCEI9kTq9ql6PQYwIhNW7hxtVD6sGa0Os5xG3v4IynHkHGLo99y7/cs4WJbdy9xbX/2qjZIDDwXpPaW69tKJd6JpDZtFfD7O8Cl3dxNIMRgUCrUwu3tTXWJ4at67r5GynS+O+dKMFB9E1g7C3tihgqu/iJpLvedRyTZruw8FUjLw/s64YS/Y0xz12IovW2UCcQJQqYCasr4y4ze6gCSIitjw5Da70ng3G+ibewOX/d/BJTouC+gBmUwIOL5a3jBg9l4nuDPz4SXG+VQrGqXYu+HABGbtnDh0dno1RFLDvIGNW54Vdrc65/pTCneImewV7UhLc83nkZXCIt3LW7POH7G8dJZTesbs1ftTXWJEaAVMNxGyLCwNrjT8gCZVeZvXSNvEoYMGIzlun68xZ/p+mPIgMHcdz7uGyC2Kbcix1C60OD1H9BvkI0mMQC0xgXX+uOp5Dx7WMUJQi6i63i7hDsHOk313LHd4DZC0PO3IUCJbclQAEBIFJiBb3APAU168dc16e2agR/kUIMyGGgvIvbbfqJv++GI46uElx8z1Gb1Zrzg0P8C1w4AD/0CjPzEHL/iRbRKJxI0hPhri2c64iy+Tv4ID9DwBp2GKzUpU7q2fYyIkHR8y7rlXfQU1oaFkMEt936ihd+Ibwmk5SHn4HxMUmzkrZqs+BU5B1/g3iS24vR8Zx0G7v2A5/Xff7EU98h/5217iY3HlxkvudantDzbsIpQD8ftWnvdh4lUWTNefwq2cq+dxKeafUGKrAyhManiDcLjgM6Pcg8BFzldaCRlca8XfxfdrC5Th3+9dYjVIk9sqx8HZvzp277Y465pwLZFwssB78YLFp3g6kn/bzZQ5P364CwApdbJBA1rktt6pC9Ok5YHhMbxPZJyNXcxJMTzwUljvwaW5gPaasdtfcnQd7ipftZJj7bRexOTARQdtV0f09DsZaSYGfcNoFRzY9PlCeGErWHvASsfEtmBDA6i1gIbnaFMrpjWq6U2rKVn2uJcerp2CeJkV3mbNZTdxBC1k3W8LVFHA7dLOQNu74fiMj+uYv1ZYhoDPz/N/7yW3upRy83nyan/ARX8z+tLIoa9Cvz2EnB+q3lhk97ctcPy/B21nItFb9wNuLATqHEiNrsOQT2UwUB3kTJ5rgRhe5Pez9t6e2RKbjkgXrvUWuCWsV/qSpA/PuBefWBMAh4KPeq30BN7cQ2dVQ14fQ0XV+kpuRBL9iwOPGMSAAq2O1dqEuB7b7qJeHS7ivxe6ztSpvON3ilBWKD53bYJHcFCSg73KvbAJuFBLo4RNlTElkvCukCFLzzr9rzVlufJ/SKzXj5gecg4LlFIyPtoff62GsQZkwD32mqQT/saKFCDMhhoNwFI78hflt4pMGM0jN4eY7aqpfdHrHapMebR+IMNAtw2KF3RfPQkaSKC267GUdrD1ezdiBTP9sOavEmOS00aH5CMNz5L781qkSk5sRkFimMchcX0mgsMeMU3ffE0Rs1Wd0JOvBHz6I+4XanJZ4mtOO+lH5hU+w2nEzxqOVeY4/HfuddRflDmCBLolHewcP0w95qUBdw4Blw/5NfuiDLwDSAsFsi+j5MIsizNJ2ZYpOUC/V4yTxfcLgeOfAecXO2TLvuUkAZc9rK/E1X6LQQ+zrdd7o04yu5PAafXO7+dN6eNmvQ2G/T2amXLlVxYidA0bfcngdVP2G4TaDMHwYS9sJje/+S+s7Q8YPU0eF/zxoNENzafb2l53IOJpeC3VL3R1Fzo1HFQWCQD6tRxUPir4pariEzpC9LoLuDkTy4dhsDNh/+8SfzvxeiFpAhCPZTBQrA8JXV+lDMmAe61s0VyjNjT9aA3+NMFZ36WZkwGkUfThFEKh9X7tx9Ssm49hZhn2hHpXvTgVhZyr2l5QBvh6iMAgHveE/feBNPMQbBgTzZmu2V8dpCVo7TurjERxlm90TUzecYkAO69vypu+YKurofhSH/kEPCt9XiaS9qjSMavBuWrr76Kjh07IiIiAomJiRg+fDhOnz7Na0MIwcKFC5GamorQ0FD06tULx48f57XRaDSYMWMG4uPjER4ejmHDhuHKlSu8NqWlpZg4cSKioqIQFRWFiRMnoqyszNsf0XPUhRgNqUaMoynSqAwgvhUw4XvggbV+mxJxi97P+rsHZr1O43fiisyNFFyZ8lZHA30WeLwrALhpbEutzFMi3g9GDmSNtL8vy5kDIHBnDoKFtDygkUjt4q7/MNeYHvuVa5WdvEXr4eLrlOFcvWxLXNUbrSoWXn5LZHldwI1kTukGjoB83fY3XKs+VI/xq0G5bds2TJs2DXv27MHGjRuh0+nQv39/VFVVmdosWrQIb731Ft577z3s27cPycnJ6NevHyorK01tZs+ejR9//BErVqzAzp07cevWLQwZMgR6vdkLNH78eBw6dAgbNmzAhg0bcOjQIUycGGCyO/UBKdIhjqi4Dtw8Bex6F/jfP4DqAL+YxlmJZzfuDrQd55++ANxNWVsDNO3Nva++CeSM5Yws4oVpRFcEq1m9Wb/UWcLigft/BDK6CK9v3I3vaewuYtxL8RoFy8xBMHFll/Dy7a+bPXGtBgG1lcLtAHP8rdLLoSUDXufOtdBI8TY6DZDQkr/M1bhFscQdWZB5bJ1Boti5TsX/vdZEich6OQMNX3EKhhBv3EFco7i4GImJidi2bRt69OgBQghSU1Mxe/ZszJ07FwDnjUxKSsLrr7+Oxx57DOXl5UhISMAXX3yBMWPGAACuXbuGjIwMrF+/HnfffTdOnjyJO+64A3v27EHnzp0BAHv27EGXLl1w6tQptGzZUrRPRioqKhAVFYXy8nJERtq5eFDsU3TKLAlReoEzbKwvplf3C8f3uUqTfOC8cLkzryNXAXqN7fK45v6TfFozQzxusP0DwD3vev6Yi5ryZUIckdmDizN1NvaySW9gwGvcOXV5H/BJX9s2D28CMiymqsXGo/U9wBg78ZUU77Dt38AWEcH5loPNJULXzwX2fmDbJjQGeHAD8PUYoOyC17oJgEsiGvZf8XPNiKd+V2LXximb60bNdzHEvmtvkpbHjStFsv0TUDGU5eWcrl9sLJchXFBQgMLCQvTv39/URqVSoWfPnti1i3uK3b9/P7RaLa9NamoqsrKyTG12796NqKgokzEJAHfeeSeioqJMbazRaDSoqKjg/VE8gJQncyGxXXuEOSh/eH6z/6bHhIxJwL9i3/ae+L2R5Q2YPdNS4177LnTNs9lnvvmcsqffaonYeHSrw3FpgUzPp4BYEe+SZTbzoNe5BzYeMuCBNZxHsNczXuuiCWPpVEeZ/Z76XaXl2comSU3oCWasxc4ZK9PFG57oQgGNWYpdAsagJITgySefRLdu3ZCVxd10Cgu5wPmkJH5t06SkJNO6wsJChISEICYmxm6bxETbG3hiYqKpjTWvvvqqKd4yKioKGRkZ7n1AinMYL5pGQ0RlxytszAa2Z6zYmx4DXNO+dIe7XSj55ynS8oAOIuLR3qqWY4wZY8VKbVqgUJuzeVVOVCMKi+d044xI1W9NywOyrcrZZY+p+zfpQKb8iu0yIaktfa1VI5Yr77p2FpccZV0Sz1niW4uvS2ht7o/YuWbEk78roySbswk9wcyo5fyY0whDBRvjGDRIFC5/2NSO19gS45i2MtRZb5BCw1dcIGAMyunTp+PIkSP45hvb4GTGKm6EEGKzzBrrNkLt7e1n3rx5KC8vN/1dvnxZysegeAqj2O7DG7nYtIc3Am1GCLdt3M0cx+asULURT1eHMZI/39ZYZeT+N1YuCnjmvZXlDZg906OWcxIq9rD0PhAnsuGrb/KF2Z3Jwi40VBox3qCM7yn+YdRycxxka8NNXmiWoa9IyUGjnqXxPBfzeIphPA8qr4m30d42/y90rhnx9O/K1YSeYMZ6Zuv+lbZjICRAXiHwYGINIwMe/Jnbz9gvudcHVgdn4qufCQgdyhkzZmDNmjXYvn070tPTTcuTk5MBcB7GlBSzyHFRUZHJa5mcnIza2lqUlpbyvJRFRUW46667TG1u3Lhhc9zi4mIb76cRlUoFlcp6OoXiM4SmwrtME64Xnv9PIL0D93/fhcAfHzpXmaXbPzhD4/tJAh4PJ1FFAJpKcxmzI99zT8+V181tGiR5p8ShVAgBRnwMLBvIyRgltASKT3svy9uSxFbcVKSQfqORe94z/5+aC1zYbtuGkQFEoAyf9dSiVP1Wy3JvYmUBKb6j1SDOCLSOt7bm77PC2x9YzslOGUviNeoKvNYI0FiUS2Xkwg8sfV8Eus3mzoOfZgiff4BtxrXxXJMruWINxnPU078rZzQc6ypCYyBU/jC2CfDVfUD5ZSBnHHBYwPiOSKVj6iH8alASQjBjxgz8+OOP2Lp1KzIzM3nrMzMzkZycjI0bN6J9e04Pqra2Ftu2bcPrr78OAMjLy4NSqcTGjRsxejQ3bXX9+nUcO3YMixZxumVdunRBeXk59u7di06dOBmAP/74A+Xl5SajkxIEiMlHHPjcbFAC/Mo7N47Bbg3gJr05IxTgpkzteSSsUUUDmjL+srB4YOpOs2Hyy3zg1Bp+m8prnCfNG8kvUlgzEzhokWxSbJDqSs72zfHbTQB++Sdw+2/bdQo1X6pHTIC99/PAZoGwAeupRak1dukNJfCQ8p20f0A4oaq9QcHD6GX6aTrfmATEvd8lf5mPKXb+AdwDriXGcy0snrvuKMOApDvow4mvsPQoWgqQT/jB/GCSPQoouwI0NUhTlZwHIlN92s26jF8NymnTpuHrr7/GTz/9hIiICFM8Y1RUFEJDQ8EwDGbPno1XXnkFzZs3R/PmzfHKK68gLCwM48ePN7V9+OGHMWfOHMTFxSE2NhZPPfUUsrOz0bcvFz/RunVrDBgwAFOmTMGHH34IAHj00UcxZMgQSRnelAAhb7LwzSPPqlzb6M9tjYjvJgGsgPfx4u/m/+9fxWWGll+U1h9rYxIAkrL5UzNEJGbQ1XKEnkAs21pKfKOnEDImAfPDgJG0PC52ztIbFJ7AJezseZ//WYSmFsVuMpS6gb3EK0sVBWd+b5Ze7rQ8caWGW1azXpbnmi/KF1KkYfldNOvDX0cfHj2KX2Mo33//fZSXl6NXr15ISUkx/X37rVkE9plnnsHs2bPxxBNPoEOHDrh69Sp+/fVXRESYpxHefvttDB8+HKNHj0bXrl0RFhaGtWvXQi43x6599dVXyM7ORv/+/dG/f3+0bdsWX3zxhU8/L8VN0vKATlY3kM6PCxsR1iLwQsYkAIRaZIj/sUS6MSmKnyvgSMEb9YCdxfp7NNL7OdtlxjKVxrg2YyydJzRNKcGN1MQrp/Zp9TsQe9D6i0rKUCiWBJQOZSBDdSgDhMWdgeJT5hjFhNbAtD2Ot3uvMyeGbk2jrsCDBq3DK38CS/vYtnEGaz04sX0+8ht/mt7XvNHM1uv39Dnf9uH/Uvixrsow4Pnrtu3EtEulaJpS6j5L+wJX9pnfp3cCHtnIbyOm36iOBmrKzO/DEoBnrH4HYrqYw5fQMpuUekFQ6lBSKA6xlo+wLKEnBssCMQ2F11lqujlb4ksewn8vNOVqL+7Tnxi9fuGGpDR/6HRaxrpavrdGTLvU1WojlLqFlPKXQtq2oTG2EjxCXu6eT5nLlBpRhlFjkkKxIiCyvCkUybiSPLG4I1Ai4n2znOYVi9EUIzweqLhm9pYK3Yykxn36EkK4ONM/3gcOfQ20ux/o/JjvM8+FYl0pFGeRmniljgZul5p/r+oYTm5GSna/daKf2MMPhVKPoVPeEqFT3kHMwS+Bn6bZLleogX9aBdYLlfhSxwA1pfxlqkhOG1PKlKv1Pjs/Dgx8zZVP4hl+mg4cFIgf9lbZRQolEHAnROLUelujleoUUuoJUu0f6qGk1H0uicRYygROf2OJL6NmWWxTznNnbVCGxUv3llqWDdv7IXB+q7R+ewuxjFd/Zp5TKN7GHWkoqhZAoTiEGpSUuo+YoZSWa7vMUuC617PmKbCKq0BcU+5/Z7XLqGg2hUKhUOo41KCk1H16PAWcXm+73ChobomYF8Md70agiWaLjYcvZYMoFAqFUqegWd6Uuk9aHjdFbYk361YHOmIZr/V1PCgUCoXiNtSgpNQPqAg2H6NcknE81DGiTSkUCoVCcQSd8qbUD6TKg9QXxq2g40GhUCgUj0ENSkr9INDiGP0NHQ8KhUKheBA65U2hUCgUCoVCcQtqUFIoFAqFQqFQ3IIalBQKhUKhUCgUt6AGJYVCoVAoFArFLahBSaFQKBQKhUJxC2pQUigUCoVCoVDcghqUFAqFQqFQKBS3oAYlhUKhUCgUCsUtqEFJoVAoFAqFQnELalBSKBQKhUKhUNyCGpQUCoVCoVAoFLegBiWFQqFQKBQKxS2oQUmhUCgUCoVCcQtqUFIoFAqFQqFQ3ELh7w4EC4QQAEBFRYWfe0KhUCgUCoXiG4x2j9EOEoMalBKprKwEAGRkZPi5JxQKhUKhUCi+pbKyElFRUaLrGeLI5KQAAFiWxbVr1xAREQGGYbx2nIqKCmRkZODy5cuIjIz02nHqAnSspEHHSTp0rKRDx0o6dKykQcdJOr4cK0IIKisrkZqaCplMPFKSeiglIpPJkJ6e7rPjRUZG0h+UROhYSYOOk3ToWEmHjpV06FhJg46TdHw1VvY8k0ZoUg6FQqFQKBQKxS2oQUmhUCgUCoVCcQtqUAYYKpUKCxYsgEql8ndXAh46VtKg4yQdOlbSoWMlHTpW0qDjJJ1AHCualEOhUCgUCoVCcQvqoaRQKBQKhUKhuAU1KCkUCoVCoVAobkENSgqFQqFQKBSKW1CDkkKhUCgUCoXiFtSgDCCWLFmCzMxMqNVq5OXlYceOHf7ukld59dVX0bFjR0RERCAxMRHDhw/H6dOneW0mT54MhmF4f3feeSevjUajwYwZMxAfH4/w8HAMGzYMV65c4bUpLS3FxIkTERUVhaioKEycOBFlZWXe/ogeY+HChTbjkJycbFpPCMHChQuRmpqK0NBQ9OrVC8ePH+ftoz6MEwA0btzYZqwYhsG0adMA1N9zavv27Rg6dChSU1PBMAxWr17NW+/Lc+jSpUsYOnQowsPDER8fj5kzZ6K2ttYbH9sl7I2VVqvF3LlzkZ2djfDwcKSmpuKBBx7AtWvXePvo1auXzXk2duxYXpu6PlaAb39vwT5WQtcthmHwxhtvmNoE9HlFKAHBihUriFKpJB9//DE5ceIEmTVrFgkPDycXL170d9e8xt13302WLVtGjh07Rg4dOkQGDx5MGjZsSG7dumVqM2nSJDJgwABy/fp1019JSQlvP1OnTiVpaWlk48aN5MCBA6R3794kJyeH6HQ6U5sBAwaQrKwssmvXLrJr1y6SlZVFhgwZ4rPP6i4LFiwgbdq04Y1DUVGRaf1rr71GIiIiyMqVK8nRo0fJmDFjSEpKCqmoqDC1qQ/jRAghRUVFvHHauHEjAUC2bNlCCKm/59T69evJ888/T1auXEkAkB9//JG33lfnkE6nI1lZWaR3797kwIEDZOPGjSQ1NZVMnz7d62MgFXtjVVZWRvr27Uu+/fZbcurUKbJ7927SuXNnkpeXx9tHz549yZQpU3jnWVlZGa9NXR8rQnz3e6sLY2U5RtevXyeffvopYRiG/PXXX6Y2gXxeUYMyQOjUqROZOnUqb1mrVq3Is88+66ce+Z6ioiICgGzbts20bNKkSeSee+4R3aasrIwolUqyYsUK07KrV68SmUxGNmzYQAgh5MSJEwQA2bNnj6nN7t27CQBy6tQpz38QL7BgwQKSk5MjuI5lWZKcnExee+0107KamhoSFRVFPvjgA0JI/RknIWbNmkWaNm1KWJYlhNBzihBiczPz5Tm0fv16IpPJyNWrV01tvvnmG6JSqUh5eblXPq87CN34rdm7dy8BwHMA9OzZk8yaNUt0m/oyVr76vdWFsbLmnnvuIfn5+bxlgXxe0SnvAKC2thb79+9H//79ecv79++PXbt2+alXvqe8vBwAEBsby1u+detWJCYmokWLFpgyZQqKiopM6/bv3w+tVssbu9TUVGRlZZnGbvfu3YiKikLnzp1Nbe68805ERUUF1fiePXsWqampyMzMxNixY3H+/HkAQEFBAQoLC3ljoFKp0LNnT9Pnq0/jZEltbS2+/PJLPPTQQ2AYxrScnlN8fHkO7d69G1lZWUhNTTW1ufvuu6HRaLB//36vfk5vUV5eDoZhEB0dzVv+1VdfIT4+Hm3atMFTTz2FyspK07r6NFa++L3VlbEycuPGDaxbtw4PP/ywzbpAPa8ULm9J8Rg3b96EXq9HUlISb3lSUhIKCwv91CvfQgjBk08+iW7duiErK8u0fODAgRg1ahQaNWqEgoICzJ8/H/n5+di/fz9UKhUKCwsREhKCmJgY3v4sx66wsBCJiYk2x0xMTAya8e3cuTM+//xztGjRAjdu3MDLL7+Mu+66C8ePHzd9BqHz5+LFiwBQb8bJmtWrV6OsrAyTJ082LaPnlC2+PIcKCwttjhMTE4OQkJCgHLuamho8++yzGD9+PCIjI03LJ0yYgMzMTCQnJ+PYsWOYN28eDh8+jI0bNwKoP2Plq99bXRgrS5YvX46IiAiMGDGCtzyQzytqUAYQlh4UgDOyrJfVVaZPn44jR45g586dvOVjxowx/Z+VlYUOHTqgUaNGWLdunc0PzRLrsRMax2Aa34EDB5r+z87ORpcuXdC0aVMsX77cFODuyvlT18bJmk8++QQDBw7kPYnTc0ocX51DdWXstFotxo4dC5ZlsWTJEt66KVOmmP7PyspC8+bN0aFDBxw4cAC5ubkA6sdY+fL3FuxjZcmnn36KCRMmQK1W85YH8nlFp7wDgPj4eMjlcpsng6KiIpuniLrIjBkzsGbNGmzZsgXp6el226akpKBRo0Y4e/YsACA5ORm1tbUoLS3ltbMcu+TkZNy4ccNmX8XFxUE7vuHh4cjOzsbZs2dN2d72zp/6OE4XL17Epk2b8Mgjj9htR88p+PQcSk5OtjlOaWkptFptUI2dVqvF6NGjUVBQgI0bN/K8k0Lk5uZCqVTyzrP6MlaWeOv3VpfGaseOHTh9+rTDaxcQWOcVNSgDgJCQEOTl5Zlc1kY2btyIu+66y0+98j6EEEyfPh2rVq3C5s2bkZmZ6XCbkpISXL58GSkpKQCAvLw8KJVK3thdv34dx44dM41dly5dUF5ejr1795ra/PHHHygvLw/a8dVoNDh58iRSUlJM0x+WY1BbW4tt27aZPl99HKdly5YhMTERgwcPttuOnlPw6TnUpUsXHDt2DNevXze1+fXXX6FSqZCXl+fVz+kpjMbk2bNnsWnTJsTFxTnc5vjx49BqtabzrL6MlTXe+r3VpbH65JNPkJeXh5ycHIdtA+q8cjmdh+JRjLJBn3zyCTlx4gSZPXs2CQ8PJxcuXPB317zG448/TqKiosjWrVt5EgjV1dWEEEIqKyvJnDlzyK5du0hBQQHZsmUL6dKlC0lLS7ORMklPTyebNm0iBw4cIPn5+YKSE23btiW7d+8mu3fvJtnZ2QEt8WLNnDlzyNatW8n58+fJnj17yJAhQ0hERITp/HjttddIVFQUWbVqFTl69CgZN26coORLXR8nI3q9njRs2JDMnTuXt7w+n1OVlZXk4MGD5ODBgwQAeeutt8jBgwdNmcm+OoeMkiV9+vQhBw4cIJs2bSLp6ekBJe9ib6y0Wi0ZNmwYSU9PJ4cOHeJduzQaDSGEkHPnzpEXX3yR7Nu3jxQUFJB169aRVq1akfbt29ersfLl7y3Yx8pIeXk5CQsLI++//77N9oF+XlGDMoBYvHgxadSoEQkJCSG5ubk8+Zy6CADBv2XLlhFCCKmurib9+/cnCQkJRKlUkoYNG5JJkyaRS5cu8fZz+/ZtMn36dBIbG0tCQ0PJkCFDbNqUlJSQCRMmkIiICBIREUEmTJhASktLffRJ3ceoCahUKklqaioZMWIEOX78uGk9y7JkwYIFJDk5mahUKtKjRw9y9OhR3j7qwzgZ+eWXXwgAcvr0ad7y+nxObdmyRfD3NmnSJEKIb8+hixcvksGDB5PQ0FASGxtLpk+fTmpqarz58Z3C3lgVFBSIXruMWqeXLl0iPXr0ILGxsSQkJIQ0bdqUzJw500Z/sa6Pla9/b8E8VkY+/PBDEhoaaqMtSUjgn1cMIYS47t+kUCgUCoVCodR3aAwlhUKhUCgUCsUtqEFJoVAoFAqFQnELalBSKBQKhUKhUNyCGpQUCoVCoVAoFLegBiWFQqFQKBQKxS2oQUmhUCgUCoVCcQtqUFIoFAqFQqFQ3IIalBQKhUKhUCgUt6AGJYVCoVAoFArFLahBSaFQKF5i8uTJGD58uM3yrVu3gmEYlJWV+bxPFAqF4g2oQUmhUCh1EK1W6+8uUCiUegQ1KCkUCsXPrFy5Em3atIFKpULjxo3x5ptv8tYzDIPVq1fzlkVHR+Ozzz4DAFy4cAEMw+C7775Dr169oFar8eWXX+LixYsYOnQoYmJiEB4ejjZt2mD9+vU++lQUCqU+ofB3BygUCqU+s3//fowePRoLFy7EmDFjsGvXLjzxxBOIi4vD5MmTndrX3Llz8eabb2LZsmVQqVR49NFHUVtbi+3btyM8PBwnTpxAgwYNvPNBKBRKvYYalBQKheJF/ve//9kYcXq93vT/W2+9hT59+mD+/PkAgBYtWuDEiRN44403nDYoZ8+ejREjRpjeX7p0CSNHjkR2djYAoEmTJi5+CgqFQrEPnfKmUCgUL9K7d28cOnSI97d06VLT+pMnT6Jr1668bbp27YqzZ8/yDE8pdOjQgfd+5syZePnll9G1a1csWLAAR44ccf2DUCgUih2oQUmhUCheJDw8HM2aNeP9paWlmdYTQsAwDG8bQgjvPcMwNsuEkm7Cw8N57x955BGcP38eEydOxNGjR9GhQwe8++677n4kCoVCsYEalBQKheJH7rjjDuzcuZO3bNeuXWjRogXkcjkAICEhAdevXzetP3v2LKqrqyXtPyMjA1OnTsWqVaswZ84cfPzxx57rPIVCoRigMZQUCoXiR+bMmYOOHTviX//6F8aMGYPdu3fjvffew5IlS0xt8vPz8d577+HOO+8Ey7KYO3culEqlw33Pnj0bAwcORIsWLVBaWorNmzejdevW3vw4FAqlnkI9lBQKheJHcnNz8d1332HFihXIysrCCy+8gJdeeomXkPPmm28iIyMDPXr0wPjx4/HUU08hLCzM4b71ej2mTZuG1q1bY8CAAWjZsiXPUKVQKBRPwRDrwBwKhUKhUCgUCsUJqIeSQqFQKBQKheIW1KCkUCgUCoVCobgFNSgpFAqFQqFQKG5BDUoKhUKhUCgUiltQg5JCoVAoFAqF4hbUoKRQKBQKhUKhuAU1KCkUCoVCoVAobkENSgqFQqFQKBSKW1CDkkKhUCgUCoXiFtSgpFAoFAqFQqG4BTUoKRQKhUKhUChu8f/bQyP+IzKaQAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig = plt.figure() \n",
    "\n",
    "axes = fig.add_axes([0.1, 0.1, 0.9, 0.9])\n",
    "predictionsAdjusted = []\n",
    "predictions = Tuples[0]\n",
    "\n",
    "for i in predictions:\n",
    "    for j in i: \n",
    "        predictionsAdjusted.append(j)\n",
    "\n",
    "fig = plt.figure() \n",
    "Hours = [i for i in range(len(data[4]) *6)]\n",
    "\n",
    "axes = fig.add_axes([0.1, 0.1, 0.9, 0.9])\n",
    "axes.scatter(Hours, predictionsAdjusted, label = \"predictions\", s = 15,  marker = \"*\")\n",
    "testingValuesAdjusted = [] \n",
    "\n",
    "\n",
    "for i in Tuples[1]: # getting the actual testing values. \n",
    "    for j in i: \n",
    "        testingValuesAdjusted.append(j)\n",
    "axes.scatter(Hours, testingValuesAdjusted, label = \"testing values\",s = 15,  marker = \"*\")\n",
    "axes.set_xlabel(\"Hours\")\n",
    "axes.set_ylabel(\"Wattage\")\n",
    "plt.title(\"Predictions 6 hour ahead\")\n",
    "axes.legend() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d61788d0284415b4fed48a16e8e34bc70a22da2be71b804d332ad1f39f90ff8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
